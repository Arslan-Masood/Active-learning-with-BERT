{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/home/mmasood1/.conda/envs/env_arslan/lib/python3.9/site-packages/deepchem/models/torch_models/__init__.py)\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_chemprop_pred' from 'utils.model_utils' (/projects/home/mmasood1/TG GATE/active_learning/utils/model_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelCheckpoint\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m pretrained_model, BALD_acquisition_function, get_random_indices, get_top_indices\n\u001b[0;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_chemprop_pred, compute_binary_classification_metrics_MT\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_chemprop_pred' from 'utils.model_utils' (/projects/home/mmasood1/TG GATE/active_learning/utils/model_utils.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from chemprop.args import TrainArgs\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "\n",
    "import wandb\n",
    "import deepchem as dc\n",
    "import os\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "wandb.login(key=\"27edf9c66b032c03f72d30e923276b93aa736429\")\n",
    "\n",
    "from utils.data_utils import scafoldsplit_train_test, dataloader_for_numpy,convert_to_dataframe, convert_dataframe_to_dataloader\n",
    "from utils.data_utils import get_query_set, update_training_set, remove_queried_index_from_pool_set\n",
    "from utils.utils import wandb_init_model\n",
    "from utils.models import Custom_Chemprop\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from utils.model_utils import pretrained_model, BALD_acquisition_function, get_random_indices, get_top_indices\n",
    "from utils.model_utils import get_chemprop_pred, compute_binary_classification_metrics_MT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SMILES', 'NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER',\n",
       "       'NR-ER-LBD', 'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP',\n",
       "       'SR-p53'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(\"/projects/home/mmasood1/arslan_data_repository/Tox21/BERT_representations/BERT_pretrained_on_Tox21_trainset/Tox21_filtered_data.csv\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainArgs.project_name = 'Test'\n",
    "TrainArgs.model_name = 'Trial'\n",
    "\n",
    "TrainArgs.target_file = \"/projects/home/mmasood1/arslan_data_repository/Tox21/complete_Tox21.csv\"\n",
    "TrainArgs.input_dim = 1024\n",
    "TrainArgs.train_frac = 0.8\n",
    "\n",
    "TrainArgs.pretrained_dir = \"/projects/home/mmasood1/Model_weights/invitro/Chemprop/fold_0/fold_0/model_0/\"\n",
    "TrainArgs.model_weights_dir = \"/projects/home/mmasood1/Model_weights/preclinical_clinical/chemprop/\"\n",
    "TrainArgs.metadata_dir = '/projects/home/mmasood1/Active_learning_models_predictions/Tox21/Chemprop/'\n",
    "TrainArgs.pretrained_model = False\n",
    "\n",
    "TrainArgs.depth = 3\n",
    "TrainArgs.hidden_size = 300\n",
    "TrainArgs.ffn_num_layers = 2\n",
    "TrainArgs.ffn_hidden_size = 300\n",
    "TrainArgs.num_of_tasks = None\n",
    "TrainArgs.use_input_features = False\n",
    "TrainArgs.dropout = 0.25\n",
    "TrainArgs.batch_size = 50\n",
    "TrainArgs.adding_bond_types = True\n",
    "TrainArgs.atom_descriptors_size = 0\n",
    "\n",
    "TrainArgs.scheduler_type = 'ReduceLROnPlateau'\n",
    "TrainArgs.warmup_epochs = 2\n",
    "TrainArgs.epochs = 10\n",
    "TrainArgs.init_lr = 1e-4\n",
    "TrainArgs.max_lr = 1e-3\n",
    "TrainArgs.final_lr = 1e-4\n",
    "TrainArgs.loss_function = \"binary_cross_entropy\"\n",
    "TrainArgs.seed = 42\n",
    "\n",
    "TrainArgs.accelerator = 'gpu'\n",
    "TrainArgs.EarlyStopping = False\n",
    "TrainArgs.return_trainer = True\n",
    "TrainArgs.device = torch.device(\"cuda\")\n",
    "TrainArgs.compute_metrics_during_training = True\n",
    "\n",
    "TrainArgs.num_forward_passes = 5\n",
    "TrainArgs.n_query = 10\n",
    "TrainArgs.initial_set_size = 100\n",
    "TrainArgs.num_itterations = 2\n",
    "TrainArgs.sampling_strategy = \"uniform\"\n",
    "TrainArgs.seed = 42\n",
    "TrainArgs.compute_metric_after_n_epochs = 5\n",
    "\n",
    "args = TrainArgs\n",
    "args.dataset_type = 'classification'\n",
    "args.metric = 'auc'\n",
    "args.is_atom_bond_targets = False\n",
    "args.use_target_weights = False\n",
    "args.missing_label_representation = 'nan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainArgs\n",
    "args.dataset_type = 'classification'\n",
    "args.metric = 'auc'\n",
    "args.is_atom_bond_targets = False\n",
    "args.use_target_weights = False\n",
    "args.missing_label_representation = 'nan'\n",
    "args.weight_decay = 0\n",
    "args.sample_only_from_aux_task = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NR-AR',\n",
       " 'NR-AR-LBD',\n",
       " 'NR-AhR',\n",
       " 'NR-Aromatase',\n",
       " 'NR-ER',\n",
       " 'NR-ER-LBD',\n",
       " 'NR-PPAR-gamma',\n",
       " 'SR-ARE',\n",
       " 'SR-ATAD5',\n",
       " 'SR-HSE',\n",
       " 'SR-MMP',\n",
       " 'SR-p53']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(args.target_file)\n",
    "target_names = data.loc[:, \"NR-AR\":\"SR-p53\"].columns.tolist()\n",
    "target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get targets information\n",
    "data = pd.read_csv(args.target_file)\n",
    "args.main_task = [\"NR-AR\"]\n",
    "args.aux_task =  [\"NR-AR-LBD\"]\n",
    "target_names = args.main_task + args.aux_task\n",
    "\n",
    "args.num_of_tasks = len(target_names)\n",
    "args.selected_tasks = target_names\n",
    "args.num_of_tasks, args.selected_tasks\n",
    "args.aux_task_number = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test_NR-AR_NR-AR-LBD'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.project_name +\"_\"+ args.main_task[0] +\"_\"+ args.aux_task[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_test_features (6264, 1024) (1567, 1024)\n",
      "train_test_targets (6264, 2) (1567, 2)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_initial_set_with_equal_ratio_of_active_inactive() missing 1 required positional argument: 'args'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m\n\u001b[1;32m      2\u001b[0m seed_everything(seed \u001b[39m=\u001b[39m args\u001b[39m.\u001b[39mseed)\n\u001b[1;32m      3\u001b[0m train_set, test_set \u001b[39m=\u001b[39m scafoldsplit_train_test(target_file\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mtarget_file,\n\u001b[1;32m      4\u001b[0m                                               selected_tasks\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mselected_tasks,\n\u001b[1;32m      5\u001b[0m                                               FP_size\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39minput_dim,\n\u001b[1;32m      6\u001b[0m                                               train_frac\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mtrain_frac)\n\u001b[0;32m----> 8\u001b[0m initial_set, train_set \u001b[39m=\u001b[39m get_initial_set_with_equal_ratio_of_active_inactive(train_set)\n\u001b[1;32m     10\u001b[0m randomstratifiedsplitter \u001b[39m=\u001b[39m dc\u001b[39m.\u001b[39msplits\u001b[39m.\u001b[39mRandomStratifiedSplitter()\n\u001b[1;32m     11\u001b[0m pool_set, val_set \u001b[39m=\u001b[39m randomstratifiedsplitter\u001b[39m.\u001b[39mtrain_test_split(train_set,\n\u001b[1;32m     12\u001b[0m                                                             frac_train \u001b[39m=\u001b[39m \u001b[39m0.85\u001b[39m,\n\u001b[1;32m     13\u001b[0m                                                             seed \u001b[39m=\u001b[39m args\u001b[39m.\u001b[39mseed)\n",
      "\u001b[0;31mTypeError\u001b[0m: get_initial_set_with_equal_ratio_of_active_inactive() missing 1 required positional argument: 'args'"
     ]
    }
   ],
   "source": [
    "np.random.seed(args.seed)\n",
    "seed_everything(seed = args.seed)\n",
    "train_set, test_set = scafoldsplit_train_test(target_file=args.target_file,\n",
    "                                              selected_tasks=args.selected_tasks,\n",
    "                                              FP_size=args.input_dim,\n",
    "                                              train_frac=args.train_frac)\n",
    "\n",
    "initial_set, train_set = get_initial_set_with_equal_ratio_of_active_inactive(train_set)\n",
    "\n",
    "randomstratifiedsplitter = dc.splits.RandomStratifiedSplitter()\n",
    "pool_set, val_set = randomstratifiedsplitter.train_test_split(train_set,\n",
    "                                                            frac_train = 0.85,\n",
    "                                                            seed = args.seed)\n",
    "\n",
    "print(\"train_set\",train_set.y.shape, sorted(np.nansum(train_set.y, axis=0)))\n",
    "print(\"test_set\",test_set.y.shape, sorted(np.nansum(test_set.y, axis=0)))\n",
    "print(\"pool_set\", pool_set.y.shape,sorted(np.nansum(pool_set.y, axis=0)))\n",
    "print(\"val_set\", val_set.y.shape,sorted(np.nansum(val_set.y, axis=0)))\n",
    "print(\"initial_set\", initial_set.y.shape,sorted(np.nansum(initial_set.y, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "+251-39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_set_with_equal_ratio_of_active_inactive(train_set, args):\n",
    "\n",
    "    train_active_indices = np.where(np.any(train_set.y == 1, axis=1))[0]\n",
    "    train_inactive_indices = np.where(np.all(train_set.y == 0, axis=1))[0]\n",
    "\n",
    "    # Randomly select 50 inactive and 50 active compounds for each task\n",
    "    np.random.seed(0)  # For reproducibility\n",
    "    num_samples_per_class = int(args.initial_set_size / 2)\n",
    "    selected_indices = np.concatenate([\n",
    "        np.random.choice(train_active_indices, num_samples_per_class, replace=False),\n",
    "        np.random.choice(train_inactive_indices, num_samples_per_class, replace=False)\n",
    "    ])\n",
    "    # Create the validation set\n",
    "    initial_set = train_set.select(selected_indices)\n",
    "    trainset_indices = np.setdiff1d(np.arange(len(train_set)), selected_indices)\n",
    "\n",
    "    updated_train_set = train_set.select(trainset_indices)\n",
    "    num_active_compounds = np.sum(initial_set.y[:, 0] == 1)\n",
    "    num_inactive_compounds = np.sum(initial_set.y[:, 1] == 1)\n",
    "    print(\"Number of active compounds:\", num_active_compounds)\n",
    "    print(\"Number of inactive compounds:\", num_inactive_compounds)\n",
    "\n",
    "    return initial_set, updated_train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of active compounds: 39\n",
      "Number of inactive compounds: 30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<NumpyDataset X.shape: (100, 1024), y.shape: (100, 2), w.shape: (100, 1), ids: ['C=C[C@H]1CN2CC[C@H]1C[C@H]2[C@H](OC(=O)OCC)c1ccnc2ccc(OC)cc12'\n",
       "  'CN1CCN(c2cc3c(cc2F)c(=O)c(C(=O)O)cn3-c2ccc(F)cc2)CC1'\n",
       "  'C=CC(=O)OCCOCCOC(=O)C=C' ...\n",
       "  'CCn1cc(C(=O)O)c(=O)c2cc(F)c(N3CCN(C)CC3)cc21' 'C=CCCCCCCCCCCC'\n",
       "  'O=C(O)/C=C/c1ccc(Cn2ccnc2)cc1'], task_names: [0 1]>,\n",
       " <NumpyDataset X.shape: (6164, 1024), y.shape: (6164, 2), w.shape: (6164, 1), task_names: [0 1]>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_initial_set_with_equal_ratio_of_active_inactive(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<NumpyDataset X.shape: (6264, 1024), y.shape: (6264, 2), w.shape: (6264, 1), task_names: [0 1]>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Who cares about deepchem data_object, trash it\n",
    "initial_set = convert_to_dataframe(initial_set, args.selected_tasks)\n",
    "val_set = convert_to_dataframe(val_set, args.selected_tasks)\n",
    "pool_set = convert_to_dataframe(pool_set, args.selected_tasks)\n",
    "test_set = convert_to_dataframe(test_set, args.selected_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/mmasood1/.conda/envs/env_arslan/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:389: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/home/mmasood1/.conda/envs/env_arslan/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:634: Checkpoint directory /projects/home/mmasood1/Model_weights/preclinical_clinical/chemprop/ exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type              | Params\n",
      "----------------------------------------------\n",
      "0 | loss_fn | BCEWithLogitsLoss | 0     \n",
      "1 | encoder | MPN               | 264 K \n",
      "2 | readout | Sequential        | 90.9 K\n",
      "----------------------------------------------\n",
      "355 K     Trainable params\n",
      "300       Non-trainable params\n",
      "355 K     Total params\n",
      "1.422     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "009cf0d07f15470c93f451fdd72f29b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n",
      "/home/mmasood1/.conda/envs/env_arslan/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa1cc61b73e474c93c0d948f7affb0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b42162769ee4b8193ac4cbd53e7c8a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n",
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2548cce93b4ee48a9e4a8fac405a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f2d008d2f548caa9d674105f1a8bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1180e44aaa4da480c52d65f1672675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ce075883d24745b9e46648a7f92712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc7a213748fa4cf5b3a5703bbd78ca10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n",
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef75e62c888d4b87a3bc999c4dc28adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22303d4a45974c428d69f816f653302c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd65e3b516e4898b7c4c12f5d1843cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0af5828c7ad24195884cd6614fbf03f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n",
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced_acc         0.615436\n",
      "f1_score             0.118090\n",
      "specificity          0.630950\n",
      "sensitivity          0.599922\n",
      "roc_auc              0.576513\n",
      "AUPR                 0.046404\n",
      "average_precision    0.047886\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14283/1093664921.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append(metrics.mean(), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "itteration = 0\n",
    "##### initiate dataloader ##########\n",
    "train_dataloader = convert_dataframe_to_dataloader(dataframe= initial_set, args = args, shuffle= True)\n",
    "val_dataloader = convert_dataframe_to_dataloader(dataframe= val_set, args = args, shuffle= False)\n",
    "test_dataloader = convert_dataframe_to_dataloader(dataframe= test_set, args = args, shuffle= False)\n",
    "pool_dataloader = convert_dataframe_to_dataloader(dataframe= pool_set, args = args, shuffle= False)\n",
    "\n",
    "##### Model training #############\n",
    "args.steps_per_epoch = len(train_dataloader)\n",
    "args.model_name = f'itteration_{itteration}_d{args.depth}_MPN_h{args.hidden_size}_ffn_h{args.ffn_hidden_size}_DO{args.dropout}'\n",
    "\n",
    "trained_model, run, trainer = wandb_init_model(Custom_Chemprop,\n",
    "                                            args,\n",
    "                                            train_dataloader,\n",
    "                                            val_dataloader,\n",
    "                                            model_type='chemprop')\n",
    "checkpoint_callback = [\n",
    "    cb for cb in trainer.callbacks if isinstance(cb, ModelCheckpoint)][0]\n",
    "metric_to_optimize = checkpoint_callback.best_model_score.item()\n",
    "wandb.finish()\n",
    "\n",
    "###### Model Evaluation #############\n",
    "trained_model = trained_model.eval()\n",
    "targets, pred_mean, pred_var, all_pred = get_chemprop_pred(test_dataloader, trained_model,\n",
    "                                                    n_samples=test_set.shape[0],\n",
    "                                                    n_classes=len(args.selected_tasks),\n",
    "                                                    cal_uncert=False,\n",
    "                                                    num_forward_passes=1)\n",
    "\n",
    "# compute test metrics\n",
    "metrics = compute_binary_classification_metrics_MT(\n",
    "    targets, pred_mean, missing='nan')\n",
    "print(metrics.mean())\n",
    "metrics = metrics.append(metrics.mean(), ignore_index=True)\n",
    "metrics.insert(0, 'Tasks', args.selected_tasks + ['mean'])\n",
    "#metrics.to_csv(args.metadata_dir + f'BALD\\itteration_{itteration}_metrics.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BALD_acquisition_function(pred):\n",
    "    '''\n",
    "    pred: probability (repeats, mol, tasks)\n",
    "    '''\n",
    "    pred_mean = pred.mean(axis=0)\n",
    "    epsilon = 1e-10\n",
    "    # Calculating entropy across multiple MCD forward passes\n",
    "    # input (mol, tasks) --> (mol, tasks)\n",
    "    H = - pred_mean * np.log(pred_mean + epsilon)  # shape (n_samples,task)\n",
    "    E_H = np.mean(-pred * np.log(pred + epsilon), axis=0)\n",
    "    # Calculating mutual information across multiple MCD forward passes\n",
    "    MI = H - E_H\n",
    "    return MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_indices(array_2d, topk):\n",
    "\n",
    "    # Flatten the array and get indices of N largest values\n",
    "    flat_indices = np.argpartition(array_2d.flatten(), -topk)[-topk:]\n",
    "\n",
    "    # Sort the top N values and their corresponding indices\n",
    "    sorted_indices = flat_indices[np.argsort(\n",
    "        array_2d.flatten()[flat_indices])][::-1]\n",
    "\n",
    "    # Convert flat indices to 2D indices\n",
    "    indices_2d = np.unravel_index(sorted_indices, array_2d.shape)\n",
    "\n",
    "    return indices_2d\n",
    "\n",
    "def get_top_indices_from_aux_task(array_2d, topk, aux_task_number):\n",
    "    sorted_indices = np.argsort(-array_2d[:,aux_task_number])[:topk]\n",
    "    task_array = np.ones_like(sorted_indices) * aux_task_number\n",
    "    return (sorted_indices,task_array)\n",
    "\n",
    "def remove_queried_mol_from_pool_set(pool_set, top_indices, aux_task):\n",
    "    # update pool set\n",
    "    SMILES = pool_set.iloc[:,0]\n",
    "    updated_poolset = pool_set.iloc[:, 1:].copy(deep=True)\n",
    "    mask = np.zeros_like(updated_poolset, dtype=bool)\n",
    "    mask[top_indices] = True\n",
    "    updated_poolset[mask] = np.nan\n",
    "    updated_poolset = pd.concat([SMILES, updated_poolset], axis = 1).reset_index(drop = True)\n",
    "    updated_poolset.dropna(subset= aux_task, inplace = True)\n",
    "    updated_poolset = updated_poolset.reset_index(drop = True)\n",
    "    return updated_poolset\n",
    "\n",
    "def remove_queried_index_from_pool_set(pool_set, top_indices):\n",
    "    # update pool set\n",
    "    SMILES = pool_set.iloc[:,0]\n",
    "    updated_poolset = pool_set.iloc[:, 1:].copy(deep=True)\n",
    "    mask = np.zeros_like(updated_poolset, dtype=bool)\n",
    "    mask[top_indices] = True\n",
    "    updated_poolset[mask] = np.nan\n",
    "    updated_poolset = pd.concat([SMILES, updated_poolset], axis = 1).reset_index(drop = True)\n",
    "    updated_poolset.dropna(axis = 0, how = 'all', inplace = True)\n",
    "    updated_poolset = updated_poolset.reset_index(drop = True)\n",
    "    return updated_poolset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03281303116008706\n"
     ]
    }
   ],
   "source": [
    "targets, pred_mean, pred_var, all_pred = get_chemprop_pred(pool_dataloader, trained_model,\n",
    "                                                n_samples=pool_set.shape[0],\n",
    "                                                n_classes=len(args.selected_tasks),\n",
    "                                                cal_uncert=True,\n",
    "                                                num_forward_passes=args.num_forward_passes)\n",
    "acquisition = BALD_acquisition_function(all_pred)\n",
    "\n",
    "# We should not query with missing labels, so hide it\n",
    "nan_mask = ~np.isnan(pool_set[args.selected_tasks].values)\n",
    "acquisition = acquisition * nan_mask\n",
    "print(np.max(acquisition))\n",
    "\n",
    "# Get location of TopGuns\n",
    "if args.sample_only_from_aux_task:\n",
    "    top_indices = get_top_indices_from_aux_task(acquisition, args.n_query, args.aux_task_number)\n",
    "else:\n",
    "    top_indices = get_top_indices(acquisition, args.n_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5212, 4606, 5317, 3573, 4303, 4226,  201, 1751,   61, 4717]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5212, 4606, 5317, 3573, 4303, 4226,  201, 1751,   61, 4717, 2551,\n",
       "        3045, 3881,  250, 2177, 3450, 2035, 2940, 5044,  940, 5202, 2463,\n",
       "        4643, 2079, 3359, 1933, 1802, 3403, 3624, 4115, 2305, 4179, 3673,\n",
       "        2924, 4032, 2725,  498, 3968, 3889, 4669, 3274, 1652, 3651, 1764,\n",
       "        1825, 3203, 4942, 1502, 4596,  769, 2864, 2399, 4139, 5288, 4835,\n",
       "        1998, 5012, 2227, 1522,  130, 2152, 2300, 2526,  593, 5131, 3931,\n",
       "        3586, 2407, 4949, 2183,  312,  785, 4149, 5128, 2386,  574, 2746,\n",
       "        4922, 3349, 4399, 3946, 1824, 5204,  260, 3398, 2041, 2359, 3314,\n",
       "        2100, 1996, 2003, 1981,  107, 2641, 4403, 2396, 4466, 4335, 4693,\n",
       "        3417]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_indices_from_aux_task(acquisition, 100, args.aux_task_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_set = get_query_set(pool_set, top_indices)\n",
    "updated_training = update_training_set(initial_set, query_set)\n",
    "if args.sample_only_from_aux_task:\n",
    "    updated_poolset = remove_queried_mol_from_pool_set(pool_set, top_indices, args.aux_task)\n",
    "else:\n",
    "    updated_poolset = remove_queried_index_from_pool_set(pool_set, top_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>NR-AR</th>\n",
       "      <th>NR-AR-LBD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC(O)(P(=O)(O)O)P(=O)(O)O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OC[C@H](O)[C@@H](O)[C@H](O)CO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC(C)COC(=O)C(C)C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C=C(C)C(=O)OCCOC(=O)C(=C)C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCCCCCCCCCOCC(O)CN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4664</th>\n",
       "      <td>c1ccc2c(c1)CCNC2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4665</th>\n",
       "      <td>Cc1c(N)nc([C@H](CC(N)=O)NC[C@H](N)C(N)=O)nc1C(...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4666</th>\n",
       "      <td>COc1ccc2c3c1O[C@H]1C(=O)CC[C@H]4[C@@H](C2)N(C)...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4667</th>\n",
       "      <td>O=S1(=O)c2cccc3cccc(c23)N1CCCN1CCN(c2ccc(F)cc2...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4668</th>\n",
       "      <td>CC(C)CCC[C@@H](C)[C@H]1CC(=O)C2=C3CC[C@H]4C[C@...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4669 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 SMILES  NR-AR  NR-AR-LBD\n",
       "0                             CC(O)(P(=O)(O)O)P(=O)(O)O    0.0        0.0\n",
       "1                         OC[C@H](O)[C@@H](O)[C@H](O)CO    0.0        0.0\n",
       "2                                     CC(C)COC(=O)C(C)C    0.0        0.0\n",
       "3                            C=C(C)C(=O)OCCOC(=O)C(=C)C    0.0        0.0\n",
       "4                                    CCCCCCCCCCOCC(O)CN    0.0        0.0\n",
       "...                                                 ...    ...        ...\n",
       "4664                                   c1ccc2c(c1)CCNC2    0.0        0.0\n",
       "4665  Cc1c(N)nc([C@H](CC(N)=O)NC[C@H](N)C(N)=O)nc1C(...    1.0        0.0\n",
       "4666  COc1ccc2c3c1O[C@H]1C(=O)CC[C@H]4[C@@H](C2)N(C)...    0.0        0.0\n",
       "4667  O=S1(=O)c2cccc3cccc(c23)N1CCCN1CCN(c2ccc(F)cc2...    0.0        0.0\n",
       "4668  CC(C)CCC[C@@H](C)[C@H]1CC(=O)C2=C3CC[C@H]4C[C@...    0.0        0.0\n",
       "\n",
       "[4669 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_training = update_training_set(initial_set, query_set)\n",
    "updated_poolset = remove_queried_mol_from_pool_set(pool_set, top_indices, args.aux_task)\n",
    "updated_poolset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>NR-AR</th>\n",
       "      <th>NR-AR-LBD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC(O)(P(=O)(O)O)P(=O)(O)O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OC[C@H](O)[C@@H](O)[C@H](O)CO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCCCCCCC(=O)[O-].CCCCCCCC(=O)[O-].[Zn+2]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC(C)COC(=O)C(C)C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C=C(C)C(=O)OCCOC(=O)C(=C)C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5319</th>\n",
       "      <td>O=S1(=O)c2cccc3cccc(c23)N1CCCN1CCN(c2ccc(F)cc2...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5320</th>\n",
       "      <td>Cc1oc(-c2ccccc2)nc1CCC(=O)c1ccc(CC2SC(=O)NC2=O...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5321</th>\n",
       "      <td>Cc1cc(CCCOc2c(C)cc(-c3noc(C(F)(F)F)n3)cc2C)on1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5322</th>\n",
       "      <td>O=C1OC(OC(=O)c2cccnc2Nc2cccc(C(F)(F)F)c2)c2ccc...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5323</th>\n",
       "      <td>CC(C)CCC[C@@H](C)[C@H]1CC(=O)C2=C3CC[C@H]4C[C@...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5324 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 SMILES  NR-AR  NR-AR-LBD\n",
       "0                             CC(O)(P(=O)(O)O)P(=O)(O)O    0.0        0.0\n",
       "1                         OC[C@H](O)[C@@H](O)[C@H](O)CO    0.0        0.0\n",
       "2              CCCCCCCC(=O)[O-].CCCCCCCC(=O)[O-].[Zn+2]    NaN        NaN\n",
       "3                                     CC(C)COC(=O)C(C)C    0.0        0.0\n",
       "4                            C=C(C)C(=O)OCCOC(=O)C(=C)C    0.0        0.0\n",
       "...                                                 ...    ...        ...\n",
       "5319  O=S1(=O)c2cccc3cccc(c23)N1CCCN1CCN(c2ccc(F)cc2...    0.0        0.0\n",
       "5320  Cc1oc(-c2ccccc2)nc1CCC(=O)c1ccc(CC2SC(=O)NC2=O...    NaN        NaN\n",
       "5321     Cc1cc(CCCOc2c(C)cc(-c3noc(C(F)(F)F)n3)cc2C)on1    NaN        NaN\n",
       "5322  O=C1OC(OC(=O)c2cccnc2Nc2cccc(C(F)(F)F)c2)c2ccc...    0.0        NaN\n",
       "5323  CC(C)CCC[C@@H](C)[C@H]1CC(=O)C2=C3CC[C@H]4C[C@...    0.0        0.0\n",
       "\n",
       "[5324 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/mmasood1/.conda/envs/env_arslan/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:389: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/home/mmasood1/.conda/envs/env_arslan/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:634: Checkpoint directory /projects/home/mmasood1/Model_weights/preclinical_clinical/chemprop/ exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type              | Params\n",
      "----------------------------------------------\n",
      "0 | loss_fn | BCEWithLogitsLoss | 0     \n",
      "1 | encoder | MPN               | 264 K \n",
      "2 | readout | Sequential        | 93.9 K\n",
      "----------------------------------------------\n",
      "358 K     Trainable params\n",
      "300       Non-trainable params\n",
      "358 K     Total params\n",
      "1.434     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33fbf2441d6a4c388f6ff88f86781f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n",
      "/home/mmasood1/.conda/envs/env_arslan/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4389ecd6912f4e5bb3084f526a3d7f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6781844cd0e2445a92ad9f196dd86640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n",
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3daccc83719441f0b1fd3c255e855624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db59723fa5974a8481280dfe30621d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12467db9e476478eb54f3b7cb2e78b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5785b83ec23b4c2c936349f036489d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "220bfe7ed268433c9e13a07e8ffcdd8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n",
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e783547ae44c368d6493692aa0ab24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af2d2982cd884a91946fb616ab21a126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9294f7af28f4b7ea8ee1016ab965c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d85b0a529624da9a46c885e2d236c38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n",
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced_acc         0.550654\n",
      "f1_score             0.195763\n",
      "specificity          0.528359\n",
      "sensitivity          0.572949\n",
      "roc_auc              0.486633\n",
      "AUPR                 0.109616\n",
      "average_precision    0.111973\n",
      "dtype: float64\n",
      "initial_counts 1030 query_counts 80 updated_training_counts 1110 updated_poolset_counts 54021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21518/1550923573.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append(metrics.mean(), ignore_index=True)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/mmasood1/.conda/envs/env_arslan/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:389: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/home/mmasood1/.conda/envs/env_arslan/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:634: Checkpoint directory /projects/home/mmasood1/Model_weights/preclinical_clinical/chemprop/ exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type              | Params\n",
      "----------------------------------------------\n",
      "0 | loss_fn | BCEWithLogitsLoss | 0     \n",
      "1 | encoder | MPN               | 264 K \n",
      "2 | readout | Sequential        | 93.9 K\n",
      "----------------------------------------------\n",
      "358 K     Trainable params\n",
      "300       Non-trainable params\n",
      "358 K     Total params\n",
      "1.434     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10 50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "718aa5fbfc4e46b793c650bd94102f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n",
      "/home/mmasood1/.conda/envs/env_arslan/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89eee6ed39104779ba23c32e14ef3614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "906b63623a41430bbebe28381eafbbde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n",
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8e98a9f3f946b7b77f8d16a943a4b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f0b594cf63460bb08348fdd800f705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be68fa035a4b437ba2cbd887cd80a2c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea1f834b1c94d6397a7d182d36bd785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e065eb3edc45ef9fb85235a183b3de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n",
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3218c78d85647f8a0f02e3c2f83ec99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046974187c3145c9a89d2a2fe4f3795b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f847a2247d849f8ad784b29eb210335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7f83f4ff89844fcac0af61788f3fe3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n",
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced_acc         0.603184\n",
      "f1_score             0.243002\n",
      "specificity          0.638603\n",
      "sensitivity          0.567765\n",
      "roc_auc              0.560059\n",
      "AUPR                 0.158302\n",
      "average_precision    0.161478\n",
      "dtype: float64\n",
      "initial_counts 1110 query_counts 83 updated_training_counts 1191 updated_poolset_counts 53938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21518/1550923573.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append(metrics.mean(), ignore_index=True)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Training_count,Queryset counts are not equal",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 83\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39m# Use an assertion to check if the counts are equal\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39minitial_counts\u001b[39m\u001b[39m\"\u001b[39m, initial_counts\u001b[39m.\u001b[39msum(), \n\u001b[1;32m     80\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mquery_counts\u001b[39m\u001b[39m\"\u001b[39m, query_counts\u001b[39m.\u001b[39msum(), \n\u001b[1;32m     81\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mupdated_training_counts\u001b[39m\u001b[39m\"\u001b[39m, updated_training_counts\u001b[39m.\u001b[39msum(), \n\u001b[1;32m     82\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mupdated_poolset_counts\u001b[39m\u001b[39m\"\u001b[39m, updated_poolset_counts\u001b[39m.\u001b[39msum())\n\u001b[0;32m---> 83\u001b[0m \u001b[39massert\u001b[39;00m updated_training_counts\u001b[39m.\u001b[39mequals(initial_counts \u001b[39m+\u001b[39m query_counts), \u001b[39m\"\u001b[39m\u001b[39mTraining_count,Queryset counts are not equal\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     84\u001b[0m \u001b[39massert\u001b[39;00m initial_poolset_counts\u001b[39m.\u001b[39mequals(updated_poolset_counts \u001b[39m+\u001b[39m query_counts), \u001b[39m\"\u001b[39m\u001b[39mPoolset, Queryset count are not equal\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m query_set\u001b[39m.\u001b[39mto_csv(args\u001b[39m.\u001b[39mmetadata_dir \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mquery_sets\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mitteration_\u001b[39m\u001b[39m{\u001b[39;00mitteration\u001b[39m}\u001b[39;00m\u001b[39m_query_set.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Training_count,Queryset counts are not equal"
     ]
    }
   ],
   "source": [
    "'''\n",
    "def Active_learning_loop(model,args,\n",
    "                         initial_set,\n",
    "                         pool_set,\n",
    "                         val_set,\n",
    "                         test_set):\n",
    "'''\n",
    "model = Custom_Chemprop\n",
    "for itteration in range(args.num_itterations):\n",
    "    ##### initiate dataloader ##########\n",
    "    train_dataloader = convert_dataframe_to_dataloader(dataframe= initial_set, args = args, shuffle= True)\n",
    "    val_dataloader = convert_dataframe_to_dataloader(dataframe= val_set, args = args, shuffle= False)\n",
    "    test_dataloader = convert_dataframe_to_dataloader(dataframe= test_set, args = args, shuffle= False)\n",
    "    pool_dataloader = convert_dataframe_to_dataloader(dataframe= pool_set, args = args, shuffle= False)\n",
    "\n",
    "    ##### Model training #############\n",
    "    args.steps_per_epoch = len(train_dataloader)\n",
    "    args.model_name = f'itteration_{itteration}_d{args.depth}_MPN_h{args.hidden_size}_ffn_h{args.ffn_hidden_size}_DO{args.dropout}'\n",
    "\n",
    "    trained_model, run, trainer = wandb_init_model(model,\n",
    "                                                args,\n",
    "                                                train_dataloader,\n",
    "                                                val_dataloader,\n",
    "                                                model_type='chemprop')\n",
    "    checkpoint_callback = [\n",
    "        cb for cb in trainer.callbacks if isinstance(cb, ModelCheckpoint)][0]\n",
    "    metric_to_optimize = checkpoint_callback.best_model_score.item()\n",
    "    wandb.finish()\n",
    "\n",
    "    ###### Model Evaluation #############\n",
    "    trained_model = trained_model.eval()\n",
    "    targets, pred_mean, pred_var, all_pred = get_chemprop_pred(test_dataloader, trained_model,\n",
    "                                                        n_samples=test_set.shape[0],\n",
    "                                                        n_classes=len(args.selected_tasks),\n",
    "                                                        cal_uncert=False,\n",
    "                                                        num_forward_passes=1)\n",
    "\n",
    "    # compute test metrics\n",
    "    metrics = compute_binary_classification_metrics_MT(\n",
    "        targets, pred_mean, missing='nan')\n",
    "    print(metrics.mean())\n",
    "    metrics = metrics.append(metrics.mean(), ignore_index=True)\n",
    "    metrics.insert(0, 'Tasks', args.selected_tasks + ['mean'])\n",
    "    metrics.to_csv(args.metadata_dir + f'BALD\\itteration_{itteration}_metrics.csv', index=False)\n",
    "\n",
    "    ####### Uncertainity estmation ################\n",
    "    if args.sampling_strategy == \"BALD\":\n",
    "        targets, pred_mean, pred_var, all_pred = get_chemprop_pred(pool_dataloader, trained_model,\n",
    "                                                        n_samples=pool_set.shape[0],\n",
    "                                                        n_classes=len(args.selected_tasks),\n",
    "                                                        cal_uncert=True,\n",
    "                                                        num_forward_passes=args.num_forward_passes)\n",
    "        acquisition = BALD_acquisition_function(all_pred)\n",
    "        \n",
    "        # We should not query with missing labels, so hide it\n",
    "        nan_mask = ~np.isnan(pool_set[args.selected_tasks].values)\n",
    "        acquisition = acquisition * nan_mask\n",
    "        print(np.max(acquisition))\n",
    "\n",
    "        # Get location of TopGuns\n",
    "        top_indices = get_top_indices(acquisition, args.n_query)\n",
    "\n",
    "    if args.sampling_strategy == \"uniform\":\n",
    "        top_indices = get_random_indices(pool_set, args)\n",
    "    ##########  updated dataset ##################\n",
    "    query_set = get_query_set(pool_set, top_indices)\n",
    "    updated_training = update_training_set(initial_set, query_set)\n",
    "    updated_poolset = remove_queried_index_from_pool_set(pool_set, top_indices)\n",
    "\n",
    "    initial_counts = initial_set.iloc[:, 1:].count()\n",
    "    query_counts = query_set.iloc[:, 1:].count()\n",
    "    updated_training_counts = updated_training.iloc[:, 1:].count()\n",
    "\n",
    "    initial_poolset_counts = pool_set.iloc[:, 1:].count()\n",
    "    updated_poolset_counts = updated_poolset.iloc[:, 1:].count()\n",
    "\n",
    "\n",
    "    # Use an assertion to check if the counts are equal\n",
    "    print(\"initial_counts\", initial_counts.sum(), \n",
    "          \"query_counts\", query_counts.sum(), \n",
    "          \"updated_training_counts\", updated_training_counts.sum(), \n",
    "          \"updated_poolset_counts\", updated_poolset_counts.sum())\n",
    "    assert updated_training_counts.equals(initial_counts + query_counts), \"Training_count,Queryset counts are not equal\"\n",
    "    assert initial_poolset_counts.equals(updated_poolset_counts + query_counts), \"Poolset, Queryset count are not equal\"\n",
    "    query_set.to_csv(args.metadata_dir + f'query_sets\\itteration_{itteration}_query_set.csv', index=False)\n",
    "\n",
    "    del initial_set,pool_set\n",
    "    del train_dataloader,val_dataloader,test_dataloader,pool_dataloader, trained_model\n",
    "    \n",
    "    initial_set = updated_training.copy()\n",
    "    pool_set = updated_poolset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/projects/home/mmasood1/Active_learning_models_predictions/Tox21/Chemprop/BALD/NR-AR_NR-AR/itteration_0_metrics.csv'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_names = args.main_task[0] +\"_\"+ args.main_task[0]\n",
    "args.metadata_dir + f'BALD/{t_names}/itteration_{itteration}_metrics.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NR-AR_NR-AR'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.main_task[0] +\"_\"+ args.main_task[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_arslan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
