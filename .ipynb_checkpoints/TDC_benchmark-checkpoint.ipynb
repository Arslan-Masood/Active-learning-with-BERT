{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tdc.benchmark_group import admet_group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdc.benchmark_group import admet_group\n",
    "group = admet_group(path = 'data/')\n",
    "data_dir = \"/projects/home/mmasood1/arslan_data_repository/DILI\"\n",
    "\n",
    "for seed in [1, 2, 3, 4, 5]:\n",
    "    benchmark = group.get('DILI') \n",
    "    # all benchmark names in a benchmark group are stored in group.dataset_names\n",
    "    name = benchmark['name']\n",
    "    train_val, test = benchmark['train_val'], benchmark['test']\n",
    "    train, valid = group.get_train_valid_split(benchmark = name, split_type = 'default', seed = seed)\n",
    "    seed_dir = data_dir + f\"/seed_{seed}/\"\n",
    "    #os.makedirs(seed_dir, exist_ok = True)\n",
    "    #train.to_csv(seed_dir + f\"train_seed_{seed}.csv\", index = False)\n",
    "    #valid.to_csv(seed_dir + f\"valid_seed_{seed}.csv\", index = False)\n",
    "    #test.to_csv(seed_dir + f\"test_seed_{seed}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMILES Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rdkit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrdkit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Chem\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrdkit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mChem\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Draw\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrdkit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mChem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDraw\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IPythonConsole\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rdkit'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem.MolStandardize import rdMolStandardize\n",
    "#IPythonConsole.drawOptions.comicMode=True\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.info')\n",
    "import rdkit\n",
    "from rdkit.Chem.SaltRemover import SaltRemover\n",
    "print(rdkit.__version__)\n",
    "import numpy as np\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(smiles,remover=SaltRemover()):\n",
    "    config = {}\n",
    "    config[\"StandardizeSmiles\"] = True\n",
    "    config[\"FragmentParent\"] = False\n",
    "    config[\"SaltRemover\"] = True\n",
    "    config[\"isomericSmiles\"] = False\n",
    "    config[\"kekuleSmiles\"] = True\n",
    "    config[\"canonical\"] = True\n",
    "    # follows the steps in\n",
    "    # https://github.com/rdkit/rdkit/blob/master/Docs/Notebooks/MolStandardize.ipynb\n",
    "    try:\n",
    "        if config[\"StandardizeSmiles\"]:\n",
    "            # removeHs, disconnect metal atoms, normalize the molecule, reionize the molecule\n",
    "\n",
    "                smiles = rdMolStandardize.StandardizeSmiles(smiles)\n",
    "\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        # remove salts\n",
    "        if config[\"SaltRemover\"]:\n",
    "            mol = remover.StripMol(mol, dontRemoveEverything=False) \n",
    "\n",
    "        if config[\"FragmentParent\"]:\n",
    "            mol = rdMolStandardize.FragmentParent(mol) \n",
    "\n",
    "        if config[\"kekuleSmiles\"]:\n",
    "            Chem.Kekulize(mol, clearAromaticFlags=True)\n",
    "        normalized_smiles = Chem.MolToSmiles(mol, \n",
    "                            isomericSmiles = config[\"isomericSmiles\"],\n",
    "                            kekuleSmiles = config[\"kekuleSmiles\"],\n",
    "                            canonical = config[\"canonical\"],\n",
    "                            allHsExplicit = False)\n",
    "        if normalized_smiles == '':\n",
    "            normalized_smiles = np.nan\n",
    "    except:\n",
    "        normalized_smiles = np.nan\n",
    "    return normalized_smiles\n",
    "\n",
    "def normalize_smiles_parallel(smiles_list):\n",
    "    with Pool() as pool:\n",
    "        results = []\n",
    "        total = len(smiles_list)\n",
    "        with tqdm(total=total, ncols=80, desc=\"Processing\") as pbar:\n",
    "            for normalized_smiles in pool.imap(standardize, smiles_list):\n",
    "                results.append(normalized_smiles)\n",
    "                pbar.update(1)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|███████████████████████████| 325/325 [00:00<00:00, 6594.02it/s]\n",
      "Processing: 100%|█████████████████████████████| 54/54 [00:00<00:00, 3243.76it/s]\n",
      "Processing: 100%|█████████████████████████████| 96/96 [00:00<00:00, 3918.27it/s]\n",
      "Processing: 100%|███████████████████████████| 331/331 [00:00<00:00, 7341.58it/s]\n",
      "Processing: 100%|█████████████████████████████| 48/48 [00:00<00:00, 2582.27it/s]\n",
      "Processing: 100%|█████████████████████████████| 96/96 [00:00<00:00, 4167.30it/s]\n",
      "Processing: 100%|███████████████████████████| 331/331 [00:00<00:00, 6943.00it/s]\n",
      "Processing: 100%|█████████████████████████████| 48/48 [00:00<00:00, 2555.42it/s]\n",
      "Processing: 100%|█████████████████████████████| 96/96 [00:00<00:00, 3314.84it/s]\n",
      "Processing: 100%|███████████████████████████| 331/331 [00:00<00:00, 6586.56it/s]\n",
      "Processing: 100%|█████████████████████████████| 48/48 [00:00<00:00, 2459.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: 100%|█████████████████████████████| 96/96 [00:00<00:00, 4388.69it/s]\n",
      "Processing: 100%|███████████████████████████| 331/331 [00:00<00:00, 6008.51it/s]\n",
      "Processing: 100%|█████████████████████████████| 48/48 [00:00<00:00, 2405.80it/s]\n",
      "Processing: 100%|█████████████████████████████| 96/96 [00:00<00:00, 3649.60it/s]\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/projects/home/mmasood1/arslan_data_repository/DILI\"\n",
    "dataset_list = [\"train\",\"valid\",\"test\"]\n",
    "\n",
    "for seed in [1, 2, 3, 4, 5]:\n",
    "    for dataset in dataset_list:\n",
    "        seed_dir = data_dir + f\"/seed_{seed}/\"\n",
    "        normlization_dir = seed_dir + \"normalized_data/\"\n",
    "        os.makedirs(normlization_dir, exist_ok = True)\n",
    "\n",
    "        data = pd.read_csv(seed_dir + f\"{dataset}_seed_{seed}.csv\")\n",
    "        total_mol = data.shape[0]\n",
    "\n",
    "        data.drop(\"Drug_ID\", axis = 1, inplace = True)\n",
    "        data.rename(columns= {'Drug':'SMILES'}, inplace =  True)\n",
    "        normalized_smiles_list = normalize_smiles_parallel(data.SMILES.tolist())\n",
    "        data[\"Normalized_SMILES\"] = normalized_smiles_list\n",
    "        data = data[~data.Normalized_SMILES.isnull()]\n",
    "        data.to_csv(normlization_dir + f\"{dataset}_seed_{seed}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get BERT representation\n",
    "### change env to molbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, yaml\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from molbert.models.smiles import SmilesMolbertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Tuple, Sequence, Any, Dict, Union, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from molbert.utils.featurizer.molfeaturizer import SmilesIndexFeaturizer\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class MolBertFeaturizer:\n",
    "    \"\"\"\n",
    "    This featurizer takes a molbert model and transforms the input data and\n",
    "    returns the representation in the last layer (pooled output and sequence_output).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        featurizer,\n",
    "        device: str = None,\n",
    "        embedding_type: str = 'pooled',\n",
    "        max_seq_len: Optional[int] = None,\n",
    "        permute: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            checkpoint_path: path or S3 location of trained model checkpoint\n",
    "            device: device for torch\n",
    "            embedding_type: method to reduce MolBERT encoding to an output set of features. Default: 'pooled'\n",
    "                Other options are embeddings summed or concat across layers, and then averaged\n",
    "                Raw sequence and pooled output is also available (set to 'dict')\n",
    "                average-sum-[2|4], average-cat-[2,4], average-[1|2|3|4], average-1-cat-pooled, pooled, dict\n",
    "            max_seq_len: used by the tokenizer, SMILES longer than this will fail to featurize\n",
    "                MolBERT was trained with SuperPositionalEncodings (TransformerXL) to decoupled from the training setup\n",
    "                By default the training config is used (128). If you have long SMILES to featurize, increase this value\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.device = device or 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.embedding_type = embedding_type\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.permute = permute\n",
    "\n",
    "        # load smiles index featurizer\n",
    "        self.featurizer = featurizer\n",
    "\n",
    "        # load model\n",
    "        self.model = model\n",
    "\n",
    "    def __getstate__(self):\n",
    "        self.__dict__.update({'model': self.model.to('cpu')})\n",
    "        self.__dict__.update({'device': 'cpu'})\n",
    "        return self.__dict__\n",
    "\n",
    "    @property\n",
    "\n",
    "    def transform_single(self, smiles: str) -> Tuple[np.ndarray, bool]:\n",
    "        features, valid = self.transform([smiles])\n",
    "        return features, valid[0]\n",
    "\n",
    "    def transform(self, molecules: Sequence[Any]) -> Tuple[Union[Dict, np.ndarray], np.ndarray]:\n",
    "        input_ids, valid = self.featurizer.transform(molecules)\n",
    "\n",
    "        input_ids = self.trim_batch(input_ids, valid)\n",
    "\n",
    "        token_type_ids = np.zeros_like(input_ids, dtype=np.int64)\n",
    "        attention_mask = np.zeros_like(input_ids, dtype=np.int64)\n",
    "\n",
    "        attention_mask[input_ids != 0] = 1\n",
    "\n",
    "        input_ids = torch.tensor(input_ids, dtype=torch.long, device=self.device)\n",
    "        token_type_ids = torch.tensor(token_type_ids, dtype=torch.long, device=self.device)\n",
    "        attention_mask = torch.tensor(attention_mask, dtype=torch.long, device=self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.model.bert(\n",
    "                input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask\n",
    "            )\n",
    "\n",
    "        sequence_output, pooled_output = outputs\n",
    "\n",
    "        # set invalid outputs to 0s\n",
    "        valid_tensor = torch.tensor(\n",
    "            valid, dtype=sequence_output.dtype, device=sequence_output.device, requires_grad=False\n",
    "        )\n",
    "\n",
    "        pooled_output = pooled_output * valid_tensor[:, None]\n",
    "        sequence_out = sequence_output * valid_tensor[:, None, None]\n",
    "\n",
    "        sequence_out = sequence_out.detach().cpu().numpy()\n",
    "        pooled_output = pooled_output.detach().cpu().numpy()\n",
    "        out = pooled_output\n",
    "\n",
    "        return out, valid\n",
    "\n",
    "    @staticmethod\n",
    "    def trim_batch(input_ids, valid):\n",
    "\n",
    "        # trim input horizontally if there is at least 1 valid data point\n",
    "        if any(valid):\n",
    "            _, cols = np.where(input_ids[valid] != 0)\n",
    "        # else trim input down to 1 column (avoids empty batch error)\n",
    "        else:\n",
    "            cols = np.array([0])\n",
    "\n",
    "        max_idx: int = int(cols.max().item() + 1)\n",
    "\n",
    "        input_ids = input_ids[:, :max_idx]\n",
    "\n",
    "        return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/projects/home/mmasood1/arslan_data_repository/invitro/invitro_1m/25_04_2024/SMILES_len_th_128/train_set_invitro_1m_300k_ADME_filtered.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4172637/4079384585.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_file'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SMILES'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mtarget_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/work/masooda1/.conda_envs/molbert/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     ) as handles:\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/work/masooda1/.conda_envs/molbert/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/projects/home/mmasood1/arslan_data_repository/invitro/invitro_1m/25_04_2024/SMILES_len_th_128/train_set_invitro_1m_300k_ADME_filtered.pkl'"
     ]
    }
   ],
   "source": [
    "# config_dict\n",
    "model_weights_dir = '/projects/home/mmasood1/Model_weights/invitro/invitro_1million/MolBERT/Retrain_on_top_of_BERT/complete_1m_300k_ADME/without_physchem_head/'\n",
    "pretrained_model_path = '/scratch/cs/pml/AI_drug/molbert_100epochs/checkpoints/last.ckpt'\n",
    "data_dir = '/projects/home/mmasood1/arslan_data_repository/invitro/invitro_1m/25_04_2024/SMILES_len_th_128/'\n",
    "pos_weights = \"/projects/home/mmasood1/arslan_data_repository/invitro/invitro_1m/25_04_2024/pos_weights.csv\"\n",
    "metadata_dir = \"/projects/home/mmasood1/trained_model_predictions/SIDER_PreClinical/BERT_finetune/MF/\"\n",
    "model_dir = os.path.dirname(os.path.dirname(pretrained_model_path))\n",
    "hparams_path = os.path.join(model_dir, 'hparams.yaml')\n",
    "# load config\n",
    "with open(hparams_path) as yaml_file:\n",
    "    config_dict = yaml.load(yaml_file, Loader=yaml.FullLoader)\n",
    "\n",
    "config_dict['project_name'] = \"BERT_invitro_ADME_pretraining\"\n",
    "config_dict['model_name'] = \"SMILES_len_th_128_Permute_False_PhySchem_False\"\n",
    "\n",
    "config_dict['model_weights_dir'] = model_weights_dir\n",
    "config_dict['pretrained_model_path'] = pretrained_model_path\n",
    "config_dict[\"metadata_dir\"] = metadata_dir\n",
    "config_dict['pos_weights'] = pos_weights\n",
    "config_dict['data_dir'] = data_dir\n",
    "config_dict['train_file'] = data_dir + \"train_set_invitro_1m_300k_ADME_filtered.pkl\"\n",
    "config_dict['valid_file'] = data_dir + \"test_set_invitro_1m_300k_ADME_filtered.pkl\"\n",
    "config_dict['test_file'] = data_dir + \"test_set_invitro_1m_300k_ADME_filtered.pkl\"\n",
    "\n",
    "config_dict['mode'] = 'classification'\n",
    "config_dict['alpha'] = 0.0\n",
    "config_dict['beta'] = 0.0\n",
    "config_dict['gamma'] = 0.0\n",
    "\n",
    "config_dict['max_epochs'] = 50\n",
    "config_dict['unfreeze_epoch'] = 210\n",
    "config_dict[\"l2_lambda\"] = 0.0\n",
    "config_dict['embedding_size'] = 50\n",
    "config_dict[\"num_physchem_properties\"] = 200\n",
    "config_dict[\"num_invivo_tasks\"] = 0\n",
    "\n",
    "config_dict['optim'] = 'AdamW'#SGD\n",
    "config_dict['loss_type'] = 'BCE'# Focal_loss\n",
    "\n",
    "config_dict['lr'] = 1e-05\n",
    "config_dict[\"BERT_lr\"] = 3e-5\n",
    "config_dict[\"batch_size\"] = 264\n",
    "config_dict[\"seed\"] = 42\n",
    "\n",
    "\n",
    "\n",
    "config_dict['missing'] = 'nan'\n",
    "config_dict['compute_metric_after_n_epochs'] = 5\n",
    "config_dict['return_trainer'] = True\n",
    "config_dict['EarlyStopping'] = False\n",
    "\n",
    "config_dict[\"accelerator\"] = \"gpu\"\n",
    "config_dict[\"device\"] = torch.device(\"cuda\")\n",
    "\n",
    "\n",
    "data = pd.read_pickle(config_dict['train_file'])\n",
    "data.drop(['SMILES'], axis = 1, inplace = True)\n",
    "target_names = data.columns.tolist()\n",
    "\n",
    "config_dict[\"output_size\"] = len(target_names)\n",
    "config_dict[\"num_invitro_tasks\"] = len(target_names)\n",
    "config_dict[\"num_of_tasks\"] = len(target_names)\n",
    "\n",
    "config_dict[\"label_column\"] = target_names\n",
    "config_dict[\"selected_tasks\"] = target_names\n",
    "config_dict['num_mols'] = data.shape[0]\n",
    "config_dict['max_seq_length'] = 128\n",
    "config_dict['bert_output_dim'] = 768\n",
    "config_dict['invitro_head_hidden_layer'] = 2048\n",
    "\n",
    "config_dict[\"permute\"] = False\n",
    "\n",
    "config_dict['pretrained_model'] = True\n",
    "config_dict['freeze_level'] = False\n",
    "config_dict[\"gpu\"] = -1\n",
    "config_dict[\"precision\"] = 32\n",
    "config_dict[\"distributed_backend\"] = \"dp\"\n",
    "config_dict[\"pretrained_crash_model\"] = None #\"/projects/home/mmasood1/Model_weights/invitro/invitro_1million/MolBERT/Retrain_on_top_of_BERT/complete_1m_300k/invitro_with_PhysChem/epoch=2-val_f1_score=0.00.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "model = SmilesMolbertModel(config_dict)\n",
    "checkpoint = torch.load(config_dict[\"pretrained_model_path\"], map_location=lambda storage, loc: storage)\n",
    "model.load_state_dict(checkpoint['state_dict'], strict = False)\n",
    "model.eval()\n",
    "model.freeze()\n",
    "model = model.to(\"cpu\")\n",
    "\n",
    "featurizer = SmilesIndexFeaturizer.bert_smiles_index_featurizer(126, permute = False)\n",
    "f = MolBertFeaturizer(model = model,\n",
    "                        featurizer= featurizer,\n",
    "                        device = \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 18/640 [00:03<03:01,  3.43it/s]WARNING: SMILES is too long! ['[CLS]', 'N', 'C', 'C', '[', 'C', '@', 'H', ']', '(', 'O', ')', 'C', '(', '=', 'O', ')', 'N', '[', 'C', 'α', 'H', ']', '1', 'C', '[', 'C', '@', 'H', ']', '(', 'N', ')', '[', 'C', 'α', 'H', ']', '(', 'O', '[', 'C', '@', 'H', ']', '2', 'O', '[', 'C', '@', 'H', ']', '(', 'C', 'N', ')', '[', 'C', 'α', 'H', ']', '(', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'O', ')', '[', 'C', '@', 'H', ']', '2', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'O', ')', '[', 'C', '@', 'H', ']', '1', 'O', '[', 'C', '@', 'H', ']', '1', 'O', '[', 'C', '@', 'H', ']', '(', 'C', 'O', ')', '[', 'C', 'α', 'H', ']', '(', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'N', ')', '[', 'C', '@', 'H', ']', '1', 'O', '[SEP]']\n",
      "WARNING: SMILES is too long! ['[CLS]', 'C', '=', 'C', 'C', '[', 'N', 'α', '+', ']', '1', '2', 'C', 'C', '[', 'C', 'α', ']', '3', '4', 'C', '5', '=', 'C', 'C', '=', 'C', 'C', '=', 'C', '5', 'N', '5', '/', 'C', '=', 'C', '6', '/', '[', 'C', '@', 'H', ']', '7', 'C', '[', 'C', '@', 'H', ']', '8', '[', 'C', 'α', ']', '9', '(', 'C', 'C', '[', 'N', 'α', '+', ']', '8', '(', 'C', 'C', '=', 'C', ')', 'C', '/', 'C', '7', '=', 'C', '/', 'C', 'O', ')', 'C', '7', '=', 'C', 'C', '=', 'C', 'C', '=', 'C', '7', 'N', '(', '/', 'C', '=', 'C', '(', '/', '[', 'C', 'α', 'H', ']', '(', 'C', '[', 'C', '@', 'H', ']', '1', '3', ')', '/', 'C', '(', '=', 'C', '\\\\', 'C', 'O', ')', 'C', '2', ')', '[', 'C', 'α', 'H', ']', '4', '5', ')', '[', 'C', 'α', 'H', ']', '6', '9', '[SEP]']\n",
      "  5%|▌         | 32/640 [00:06<02:45,  3.68it/s]WARNING: SMILES is too long! ['[CLS]', 'C', 'N', '[', 'C', 'α', 'H', ']', '1', '[', 'C', '@', 'H', ']', '(', 'O', '[', 'C', '@', 'H', ']', '2', '[', 'C', '@', 'H', ']', '(', 'O', '[', 'C', 'α', 'H', ']', '3', '[', 'C', 'α', 'H', ']', '(', 'N', 'C', '(', '=', 'N', ')', 'N', ')', '[', 'C', '@', 'H', ']', '(', 'O', ')', '[', 'C', 'α', 'H', ']', '(', 'N', 'C', '(', '=', 'N', ')', 'N', ')', '[', 'C', '@', 'H', ']', '(', 'O', ')', '[', 'C', '@', 'H', ']', '3', 'O', ')', 'O', '[', 'C', 'α', 'H', ']', '(', 'C', ')', '[', 'C', '@', ']', '2', '(', 'O', ')', 'C', '=', 'O', ')', 'O', '[', 'C', 'α', 'H', ']', '(', 'C', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'O', ')', '[', 'C', '@', 'H', ']', '1', 'O', '[SEP]']\n",
      "WARNING: SMILES is too long! ['[CLS]', 'C', '[', 'C', 'α', 'H', ']', '1', 'O', '[', 'C', 'α', 'H', ']', '(', 'O', '[', 'C', '@', 'H', ']', '2', 'C', '[', 'C', 'α', 'H', ']', '(', 'O', ')', '[', 'C', '@', ']', '3', '(', 'C', 'O', ')', '[', 'C', '@', 'H', ']', '4', '[', 'C', '@', 'H', ']', '(', 'O', ')', 'C', '[', 'C', '@', ']', '5', '(', 'C', ')', '[', 'C', 'α', 'H', ']', '(', 'C', '6', '=', 'C', 'C', '(', '=', 'O', ')', 'O', 'C', '6', ')', 'C', 'C', '[', 'C', '@', ']', '5', '(', 'O', ')', '[', 'C', 'α', 'H', ']', '4', 'C', 'C', '[', 'C', '@', ']', '3', '(', 'O', ')', 'C', '2', ')', '[', 'C', '@', 'H', ']', '(', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'O', ')', '[', 'C', '@', 'H', ']', '1', 'O', '[SEP]']\n",
      "  5%|▌         | 34/640 [00:06<01:43,  5.85it/s]WARNING: SMILES is too long! ['[CLS]', 'C', '[', 'C', '@', 'H', ']', '1', 'O', '[', 'C', '@', 'H', ']', '(', 'O', '[', 'C', 'α', 'H', ']', '2', '[', 'C', 'α', 'H', ']', '(', 'C', 'O', ')', 'O', '[', 'C', '@', 'H', ']', '(', 'O', '[', 'C', '@', 'H', ']', '(', '[', 'C', '@', 'H', ']', '(', 'O', ')', 'C', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'O', ')', '[', 'C', 'α', 'H', ']', '(', 'O', ')', 'C', '=', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'O', ')', '[', 'C', '@', 'H', ']', '2', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'O', ')', '[', 'C', 'α', 'H', ']', '(', 'O', ')', '[', 'C', 'α', 'H', ']', '1', 'N', '[', 'C', '@', 'H', ']', '1', 'C', '=', 'C', '(', 'C', 'O', ')', '[', 'C', 'α', 'H', ']', '(', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'O', ')', '[', 'C', '@', 'H', ']', '1', 'O', '[SEP]']\n",
      "WARNING: SMILES is too long! ['[CLS]', 'C', '[', 'C', 'α', 'H', ']', '1', 'O', 'C', '(', '=', 'O', ')', 'C', 'C', '(', 'O', ')', 'C', 'C', '(', 'O', ')', 'C', 'C', '(', 'O', ')', 'C', 'C', 'C', '(', 'O', ')', 'C', '(', 'O', ')', 'C', '[', 'C', '@', ']', '2', '(', 'O', ')', 'C', 'C', '(', 'O', ')', 'C', '(', 'C', '(', '=', 'O', ')', 'O', ')', 'C', '(', 'C', 'C', '(', 'O', '[', 'C', '@', 'H', ']', '3', 'O', '[', 'C', '@', 'H', ']', '(', 'C', ')', '[', 'C', 'α', 'H', ']', '(', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'N', ')', '[', 'C', 'α', 'H', ']', '3', 'O', ')', '/', 'C', '=', 'C', '/', 'C', '=', 'C', '/', 'C', '=', 'C', '/', 'C', '=', 'C', '/', 'C', 'C', '/', 'C', '=', 'C', '/', 'C', '=', 'C', '/', '[', 'C', '@', 'H', ']', '(', 'C', ')', '[', 'C', 'α', 'H', ']', '(', 'O', ')', '[', 'C', '@', 'H', ']', '1', 'C', ')', 'O', '2', '[SEP]']\n",
      "  7%|▋         | 44/640 [00:08<02:02,  4.86it/s]WARNING: SMILES is too long! ['[CLS]', 'N', 'C', '[', 'C', 'α', 'H', ']', '1', 'O', '[', 'C', '@', 'H', ']', '(', 'O', '[', 'C', 'α', 'H', ']', '2', '[', 'C', 'α', 'H', ']', '(', 'C', 'O', ')', 'O', '[', 'C', 'α', 'H', ']', '(', 'O', '[', 'C', 'α', 'H', ']', '3', '[', 'C', 'α', 'H', ']', '(', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'N', ')', 'C', '[', 'C', '@', 'H', ']', '(', 'N', ')', '[', 'C', '@', 'H', ']', '3', 'O', '[', 'C', '@', 'H', ']', '3', 'O', '[', 'C', '@', 'H', ']', '(', 'C', 'O', ')', '[', 'C', 'α', 'H', ']', '(', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'O', ')', '[', 'C', '@', 'H', ']', '3', 'N', ')', '[', 'C', 'α', 'H', ']', '2', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'N', ')', '[', 'C', 'α', 'H', ']', '(', 'O', ')', '[', 'C', 'α', 'H', ']', '1', 'O', '[SEP]']\n",
      "WARNING: SMILES is too long! ['[CLS]', 'C', '[', 'C', 'α', 'H', ']', '(', 'O', ')', '[', 'C', 'α', 'H', ']', '1', 'N', 'C', '(', '=', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'C', 'C', 'C', 'C', 'N', ')', 'N', 'C', '(', '=', 'O', ')', '[', 'C', 'α', 'H', ']', '(', 'C', 'C', '2', '=', 'C', 'N', 'C', '3', '=', 'C', 'C', '=', 'C', 'C', '=', 'C', '2', '3', ')', 'N', 'C', '(', '=', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'C', 'C', '2', '=', 'C', 'C', '=', 'C', 'C', '=', 'C', '2', ')', 'N', 'C', '(', '=', 'O', ')', '[', 'C', 'α', 'H', ']', '(', 'N', 'C', '(', '=', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'N', ')', 'C', 'C', '2', '=', 'C', 'C', '=', 'C', 'C', '=', 'C', '2', ')', 'C', 'S', 'S', 'C', '[', 'C', 'α', 'H', ']', '(', 'C', '(', '=', 'O', ')', 'N', '[', 'C', '@', 'H', ']', '(', 'C', 'O', ')', '[', 'C', 'α', 'H', ']', '(', 'C', ')', 'O', ')', 'N', 'C', '1', '=', 'O', '[SEP]']\n",
      " 20%|█▉        | 127/640 [00:22<01:28,  5.82it/s]WARNING: SMILES has forbidden symbol! CCP(CC)(CC)=[Au]S[C@@H]1O[C@H](COC(C)=O)[C@@H](OC(C)=O)[C@H](OC(C)=O)[C@H]1OC(C)=O -> Au\n",
      " 21%|██        | 135/640 [00:24<02:12,  3.80it/s]WARNING: SMILES is too long! ['[CLS]', 'C', 'O', '[', 'C', '@', 'H', ']', '1', '/', 'C', '=', 'C', '/', 'O', '[', 'C', 'α', ']', '2', '(', 'C', ')', 'O', 'C', '3', '=', 'C', '(', 'C', ')', 'C', '(', 'O', ')', '=', 'C', '4', 'C', '(', '=', 'C', '3', 'C', '2', '=', 'O', ')', 'C', '2', '=', 'N', 'C', '3', '(', 'C', 'C', 'N', '(', 'C', 'C', '(', 'C', ')', 'C', ')', 'C', 'C', '3', ')', 'N', 'C', '2', '=', 'C', '(', 'N', 'C', '(', '=', 'O', ')', '/', 'C', '(', 'C', ')', '=', 'C', '\\\\', 'C', '=', 'C', '\\\\', '[', 'C', '@', 'H', ']', '(', 'C', ')', '[', 'C', '@', 'H', ']', '(', 'O', ')', '[', 'C', 'α', 'H', ']', '(', 'C', ')', '[', 'C', 'α', 'H', ']', '(', 'O', ')', '[', 'C', 'α', 'H', ']', '(', 'C', ')', '[', 'C', '@', 'H', ']', '(', 'O', 'C', '(', 'C', ')', '=', 'O', ')', '[', 'C', 'α', 'H', ']', '1', 'C', ')', 'C', '4', '=', 'O', '[SEP]']\n",
      " 22%|██▏       | 142/640 [00:25<01:33,  5.34it/s]WARNING: SMILES is too long! ['[CLS]', 'C', '=', 'C', 'C', '[', 'C', 'α', 'H', ']', '1', '/', 'C', '=', 'C', '(', '\\\\', 'C', ')', 'C', '[', 'C', '@', 'H', ']', '(', 'C', ')', 'C', '[', 'C', '@', 'H', ']', '(', 'O', 'C', ')', '[', 'C', '@', 'H', ']', '2', 'O', '[', 'C', 'α', ']', '(', 'O', ')', '(', 'C', '(', '=', 'O', ')', 'C', '(', '=', 'O', ')', 'N', '3', 'C', 'C', 'C', 'C', '[', 'C', '@', 'H', ']', '3', 'C', '(', '=', 'O', ')', 'O', '[', 'C', '@', 'H', ']', '(', '/', 'C', '(', 'C', ')', '=', 'C', '/', '[', 'C', 'α', 'H', ']', '3', 'C', 'C', '[', 'C', 'α', 'H', ']', '(', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'O', 'C', ')', 'C', '3', ')', '[', 'C', '@', 'H', ']', '(', 'C', ')', '[', 'C', 'α', 'H', ']', '(', 'O', ')', 'C', 'C', '1', '=', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'C', ')', 'C', '[', 'C', 'α', 'H', ']', '2', 'O', 'C', '[SEP]']\n",
      " 33%|███▎      | 209/640 [00:36<01:26,  4.98it/s]WARNING: SMILES is too long! ['[CLS]', 'C', 'C', 'C', '1', '=', 'C', '[', 'C', 'α', 'H', ']', '2', 'C', 'N', '(', 'C', '1', ')', 'C', 'C', '1', '=', 'C', '(', 'N', 'C', '3', '=', 'C', 'C', '=', 'C', 'C', '=', 'C', '1', '3', ')', '[', 'C', 'α', ']', '(', 'C', '(', '=', 'O', ')', 'O', 'C', ')', '(', 'C', '1', '=', 'C', 'C', '3', '=', 'C', '(', 'C', '=', 'C', '1', 'O', 'C', ')', 'N', '(', 'C', ')', '[', 'C', '@', 'H', ']', '1', '[', 'C', 'α', ']', '(', 'O', ')', '(', 'C', '(', '=', 'O', ')', 'O', 'C', ')', '[', 'C', '@', 'H', ']', '(', 'O', 'C', '(', 'C', ')', '=', 'O', ')', '[', 'C', '@', ']', '4', '(', 'C', 'C', ')', 'C', '=', 'C', 'C', 'N', '5', 'C', 'C', '[', 'C', '@', ']', '3', '1', '[', 'C', '@', 'H', ']', '4', '5', ')', 'C', '2', '[SEP]']\n",
      " 33%|███▎      | 211/640 [00:36<01:06,  6.47it/s]WARNING: SMILES is too long! ['[CLS]', 'C', 'C', '[', 'C', '@', 'H', ']', '1', 'O', 'C', '(', '=', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'C', ')', '[', 'C', 'α', 'H', ']', '(', 'O', '[', 'C', '@', 'H', ']', '2', 'C', '[', 'C', 'α', ']', '(', 'C', ')', '(', 'O', 'C', ')', '[', 'C', 'α', 'H', ']', '(', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'C', ')', 'O', '2', ')', '[', 'C', '@', 'H', ']', '(', 'C', ')', '[', 'C', 'α', 'H', ']', '(', 'O', '[', 'C', 'α', 'H', ']', '2', 'O', '[', 'C', '@', 'H', ']', '(', 'C', ')', 'C', '[', 'C', '@', 'H', ']', '(', 'N', '(', 'C', ')', 'C', ')', '[', 'C', '@', 'H', ']', '2', 'O', ')', '[', 'C', '@', ']', '(', 'C', ')', '(', 'O', ')', 'C', '[', 'C', 'α', 'H', ']', '(', 'C', ')', 'C', '(', '=', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'C', ')', '[', 'C', 'α', 'H', ']', '(', 'O', ')', '[', 'C', '@', ']', '1', '(', 'C', ')', 'O', '[SEP]']\n",
      "WARNING: SMILES is too long! ['[CLS]', 'C', 'O', '[', 'C', 'α', 'H', ']', '1', '[', 'C', 'α', 'H', ']', '(', 'O', '[', 'C', 'α', 'H', ']', '2', 'O', '[', 'C', '@', 'H', ']', '(', 'C', ')', '[', 'C', 'α', 'H', ']', '(', 'O', '[', 'C', '@', 'H', ']', '3', 'C', '[', 'C', 'α', ']', '(', 'C', ')', '(', 'O', ')', '[', 'C', 'α', 'H', ']', '(', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'C', ')', 'O', '3', ')', '[', 'C', '@', 'H', ']', '(', 'N', '(', 'C', ')', 'C', ')', '[', 'C', '@', 'H', ']', '2', 'O', ')', '[', 'C', 'α', 'H', ']', '(', 'C', 'C', '=', 'O', ')', 'C', '[', 'C', 'α', 'H', ']', '(', 'C', ')', '[', 'C', 'α', 'H', ']', '(', 'O', '[', 'C', '@', 'H', ']', '2', 'C', 'C', '[', 'C', '@', 'H', ']', '(', 'N', '(', 'C', ')', 'C', ')', '[', 'C', '@', 'H', ']', '(', 'C', ')', 'O', '2', ')', '/', 'C', '=', 'C', '/', 'C', '=', 'C', '/', 'C', '[', 'C', 'α', 'H', ']', '(', 'C', ')', 'O', 'C', '(', '=', 'O', ')', 'C', '[', 'C', '@', 'H', ']', '1', 'O', '[SEP]']\n",
      " 49%|████▊     | 311/640 [00:52<00:52,  6.31it/s]WARNING: SMILES is too long! ['[CLS]', 'C', 'C', '[', 'C', '@', 'H', ']', '1', 'O', 'C', '(', '=', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'C', ')', 'C', '(', '=', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'C', ')', '[', 'C', 'α', 'H', ']', '(', 'O', '[', 'C', 'α', 'H', ']', '2', 'O', '[', 'C', '@', 'H', ']', '(', 'C', ')', 'C', '[', 'C', '@', 'H', ']', '(', 'N', '(', 'C', ')', 'C', ')', '[', 'C', '@', 'H', ']', '2', 'O', ')', '[', 'C', '@', ']', '(', 'C', ')', '(', 'O', 'C', ')', 'C', '[', 'C', 'α', 'H', ']', '(', 'C', ')', 'C', '(', '=', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'C', ')', '[', 'C', '@', 'H', ']', '2', 'N', '(', 'C', 'C', 'C', 'C', 'N', '3', 'C', '=', 'N', 'C', '(', 'C', '4', '=', 'C', 'C', '=', 'C', 'N', '=', 'C', '4', ')', '=', 'C', '3', ')', 'C', '(', '=', 'O', ')', 'O', '[', 'C', '@', ']', '1', '2', 'C', '[SEP]']\n",
      " 71%|███████   | 455/640 [01:15<00:25,  7.37it/s]WARNING: SMILES is too long! ['[CLS]', 'N', '[', 'C', 'α', 'H', ']', '1', 'C', 'N', '(', 'C', '2', '=', 'C', '(', 'F', ')', 'C', '=', 'C', '3', 'C', '(', '=', 'O', ')', 'C', '(', 'C', '(', '=', 'O', ')', 'O', ')', '=', 'C', 'N', '(', '[', 'C', 'α', 'H', ']', '4', 'C', '[', 'C', 'α', 'H', ']', '4', 'F', ')', 'C', '3', '=', 'C', '2', 'χ', ')', 'C', 'C', '1', '2', 'C', 'C', '2', '.', 'N', '[', 'C', 'α', 'H', ']', '1', 'C', 'N', '(', 'C', '2', '=', 'C', '(', 'F', ')', 'C', '=', 'C', '3', 'C', '(', '=', 'O', ')', 'C', '(', 'C', '(', '=', 'O', ')', 'O', ')', '=', 'C', 'N', '(', '[', 'C', 'α', 'H', ']', '4', 'C', '[', 'C', 'α', 'H', ']', '4', 'F', ')', 'C', '3', '=', 'C', '2', 'χ', ')', 'C', 'C', '1', '2', 'C', 'C', '2', '.', 'O', '.', 'O', '.', 'O', '[SEP]']\n",
      " 76%|███████▌  | 485/640 [01:20<00:30,  5.12it/s]WARNING: SMILES is too long! ['[CLS]', 'C', '[', 'C', '@', 'H', ']', '1', 'O', '[', 'C', 'α', 'H', ']', '(', 'O', '[', 'C', '@', 'H', ']', '2', '[', 'C', 'α', 'H', ']', '(', 'O', ')', 'C', '[', 'C', '@', 'H', ']', '(', 'O', '[', 'C', '@', 'H', ']', '3', '[', 'C', 'α', 'H', ']', '(', 'O', ')', 'C', '[', 'C', '@', 'H', ']', '(', 'O', '[', 'C', '@', 'H', ']', '4', 'C', 'C', '[', 'C', '@', ']', '5', '(', 'C', ')', '[', 'C', '@', 'H', ']', '6', 'C', 'C', '[', 'C', '@', ']', '7', '(', 'C', ')', '[', 'C', 'α', 'H', ']', '(', 'C', '8', '=', 'C', 'C', '(', '=', 'O', ')', 'O', 'C', '8', ')', 'C', 'C', '[', 'C', '@', ']', '7', '(', 'O', ')', '[', 'C', 'α', 'H', ']', '6', 'C', 'C', '[', 'C', 'α', 'H', ']', '5', 'C', '4', ')', 'O', '[', 'C', 'α', 'H', ']', '3', 'C', ')', 'O', '[', 'C', 'α', 'H', ']', '2', 'C', ')', 'C', '[', 'C', '@', 'H', ']', '(', 'O', ')', '[', 'C', 'α', 'H', ']', '1', 'O', '[SEP]']\n",
      " 78%|███████▊  | 497/640 [01:22<00:24,  5.87it/s]WARNING: SMILES is too long! ['[CLS]', 'C', 'C', '[', 'C', '@', 'H', ']', '1', 'O', 'C', '(', '=', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'C', ')', '[', 'C', 'α', 'H', ']', '(', 'O', '[', 'C', '@', 'H', ']', '2', 'C', '[', 'C', 'α', ']', '(', 'C', ')', '(', 'O', 'C', ')', '[', 'C', 'α', 'H', ']', '(', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'C', ')', 'O', '2', ')', '[', 'C', '@', 'H', ']', '(', 'C', ')', '[', 'C', 'α', 'H', ']', '(', 'O', '[', 'C', 'α', 'H', ']', '2', 'O', '[', 'C', '@', 'H', ']', '(', 'C', ')', 'C', '[', 'C', '@', 'H', ']', '(', 'N', '(', 'C', ')', 'C', ')', '[', 'C', '@', 'H', ']', '2', 'O', ')', '[', 'C', '@', ']', '(', 'C', ')', '(', 'O', ')', 'C', '[', 'C', 'α', 'H', ']', '(', 'C', ')', 'C', '(', '=', 'N', 'O', 'C', 'O', 'C', 'C', 'O', 'C', ')', '[', 'C', '@', 'H', ']', '(', 'C', ')', '[', 'C', 'α', 'H', ']', '(', 'O', ')', '[', 'C', '@', ']', '1', '(', 'C', ')', 'O', '[SEP]']\n",
      " 91%|█████████▏| 585/640 [01:35<00:11,  4.80it/s]WARNING: SMILES is too long! ['[CLS]', 'C', 'C', '[', 'C', '@', 'H', ']', '1', 'O', 'C', '(', '=', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'C', ')', '[', 'C', 'α', 'H', ']', '(', 'O', '[', 'C', '@', 'H', ']', '2', 'C', '[', 'C', 'α', ']', '(', 'C', ')', '(', 'O', 'C', ')', '[', 'C', 'α', 'H', ']', '(', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'C', ')', 'O', '2', ')', '[', 'C', '@', 'H', ']', '(', 'C', ')', '[', 'C', 'α', 'H', ']', '(', 'O', '[', 'C', 'α', 'H', ']', '2', 'O', '[', 'C', '@', 'H', ']', '(', 'C', ')', 'C', '[', 'C', '@', 'H', ']', '(', 'N', '(', 'C', ')', 'C', ')', '[', 'C', '@', 'H', ']', '2', 'O', ')', '[', 'C', '@', ']', '(', 'C', ')', '(', 'O', ')', 'C', '[', 'C', 'α', 'H', ']', '(', 'C', ')', '[', 'C', 'α', 'H', ']', '2', 'N', '[', 'C', 'α', 'H', ']', '(', 'C', 'O', 'C', 'C', 'O', 'C', ')', 'O', '[', 'C', '@', 'H', ']', '(', '[', 'C', '@', 'H', ']', '2', 'C', ')', '[', 'C', '@', ']', '1', '(', 'C', ')', 'O', '[SEP]']\n",
      " 93%|█████████▎| 598/640 [01:37<00:06,  6.85it/s]WARNING: SMILES is too long! ['[CLS]', 'C', 'C', '[', 'C', '@', 'H', ']', '1', 'O', 'C', '(', '=', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'C', ')', '[', 'C', 'α', 'H', ']', '(', 'O', '[', 'C', '@', 'H', ']', '2', 'C', '[', 'C', 'α', ']', '(', 'C', ')', '(', 'O', 'C', ')', '[', 'C', 'α', 'H', ']', '(', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'C', ')', 'O', '2', ')', '[', 'C', '@', 'H', ']', '(', 'C', ')', '[', 'C', 'α', 'H', ']', '(', 'O', '[', 'C', 'α', 'H', ']', '2', 'O', '[', 'C', '@', 'H', ']', '(', 'C', ')', 'C', '[', 'C', '@', 'H', ']', '(', 'N', '(', 'C', ')', 'C', ')', '[', 'C', '@', 'H', ']', '2', 'O', ')', '[', 'C', '@', ']', '(', 'C', ')', '(', 'O', ')', 'C', '[', 'C', 'α', 'H', ']', '(', 'C', ')', 'C', 'N', '(', 'C', ')', '[', 'C', '@', 'H', ']', '(', 'C', ')', '[', 'C', 'α', 'H', ']', '(', 'O', ')', '[', 'C', '@', ']', '1', '(', 'C', ')', 'O', '[SEP]']\n",
      " 95%|█████████▌| 608/640 [01:38<00:07,  4.55it/s]WARNING: SMILES is too long! ['[CLS]', 'C', 'C', '[', 'C', '@', 'H', ']', '1', 'O', 'C', '(', '=', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'C', ')', '[', 'C', 'α', 'H', ']', '(', 'O', '[', 'C', '@', 'H', ']', '2', 'C', '[', 'C', 'α', ']', '(', 'C', ')', '(', 'O', 'C', ')', '[', 'C', 'α', 'H', ']', '(', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'C', ')', 'O', '2', ')', '[', 'C', '@', 'H', ']', '(', 'C', ')', '[', 'C', 'α', 'H', ']', '(', 'O', '[', 'C', 'α', 'H', ']', '2', 'O', '[', 'C', '@', 'H', ']', '(', 'C', ')', 'C', '[', 'C', '@', 'H', ']', '(', 'N', '(', 'C', ')', 'C', ')', '[', 'C', '@', 'H', ']', '2', 'O', ')', '[', 'C', '@', ']', '(', 'C', ')', '(', 'O', 'C', ')', 'C', '[', 'C', 'α', 'H', ']', '(', 'C', ')', 'C', '(', '=', 'O', ')', '[', 'C', '@', 'H', ']', '(', 'C', ')', '[', 'C', 'α', 'H', ']', '(', 'O', ')', '[', 'C', '@', ']', '1', '(', 'C', ')', 'O', '[SEP]']\n",
      " 96%|█████████▋| 617/640 [01:40<00:05,  4.38it/s]WARNING: SMILES is too long! ['[CLS]', 'C', '[', 'C', '@', 'H', ']', '1', 'O', '[', 'C', 'α', 'H', ']', '(', 'O', '[', 'C', '@', 'H', ']', '2', '[', 'C', 'α', 'H', ']', '(', 'O', ')', 'C', '[', 'C', '@', 'H', ']', '(', 'O', '[', 'C', '@', 'H', ']', '3', '[', 'C', 'α', 'H', ']', '(', 'O', ')', 'C', '[', 'C', '@', 'H', ']', '(', 'O', '[', 'C', '@', 'H', ']', '4', 'C', 'C', '[', 'C', '@', ']', '5', '(', 'C', ')', '[', 'C', '@', 'H', ']', '6', 'C', '[', 'C', 'α', 'H', ']', '(', 'O', ')', '[', 'C', '@', ']', '7', '(', 'C', ')', '[', 'C', 'α', 'H', ']', '(', 'C', '8', '=', 'C', 'C', '(', '=', 'O', ')', 'O', 'C', '8', ')', 'C', 'C', '[', 'C', '@', ']', '7', '(', 'O', ')', '[', 'C', 'α', 'H', ']', '6', 'C', 'C', '[', 'C', 'α', 'H', ']', '5', 'C', '4', ')', 'O', '[', 'C', 'α', 'H', ']', '3', 'C', ')', 'O', '[', 'C', 'α', 'H', ']', '2', 'C', ')', 'C', '[', 'C', '@', 'H', ']', '(', 'O', ')', '[', 'C', 'α', 'H', ']', '1', 'O', '[SEP]']\n",
      "100%|██████████| 640/640 [01:43<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bioavailability_ma 22\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from molbert.utils.featurizer.molbert_featurizer import MolBertFeaturizer\n",
    "\n",
    "def get_BERT_features(featurizer, data, SMILES_col = \"SMILES\"):\n",
    "    SMILES = data[SMILES_col].tolist()\n",
    "    features_all, masks_all = [],[]\n",
    "    for s in tqdm(SMILES):\n",
    "        features, masks = featurizer.transform([s])\n",
    "        features_all.append(features.squeeze())\n",
    "        masks_all.append(masks)\n",
    "\n",
    "    filtered = [mask[0] for mask in masks_all]\n",
    "    features = pd.DataFrame(features_all)\n",
    "    features = features[filtered]\n",
    "\n",
    "    selected_SMILES = data[filtered][SMILES_col].values\n",
    "    features.insert(0,\"SMILES\", selected_SMILES)\n",
    "    filtered_data = data[data[SMILES_col].isin(selected_SMILES)].reset_index(drop = True)\n",
    "\n",
    "    return filtered_data, features\n",
    "\n",
    "def read_file(file_path):\n",
    "    _, file_extension = os.path.splitext(file_path)\n",
    "    if file_extension.lower() == '.parquet':\n",
    "        return pd.read_parquet(file_path)\n",
    "    elif file_extension.lower() == '.tab':\n",
    "        return pd.read_csv(file_path, sep='\\t')\n",
    "    else:\n",
    "        return pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "def calculate_pos_ratio(filtered_data, Target_colmn):\n",
    "    \"\"\"\n",
    "    Calculate class weights based on the imbalance in the target variable \n",
    "    and save the results to a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        filtered_data (DataFrame): DataFrame \n",
    "        Target (str): target variable\n",
    "        \n",
    "    Returns:\n",
    "        datadrame: The calculated class weight (ratio of negative to positive samples)\n",
    "    \"\"\"\n",
    "    pos = (filtered_data[Target_colmn] == 1).sum()\n",
    "    neg = (filtered_data[Target_colmn] == 0).sum()\n",
    "    class_weight = neg/pos\n",
    "    \n",
    "    class_weight_df = pd.DataFrame({\n",
    "        \"Targets\": [Target_colmn],\n",
    "        \"weights\": [class_weight]\n",
    "    })\n",
    "        \n",
    "    return class_weight_df\n",
    "\n",
    "\n",
    "path_to_checkpoint = '/scratch/cs/pml/AI_drug/molbert_100epochs/checkpoints/last.ckpt'\n",
    "data_dir = \"/scratch/work/masooda1/datasets/datasets_for_active_learning/raw_data/TDC_ADME/\"\n",
    "filtered_data_dir = \"/scratch/work/masooda1/datasets/datasets_for_active_learning/filtered_data/TDC_ADME/\"\n",
    "feature_dir = \"/scratch/work/masooda1/datasets/datasets_for_active_learning/MolBERT_features/\"\n",
    "\n",
    "dataset = \"bioavailability_ma\"\n",
    "data = read_file(data_dir + f\"{dataset}.tab\")\n",
    "total_mol = data.shape[0]\n",
    "\n",
    "featurizer = MolBertFeaturizer(path_to_checkpoint)\n",
    "filtered_data, features = get_BERT_features(featurizer, data, SMILES_col = \"Drug\")\n",
    "calculate_class_weights(filtered_data, Target_colmn)\n",
    "\n",
    "filtered_mol = filtered_data.shape[0]\n",
    "removed_mols = total_mol - filtered_mol\n",
    "print(dataset, removed_mols)\n",
    "filtered_data.to_csv(filtered_data_dir + f\"{dataset}_filtered.csv\", index = False)\n",
    "features.to_csv(feature_dir + f\"MolBERT_{dataset}.csv\", index = False)\n",
    "\n",
    "class_weight_df.to_csv(filtered_data_dir + f\"{}_pos_ratio.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drug_ID</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dimercaprol</td>\n",
       "      <td>OCC(S)CS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Edrophonium</td>\n",
       "      <td>CC[N+](C)(C)c1cccc(O)c1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carbimazole</td>\n",
       "      <td>CCOC(=O)n1ccn(C)c1=S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vidarabine</td>\n",
       "      <td>Nc1ncnc2c1ncn2[C@@H]1O[C@H](CO)[C@@H](O)[C@@H]1O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cefacetrile</td>\n",
       "      <td>CC(=O)OCC1=C(C(=O)O)N2C(=O)[C@@H](NC(=O)CC#N)[...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>Cyclopenthiazide</td>\n",
       "      <td>NS(=O)(=O)c1cc2c(cc1Cl)NC(CC1CCCC1)NS2(=O)=O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>Sulfinpyrazone</td>\n",
       "      <td>O=C1C(CCS(=O)c2ccccc2)C(=O)N(c2ccccc2)N1c1ccccc1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>Toremifene</td>\n",
       "      <td>CN(C)CCOc1ccc(/C(=C(/CCCl)c2ccccc2)c2ccccc2)cc1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>Tamsulosin</td>\n",
       "      <td>CCOc1ccccc1OCCN[C@H](C)Cc1ccc(OC)c(S(N)(=O)=O)c1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Glimepiride</td>\n",
       "      <td>CCC1=C(C)CN(C(=O)NCCc2ccc(S(=O)(=O)NC(=O)N[C@H...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>618 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Drug_ID                                               Drug  Y\n",
       "0         Dimercaprol                                           OCC(S)CS  0\n",
       "1         Edrophonium                            CC[N+](C)(C)c1cccc(O)c1  0\n",
       "2         Carbimazole                               CCOC(=O)n1ccn(C)c1=S  0\n",
       "3          Vidarabine   Nc1ncnc2c1ncn2[C@@H]1O[C@H](CO)[C@@H](O)[C@@H]1O  0\n",
       "4         Cefacetrile  CC(=O)OCC1=C(C(=O)O)N2C(=O)[C@@H](NC(=O)CC#N)[...  0\n",
       "..                ...                                                ... ..\n",
       "613  Cyclopenthiazide       NS(=O)(=O)c1cc2c(cc1Cl)NC(CC1CCCC1)NS2(=O)=O  1\n",
       "614    Sulfinpyrazone   O=C1C(CCS(=O)c2ccccc2)C(=O)N(c2ccccc2)N1c1ccccc1  1\n",
       "615        Toremifene    CN(C)CCOc1ccc(/C(=C(/CCCl)c2ccccc2)c2ccccc2)cc1  1\n",
       "616        Tamsulosin   CCOc1ccccc1OCCN[C@H](C)Cc1ccc(OC)c(S(N)(=O)=O)c1  1\n",
       "617       Glimepiride  CCC1=C(C)CN(C(=O)NCCc2ccc(S(=O)(=O)NC(=O)N[C@H...  1\n",
       "\n",
       "[618 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bioavailability_ma 0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OCC(S)CS</td>\n",
       "      <td>-0.982734</td>\n",
       "      <td>0.848309</td>\n",
       "      <td>-0.921475</td>\n",
       "      <td>0.949607</td>\n",
       "      <td>-0.998771</td>\n",
       "      <td>-0.923095</td>\n",
       "      <td>0.885812</td>\n",
       "      <td>0.624191</td>\n",
       "      <td>0.027640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110528</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.986588</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>-0.705917</td>\n",
       "      <td>-0.849627</td>\n",
       "      <td>-0.960012</td>\n",
       "      <td>-0.999314</td>\n",
       "      <td>-0.711235</td>\n",
       "      <td>-0.030310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC[N+](C)(C)c1cccc(O)c1</td>\n",
       "      <td>-0.982225</td>\n",
       "      <td>0.519028</td>\n",
       "      <td>0.340046</td>\n",
       "      <td>0.716479</td>\n",
       "      <td>-0.246718</td>\n",
       "      <td>-0.938469</td>\n",
       "      <td>0.948774</td>\n",
       "      <td>0.912588</td>\n",
       "      <td>-0.695798</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.788338</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.998083</td>\n",
       "      <td>-0.999999</td>\n",
       "      <td>-0.084001</td>\n",
       "      <td>0.753900</td>\n",
       "      <td>-0.755501</td>\n",
       "      <td>-0.988283</td>\n",
       "      <td>-0.476534</td>\n",
       "      <td>0.714702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCOC(=O)n1ccn(C)c1=S</td>\n",
       "      <td>-0.986138</td>\n",
       "      <td>0.825191</td>\n",
       "      <td>-0.978962</td>\n",
       "      <td>0.897290</td>\n",
       "      <td>-0.998916</td>\n",
       "      <td>0.703462</td>\n",
       "      <td>0.910829</td>\n",
       "      <td>0.992432</td>\n",
       "      <td>0.901813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.728068</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.665891</td>\n",
       "      <td>-0.999960</td>\n",
       "      <td>-0.450319</td>\n",
       "      <td>-0.970705</td>\n",
       "      <td>0.995784</td>\n",
       "      <td>-0.999726</td>\n",
       "      <td>-0.994421</td>\n",
       "      <td>0.129221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nc1ncnc2c1ncn2[C@@H]1O[C@H](CO)[C@@H](O)[C@@H]1O</td>\n",
       "      <td>-0.856800</td>\n",
       "      <td>-0.284698</td>\n",
       "      <td>-0.656422</td>\n",
       "      <td>0.019128</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.762067</td>\n",
       "      <td>0.724670</td>\n",
       "      <td>0.030319</td>\n",
       "      <td>-0.582399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968568</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.646429</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>-0.548410</td>\n",
       "      <td>-0.564102</td>\n",
       "      <td>0.770477</td>\n",
       "      <td>-0.999977</td>\n",
       "      <td>-0.733871</td>\n",
       "      <td>0.975677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC(=O)OCC1=C(C(=O)O)N2C(=O)[C@@H](NC(=O)CC#N)[...</td>\n",
       "      <td>-0.987431</td>\n",
       "      <td>-0.966861</td>\n",
       "      <td>-0.956801</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.871447</td>\n",
       "      <td>0.954912</td>\n",
       "      <td>0.419545</td>\n",
       "      <td>-0.275023</td>\n",
       "      <td>0.787494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.615684</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.999787</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>-0.231133</td>\n",
       "      <td>-0.817853</td>\n",
       "      <td>-0.993000</td>\n",
       "      <td>-0.999924</td>\n",
       "      <td>-0.952184</td>\n",
       "      <td>-0.622154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>N=C(N)c1ccc(OCCCCCOc2ccc(C(=N)N)cc2)cc1</td>\n",
       "      <td>-0.909490</td>\n",
       "      <td>-0.979202</td>\n",
       "      <td>0.808468</td>\n",
       "      <td>0.935827</td>\n",
       "      <td>-0.643323</td>\n",
       "      <td>-0.849210</td>\n",
       "      <td>0.900343</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>-0.999444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089876</td>\n",
       "      <td>-0.999887</td>\n",
       "      <td>0.286485</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>-0.693791</td>\n",
       "      <td>0.893253</td>\n",
       "      <td>0.662472</td>\n",
       "      <td>-0.999360</td>\n",
       "      <td>0.672680</td>\n",
       "      <td>0.962841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)O)=CCS[C@H]...</td>\n",
       "      <td>-0.894888</td>\n",
       "      <td>-0.866015</td>\n",
       "      <td>-0.757785</td>\n",
       "      <td>0.999133</td>\n",
       "      <td>-0.328172</td>\n",
       "      <td>0.993707</td>\n",
       "      <td>-0.269381</td>\n",
       "      <td>-0.844655</td>\n",
       "      <td>0.793876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.862854</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.979117</td>\n",
       "      <td>0.999754</td>\n",
       "      <td>-0.772005</td>\n",
       "      <td>-0.576307</td>\n",
       "      <td>-0.991578</td>\n",
       "      <td>-0.031343</td>\n",
       "      <td>-0.950125</td>\n",
       "      <td>-0.365132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C[C@@H](O)[C@H]1C(=O)N2C(C(=O)O)=C(S[C@@H]3CN[...</td>\n",
       "      <td>0.660690</td>\n",
       "      <td>-0.995381</td>\n",
       "      <td>-0.162095</td>\n",
       "      <td>0.964911</td>\n",
       "      <td>0.577584</td>\n",
       "      <td>0.922075</td>\n",
       "      <td>-0.855180</td>\n",
       "      <td>-0.163378</td>\n",
       "      <td>-0.792020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.780317</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.931471</td>\n",
       "      <td>0.210391</td>\n",
       "      <td>-0.477027</td>\n",
       "      <td>0.409919</td>\n",
       "      <td>-0.999064</td>\n",
       "      <td>-0.999765</td>\n",
       "      <td>-0.627187</td>\n",
       "      <td>-0.139096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CC1(C)S[C@@H]2[C@H](NC(=O)[C@H](C(=O)O)c3ccsc3...</td>\n",
       "      <td>-0.436668</td>\n",
       "      <td>-0.883686</td>\n",
       "      <td>-0.705088</td>\n",
       "      <td>0.997300</td>\n",
       "      <td>0.592046</td>\n",
       "      <td>0.860182</td>\n",
       "      <td>-0.598569</td>\n",
       "      <td>-0.117729</td>\n",
       "      <td>-0.816496</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.670150</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.938205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.187567</td>\n",
       "      <td>-0.822262</td>\n",
       "      <td>-0.999983</td>\n",
       "      <td>-0.999745</td>\n",
       "      <td>-0.969430</td>\n",
       "      <td>-0.756884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CO[C@@]1(NC(=O)Cc2cccs2)C(=O)N2C(C(=O)O)=C(COC...</td>\n",
       "      <td>-0.831305</td>\n",
       "      <td>-0.972520</td>\n",
       "      <td>-0.383772</td>\n",
       "      <td>0.999252</td>\n",
       "      <td>0.738344</td>\n",
       "      <td>0.992211</td>\n",
       "      <td>0.023769</td>\n",
       "      <td>0.723053</td>\n",
       "      <td>0.764997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.836636</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.979651</td>\n",
       "      <td>0.999884</td>\n",
       "      <td>-0.784295</td>\n",
       "      <td>-0.981081</td>\n",
       "      <td>-0.991425</td>\n",
       "      <td>-0.979319</td>\n",
       "      <td>0.729581</td>\n",
       "      <td>0.588499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              SMILES         0         1  \\\n",
       "0                                           OCC(S)CS -0.982734  0.848309   \n",
       "1                            CC[N+](C)(C)c1cccc(O)c1 -0.982225  0.519028   \n",
       "2                               CCOC(=O)n1ccn(C)c1=S -0.986138  0.825191   \n",
       "3   Nc1ncnc2c1ncn2[C@@H]1O[C@H](CO)[C@@H](O)[C@@H]1O -0.856800 -0.284698   \n",
       "4  CC(=O)OCC1=C(C(=O)O)N2C(=O)[C@@H](NC(=O)CC#N)[... -0.987431 -0.966861   \n",
       "5            N=C(N)c1ccc(OCCCCCOc2ccc(C(=N)N)cc2)cc1 -0.909490 -0.979202   \n",
       "6  CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)O)=CCS[C@H]... -0.894888 -0.866015   \n",
       "7  C[C@@H](O)[C@H]1C(=O)N2C(C(=O)O)=C(S[C@@H]3CN[...  0.660690 -0.995381   \n",
       "8  CC1(C)S[C@@H]2[C@H](NC(=O)[C@H](C(=O)O)c3ccsc3... -0.436668 -0.883686   \n",
       "9  CO[C@@]1(NC(=O)Cc2cccs2)C(=O)N2C(C(=O)O)=C(COC... -0.831305 -0.972520   \n",
       "\n",
       "          2         3         4         5         6         7         8  ...  \\\n",
       "0 -0.921475  0.949607 -0.998771 -0.923095  0.885812  0.624191  0.027640  ...   \n",
       "1  0.340046  0.716479 -0.246718 -0.938469  0.948774  0.912588 -0.695798  ...   \n",
       "2 -0.978962  0.897290 -0.998916  0.703462  0.910829  0.992432  0.901813  ...   \n",
       "3 -0.656422  0.019128  0.999955  0.762067  0.724670  0.030319 -0.582399  ...   \n",
       "4 -0.956801  0.977592  0.871447  0.954912  0.419545 -0.275023  0.787494  ...   \n",
       "5  0.808468  0.935827 -0.643323 -0.849210  0.900343  0.999968 -0.999444  ...   \n",
       "6 -0.757785  0.999133 -0.328172  0.993707 -0.269381 -0.844655  0.793876  ...   \n",
       "7 -0.162095  0.964911  0.577584  0.922075 -0.855180 -0.163378 -0.792020  ...   \n",
       "8 -0.705088  0.997300  0.592046  0.860182 -0.598569 -0.117729 -0.816496  ...   \n",
       "9 -0.383772  0.999252  0.738344  0.992211  0.023769  0.723053  0.764997  ...   \n",
       "\n",
       "        758       759       760       761       762       763       764  \\\n",
       "0 -0.110528 -1.000000 -0.986588  0.999988 -0.705917 -0.849627 -0.960012   \n",
       "1 -0.788338 -1.000000  0.998083 -0.999999 -0.084001  0.753900 -0.755501   \n",
       "2  0.728068 -1.000000 -0.665891 -0.999960 -0.450319 -0.970705  0.995784   \n",
       "3  0.968568 -1.000000  0.646429  0.999996 -0.548410 -0.564102  0.770477   \n",
       "4  0.615684 -1.000000  0.999787  0.999997 -0.231133 -0.817853 -0.993000   \n",
       "5  0.089876 -0.999887  0.286485  0.999980 -0.693791  0.893253  0.662472   \n",
       "6  0.862854 -1.000000  0.979117  0.999754 -0.772005 -0.576307 -0.991578   \n",
       "7  0.780317 -1.000000  0.931471  0.210391 -0.477027  0.409919 -0.999064   \n",
       "8 -0.670150 -1.000000  0.938205  1.000000  0.187567 -0.822262 -0.999983   \n",
       "9 -0.836636 -1.000000  0.979651  0.999884 -0.784295 -0.981081 -0.991425   \n",
       "\n",
       "        765       766       767  \n",
       "0 -0.999314 -0.711235 -0.030310  \n",
       "1 -0.988283 -0.476534  0.714702  \n",
       "2 -0.999726 -0.994421  0.129221  \n",
       "3 -0.999977 -0.733871  0.975677  \n",
       "4 -0.999924 -0.952184 -0.622154  \n",
       "5 -0.999360  0.672680  0.962841  \n",
       "6 -0.031343 -0.950125 -0.365132  \n",
       "7 -0.999765 -0.627187 -0.139096  \n",
       "8 -0.999745 -0.969430 -0.756884  \n",
       "9 -0.979319  0.729581  0.588499  \n",
       "\n",
       "[10 rows x 769 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Drug'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4172637/814282356.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSMILES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDrug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/work/masooda1/.conda_envs/molbert/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Drug'"
     ]
    }
   ],
   "source": [
    "SMILES = data.Drug.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_BERT_features(data):\n",
    "    SMILES = data.Normalized_SMILES.tolist()\n",
    "    features_all, masks_all = [],[]\n",
    "    for s in tqdm(SMILES):\n",
    "        features, masks = f.transform([s])\n",
    "        features_all.append(features.squeeze())\n",
    "        masks_all.append(masks)\n",
    "\n",
    "    filtered = [mask[0] for mask in masks_all]\n",
    "    features = pd.DataFrame(features_all)\n",
    "    features = features[filtered]\n",
    "\n",
    "    selected_SMILES = data[filtered].Normalized_SMILES.values\n",
    "    features.insert(0,\"SMILES\", selected_SMILES)\n",
    "    filtered_data = data[data.Normalized_SMILES.isin(selected_SMILES)].reset_index(drop = True)\n",
    "    filtered_data.drop(\"SMILES\", axis = 1, inplace = True)\n",
    "    filtered_data.rename(columns = {\"Normalized_SMILES\":\"SMILES\"}, inplace = True)\n",
    "    return filtered_data, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/322 [00:00<01:39,  3.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 322/322 [00:51<00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 train 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:06<00:00,  8.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 valid 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [00:16<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [00:49<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 train 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:07<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 valid 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [00:16<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 test 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [00:49<00:00,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 train 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:07<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 valid 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [00:16<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 test 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [00:49<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 train 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:07<00:00,  6.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 valid 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [00:16<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 test 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [00:48<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 train 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:08<00:00,  5.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 valid 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [00:16<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 test 2\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/projects/home/mmasood1/arslan_data_repository/DILI\"\n",
    "dataset_list = [\"train\",\"valid\",\"test\"]\n",
    "\n",
    "for seed in [1, 2, 3, 4, 5]:\n",
    "    for dataset in dataset_list:\n",
    "\n",
    "        # relevent dirs\n",
    "        seed_dir = data_dir + f\"/seed_{seed}/\"\n",
    "        normlization_dir = seed_dir + \"normalized_data/\"\n",
    "        filtered_data_dir = normlization_dir + \"filtered_data/\"\n",
    "\n",
    "        os.makedirs(filtered_data_dir, exist_ok = True)\n",
    "\n",
    "        data = pd.read_csv(normlization_dir + f\"{dataset}_seed_{seed}.csv\")\n",
    "        total_mol = data.shape[0]\n",
    "\n",
    "        filtered_data, features = get_BERT_features(data)\n",
    "        filtered_mol = filtered_data.shape[0]\n",
    "        removed_mols = total_mol - filtered_mol\n",
    "        print(seed, dataset, removed_mols)\n",
    "        filtered_data.to_csv(filtered_data_dir + f\"{dataset}_filtered_seed_{seed}.csv\", index = False)\n",
    "        features.to_csv(filtered_data_dir + f\"{dataset}_DILI_BERT_features_seed_{seed}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute pos_weights\n",
    "data_dir = \"/projects/home/mmasood1/arslan_data_repository/DILI\"\n",
    "\n",
    "for seed in [1,2,3,4,5]:\n",
    "\n",
    "    # relevent dirs\n",
    "    seed_dir = data_dir + f\"/seed_{seed}/\"\n",
    "    normlization_dir = seed_dir + \"normalized_data/\"\n",
    "    filtered_data_dir = normlization_dir + \"filtered_data/\"\n",
    "\n",
    "    train = pd.read_csv(filtered_data_dir + f\"train_filtered_seed_{seed}.csv\")\n",
    "    valid = pd.read_csv(filtered_data_dir + f\"valid_filtered_seed_{seed}.csv\")\n",
    "    test = pd.read_csv(filtered_data_dir + f\"test_filtered_seed_{seed}.csv\")\n",
    "    all_data = pd.concat([train, valid, test], axis = 0)\n",
    "    pos = (all_data.Y == 1).sum()\n",
    "    neg = (all_data.Y == 0).sum()\n",
    "    class_weight = neg/pos\n",
    "    class_weight = pd.DataFrame({\"Targets\":\"Y\",\n",
    "                \"weights\":[class_weight]})\n",
    "    class_weight.to_csv(filtered_data_dir + f\"class_weight_seed_{seed}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Targets</th>\n",
       "      <th>weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y</td>\n",
       "      <td>0.982833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Targets   weights\n",
       "0       Y  0.982833"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Targets</th>\n",
       "      <th>weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NR-AR</td>\n",
       "      <td>22.511327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NR-AR-LBD</td>\n",
       "      <td>27.514768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NR-AhR</td>\n",
       "      <td>7.527344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NR-Aromatase</td>\n",
       "      <td>18.403333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NR-ER</td>\n",
       "      <td>6.809584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NR-ER-LBD</td>\n",
       "      <td>18.871429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NR-PPAR-gamma</td>\n",
       "      <td>33.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SR-ARE</td>\n",
       "      <td>5.191083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SR-ATAD5</td>\n",
       "      <td>25.787879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SR-HSE</td>\n",
       "      <td>16.384409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SR-MMP</td>\n",
       "      <td>5.328976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SR-p53</td>\n",
       "      <td>15.014184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Targets    weights\n",
       "0           NR-AR  22.511327\n",
       "1       NR-AR-LBD  27.514768\n",
       "2          NR-AhR   7.527344\n",
       "3    NR-Aromatase  18.403333\n",
       "4           NR-ER   6.809584\n",
       "5       NR-ER-LBD  18.871429\n",
       "6   NR-PPAR-gamma  33.677419\n",
       "7          SR-ARE   5.191083\n",
       "8        SR-ATAD5  25.787879\n",
       "9          SR-HSE  16.384409\n",
       "10         SR-MMP   5.328976\n",
       "11         SR-p53  15.014184"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"/projects/home/mmasood1/arslan_data_repository/Tox21/pos_weights.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADME classification sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from tdc.single_pred import ADME\n",
    "data = ADME(name = 'PAMPA_NCATS')\n",
    "split = data.get_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>name</th>\n",
       "      <th>p_np</th>\n",
       "      <th>smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Propanolol</td>\n",
       "      <td>1</td>\n",
       "      <td>[Cl].CC(C)NCC(O)COc1cccc2ccccc12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Terbutylchlorambucil</td>\n",
       "      <td>1</td>\n",
       "      <td>C(=O)(OC(C)(C)C)CCCc1ccc(cc1)N(CCCl)CCCl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>40730</td>\n",
       "      <td>1</td>\n",
       "      <td>c12c3c(N4CCN(C)CC4)c(F)cc1c(c(C(O)=O)cn2C(C)CO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>C1CCN(CC1)Cc1cccc(c1)OCCCNC(=O)C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>cloxacillin</td>\n",
       "      <td>1</td>\n",
       "      <td>Cc1onc(c2ccccc2Cl)c1C(=O)N[C@H]3[C@H]4SC(C)(C)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>2049</td>\n",
       "      <td>licostinel</td>\n",
       "      <td>1</td>\n",
       "      <td>C1=C(Cl)C(=C(C2=C1NC(=O)C(N2)=O)[N+](=O)[O-])Cl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>2050</td>\n",
       "      <td>ademetionine(adenosyl-methionine)</td>\n",
       "      <td>1</td>\n",
       "      <td>[C@H]3([N]2C1=C(C(=NC=N1)N)N=C2)[C@@H]([C@@H](...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>2051</td>\n",
       "      <td>mesocarb</td>\n",
       "      <td>1</td>\n",
       "      <td>[O+]1=N[N](C=C1[N-]C(NC2=CC=CC=C2)=O)C(CC3=CC=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>2052</td>\n",
       "      <td>tofisoline</td>\n",
       "      <td>1</td>\n",
       "      <td>C1=C(OC)C(=CC2=C1C(=[N+](C(=C2CC)C)[NH-])C3=CC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>2053</td>\n",
       "      <td>azidamfenicol</td>\n",
       "      <td>1</td>\n",
       "      <td>[N+](=NCC(=O)N[C@@H]([C@H](O)C1=CC=C([N+]([O-]...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2050 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num                               name  p_np  \\\n",
       "0        1                         Propanolol     1   \n",
       "1        2               Terbutylchlorambucil     1   \n",
       "2        3                              40730     1   \n",
       "3        4                                 24     1   \n",
       "4        5                        cloxacillin     1   \n",
       "...    ...                                ...   ...   \n",
       "2045  2049                         licostinel     1   \n",
       "2046  2050  ademetionine(adenosyl-methionine)     1   \n",
       "2047  2051                           mesocarb     1   \n",
       "2048  2052                         tofisoline     1   \n",
       "2049  2053                      azidamfenicol     1   \n",
       "\n",
       "                                                 smiles  \n",
       "0                      [Cl].CC(C)NCC(O)COc1cccc2ccccc12  \n",
       "1              C(=O)(OC(C)(C)C)CCCc1ccc(cc1)N(CCCl)CCCl  \n",
       "2     c12c3c(N4CCN(C)CC4)c(F)cc1c(c(C(O)=O)cn2C(C)CO...  \n",
       "3                      C1CCN(CC1)Cc1cccc(c1)OCCCNC(=O)C  \n",
       "4     Cc1onc(c2ccccc2Cl)c1C(=O)N[C@H]3[C@H]4SC(C)(C)...  \n",
       "...                                                 ...  \n",
       "2045    C1=C(Cl)C(=C(C2=C1NC(=O)C(N2)=O)[N+](=O)[O-])Cl  \n",
       "2046  [C@H]3([N]2C1=C(C(=NC=N1)N)N=C2)[C@@H]([C@@H](...  \n",
       "2047  [O+]1=N[N](C=C1[N-]C(NC2=CC=CC=C2)=O)C(CC3=CC=...  \n",
       "2048  C1=C(OC)C(=CC2=C1C(=[N+](C(=C2CC)C)[NH-])C3=CC...  \n",
       "2049  [N+](=NCC(=O)N[C@@H]([C@H](O)C1=CC=C([N+]([O-]...  \n",
       "\n",
       "[2050 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(\"/scratch/work/masooda1/datasets/datasets_for_active_learning/raw_data/TDC_ADME/BBBP.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "generating training, validation splits...\n",
      "100%|██████████| 379/379 [00:00<00:00, 2796.35it/s]\n",
      "generating training, validation splits...\n",
      "100%|██████████| 379/379 [00:00<00:00, 2909.50it/s]\n",
      "generating training, validation splits...\n",
      "100%|██████████| 379/379 [00:00<00:00, 2884.66it/s]\n",
      "generating training, validation splits...\n",
      "100%|██████████| 379/379 [00:00<00:00, 2885.25it/s]\n",
      "generating training, validation splits...\n",
      "100%|██████████| 379/379 [00:00<00:00, 2885.27it/s]\n"
     ]
    }
   ],
   "source": [
    "adme_binary_dataset = [\"HIA_Hou\", \"Pgp_Broccatelli\", \"Bioavailability_Ma\", \"CYP2C19_Veith\", \n",
    "                       \"CYP2D6_Veith\", \"CYP3A4_Veith\", \"CYP1A2_Veith\",\"CYP2C9_Veith\", \"CYP2C9_Substrate_CarbonMangels\",\n",
    "                      \"CYP2D6_Substrate_CarbonMangels\", \"CYP3A4_Substrate_CarbonMangels\"]\n",
    "SMILES_col =  \n",
    "    \"HIA_Hou\": Drug\n",
    "    \"Pgp_Broccatelli\" :\n",
    "    \"Bioavailability_Ma\" :Drug\n",
    "    \"CYP2C19_Veith\" :\n",
    "    \"CYP2D6_Veith\" :\n",
    "    \"CYP3A4_Veith\" :\n",
    "    \"CYP1A2_Veith\":\n",
    "    \"CYP2C9_Veith\" :\n",
    "    \"CYP2C9_Substrate_CarbonMangels\":\n",
    "    \"CYP2D6_Substrate_CarbonMangels\" :\n",
    "    \"CYP3A4_Substrate_CarbonMangels\":\n",
    "from tdc.benchmark_group import admet_group\n",
    "group = admet_group(path = 'data/')\n",
    "data_dir = \"/projects/home/mmasood1/arslan_data_repository/DILI\"\n",
    "\n",
    "for seed in [1, 2, 3, 4, 5]:\n",
    "    benchmark = group.get('DILI') \n",
    "    # all benchmark names in a benchmark group are stored in group.dataset_names\n",
    "    name = benchmark['name']\n",
    "    train_val, test = benchmark['train_val'], benchmark['test']\n",
    "    train, valid = group.get_train_valid_split(benchmark = name, split_type = 'default', seed = seed)\n",
    "    seed_dir = data_dir + f\"/seed_{seed}/\"\n",
    "    #os.makedirs(seed_dir, exist_ok = True)\n",
    "    #train.to_csv(seed_dir + f\"train_seed_{seed}.csv\", index = False)\n",
    "    #valid.to_csv(seed_dir + f\"valid_seed_{seed}.csv\", index = False)\n",
    "    #test.to_csv(seed_dir + f\"test_seed_{seed}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molbert",
   "language": "python",
   "name": "molbert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
