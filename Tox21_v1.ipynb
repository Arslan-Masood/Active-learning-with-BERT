{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/home/mmasood1/.conda/envs/env_arslan/lib/python3.9/site-packages/deepchem/models/torch_models/__init__.py)\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from chemprop.args import TrainArgs\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "\n",
    "import wandb\n",
    "import deepchem as dc\n",
    "import os\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "wandb.login(key=\"27edf9c66b032c03f72d30e923276b93aa736429\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_utils import scafoldsplit_train_test, dataloader_for_numpy\n",
    "from utils.utils import wandb_init_model\n",
    "from utils.models import Custom_Chemprop\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from utils.model_utils import pretrained_model\n",
    "from utils.model_utils import get_chemprop_pred, compute_binary_classification_metrics_MT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainArgs.project_name = 'DMPNN_Tox21'\n",
    "TrainArgs.model_name = 'Trial'\n",
    "\n",
    "TrainArgs.target_file = \"/projects/home/mmasood1/arslan_data_repository/Tox21/complete_Tox21.csv\"\n",
    "TrainArgs.input_dim = 1024\n",
    "TrainArgs.train_frac = 0.8\n",
    "\n",
    "TrainArgs.pretrained_dir = \"/projects/home/mmasood1/Model_weights/invitro/Chemprop/fold_0/fold_0/model_0/\"\n",
    "TrainArgs.model_weights_dir = \"/projects/home/mmasood1/Model_weights/preclinical_clinical/chemprop/\"\n",
    "TrainArgs.metadata_dir = '/projects/home/mmasood1/trained_model_predictions/Tox21/Chemprop/'\n",
    "TrainArgs.pretrained_model = False\n",
    "\n",
    "TrainArgs.depth = 3\n",
    "TrainArgs.hidden_size = 300\n",
    "TrainArgs.ffn_num_layers = 2\n",
    "TrainArgs.ffn_hidden_size = 300\n",
    "TrainArgs.num_of_tasks = None\n",
    "TrainArgs.use_input_features = False\n",
    "TrainArgs.dropout = 0.2\n",
    "TrainArgs.batch_size = 50\n",
    "TrainArgs.adding_bond_types = True\n",
    "TrainArgs.atom_descriptors_size = 0\n",
    "\n",
    "TrainArgs.scheduler_type = 'ReduceLROnPlateau'\n",
    "TrainArgs.warmup_epochs = 2\n",
    "TrainArgs.epochs = 20\n",
    "TrainArgs.init_lr = 1e-4\n",
    "TrainArgs.max_lr = 1e-3\n",
    "TrainArgs.final_lr = 1e-4\n",
    "TrainArgs.loss_function = \"binary_cross_entropy\"\n",
    "TrainArgs.seed = 42\n",
    "\n",
    "TrainArgs.accelerator = 'gpu'\n",
    "TrainArgs.EarlyStopping = True\n",
    "TrainArgs.return_trainer = True\n",
    "TrainArgs.device = torch.device(\"cuda\")\n",
    "TrainArgs.compute_metrics_during_training = True\n",
    "TrainArgs.num_forward_passes = 10\n",
    "TrainArgs.n_query = 10\n",
    "TrainArgs.sampling_strategy = \"uniform\"\n",
    "TrainArgs.seed = 42\n",
    "TrainArgs.compute_metric_after_n_epochs = 5\n",
    "\n",
    "args = TrainArgs\n",
    "args.dataset_type = 'classification'\n",
    "args.metric = 'auc'\n",
    "args.is_atom_bond_targets = False\n",
    "args.use_target_weights = False\n",
    "args.missing_label_representation = 'nan'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainArgs\n",
    "args.dataset_type = 'classification'\n",
    "args.metric = 'auc'\n",
    "args.is_atom_bond_targets = False\n",
    "args.use_target_weights = False\n",
    "args.missing_label_representation = 'nan'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get targets information\n",
    "data = pd.read_csv(args.target_file)\n",
    "target_names = data.loc[:, \"NR-AR\":\"SR-p53\"].columns.tolist()\n",
    "\n",
    "args.num_of_tasks = len(target_names)\n",
    "args.selected_tasks = target_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_test_features (6264, 1024) (1567, 1024)\n",
      "train_test_targets (6264, 12) (1567, 12)\n",
      "train_set [132.0, 193.0, 196.0, 208.0, 251.0, 276.0, 281.0, 300.0, 589.0, 648.0, 711.0, 718.0]\n",
      "test_set [44.0, 50.0, 54.0, 58.0, 68.0, 91.0, 92.0, 145.0, 147.0, 179.0, 207.0, 224.0]\n",
      "pool_set [109.0, 164.0, 164.0, 172.0, 219.0, 236.0, 236.0, 255.0, 499.0, 555.0, 602.0, 608.0]\n",
      "val_set [18.0, 25.0, 25.0, 27.0, 31.0, 33.0, 38.0, 39.0, 81.0, 84.0, 94.0, 102.0]\n",
      "initial_set [3.0, 4.0, 5.0, 5.0, 6.0, 7.0, 7.0, 9.0, 9.0, 9.0, 9.0, 14.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((6264, 12), (1567, 12), (5324, 12), (839, 12), (101, 12))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "# seed_everything(seed = config[\"seed\"])\n",
    "train_set, test_set = scafoldsplit_train_test(target_file=args.target_file,\n",
    "                                              selected_tasks=args.selected_tasks,\n",
    "                                              FP_size=args.input_dim,\n",
    "                                              train_frac=args.train_frac,)\n",
    "\n",
    "randomstratifiedsplitter = dc.splits.RandomStratifiedSplitter()\n",
    "pool_set, val_set, initial_set = randomstratifiedsplitter.train_valid_test_split(train_set,\n",
    "                                                                                 frac_train=0.85,\n",
    "                                                                                 frac_valid=0.134,\n",
    "                                                                                 frac_test=0.016,\n",
    "                                                                                 seed=42)\n",
    "\n",
    "print(\"train_set\", sorted(np.nansum(train_set.y, axis=0)))\n",
    "print(\"test_set\", sorted(np.nansum(test_set.y, axis=0)))\n",
    "print(\"pool_set\", sorted(np.nansum(pool_set.y, axis=0)))\n",
    "print(\"val_set\", sorted(np.nansum(val_set.y, axis=0)))\n",
    "print(\"initial_set\", sorted(np.nansum(initial_set.y, axis=0)))\n",
    "train_set.y.shape, test_set.y.shape, pool_set.y.shape, val_set.y.shape, initial_set.y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dataframe(dc_datset, tasks_name):\n",
    "    dataset = pd.DataFrame(dc_datset.y)\n",
    "    dataset.columns = tasks_name\n",
    "    dataset.insert(0, \"SMILES\", dc_datset.ids)\n",
    "    return dataset\n",
    "\n",
    "def convert_dataframe_to_dataloader(dataframe, args, shuffle = False):\n",
    "    dataloader = DataLoader(dataloader_for_numpy(dataframe.SMILES.values, dataframe[args.selected_tasks].values, x_type='SMILES'),\n",
    "                              batch_size=args.batch_size,\n",
    "                              pin_memory=False,\n",
    "                              num_workers=4,\n",
    "                              shuffle=shuffle,\n",
    "                              persistent_workers=True)\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Who cares about deepchem data_object, trash it\n",
    "initial_set = convert_to_dataframe(initial_set, args.selected_tasks)\n",
    "val_set = convert_to_dataframe(val_set, args.selected_tasks)\n",
    "pool_set = convert_to_dataframe(pool_set, args.selected_tasks)\n",
    "test_set = convert_to_dataframe(test_set, args.selected_tasks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = convert_dataframe_to_dataloader(dataframe= initial_set, args = args, shuffle= True)\n",
    "val_dataloader = convert_dataframe_to_dataloader(dataframe= val_set, args = args, shuffle= False)\n",
    "test_dataloader = convert_dataframe_to_dataloader(dataframe= test_set, args = args, shuffle= False)\n",
    "pool_dataloader = convert_dataframe_to_dataloader(dataframe= pool_set, args = args, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/mmasood1/.conda/envs/env_arslan/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:389: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/home/mmasood1/.conda/envs/env_arslan/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:634: Checkpoint directory /projects/home/mmasood1/Model_weights/preclinical_clinical/chemprop/ exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type              | Params\n",
      "----------------------------------------------\n",
      "0 | loss_fn | BCEWithLogitsLoss | 0     \n",
      "1 | encoder | MPN               | 264 K \n",
      "2 | readout | Sequential        | 93.9 K\n",
      "----------------------------------------------\n",
      "358 K     Trainable params\n",
      "300       Non-trainable params\n",
      "358 K     Total params\n",
      "1.434     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d144f70562d43fd98b1b904499dba5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n",
      "/home/mmasood1/.conda/envs/env_arslan/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52b517d82378474bb76cde751da67f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173fbfcf068a42e5acc911c5b16575be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n",
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7eeb81ec954d4db44ba34e0f46ed4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91c50db32e24d61b1a8ec1dc6529052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef189df9b85f450d9aad2a08554724ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d3c82edc0a4883a2294f5d4b0fc1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a57f53ada346df80a69bb0def95924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n",
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e39a95cf8d44fb8aea3aa25520c73c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86e7acd7ae44fec8ef80bc10005b372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "680063347b174a00bdeca372c53e9146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff4803931e6494d88e51937ce41705d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0d764dbbba42e7a7a6b8474ce5f4ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n",
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c811b42f0e2b44a48bcbbd76f2350d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a08af5d18d429bbca37ec9198da1ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3488199808b4f80a653350625f5f150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a4f98cb6db4349b737157538c8eb03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d420938bf804d9e8dab17e395155c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n",
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdde73bdd6b1493bbe89564a8ab8a90f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104f77a3ffbd4c17a57ee610875fa1ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3bfd11695f0450fb684c4f57fc09c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "927dc242e73c4283bb895e371b50856a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n",
      "/projects/home/mmasood1/TG GATE/active_learning/utils/models.py:214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1_score), np.nanmean(average_precision)\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "args.steps_per_epoch = len(train_dataloader)\n",
    "args.model_name = f'd{args.depth}_MPN_h{args.hidden_size}_ffn_h{args.ffn_hidden_size}_DO{args.dropout}'\n",
    "\n",
    "trained_model, run, trainer = wandb_init_model(Custom_Chemprop,\n",
    "                                               args,\n",
    "                                               train_dataloader,\n",
    "                                               val_dataloader,\n",
    "                                               model_type='chemprop')\n",
    "checkpoint_callback = [\n",
    "    cb for cb in trainer.callbacks if isinstance(cb, ModelCheckpoint)][0]\n",
    "metric_to_optimize = checkpoint_callback.best_model_score.item()\n",
    "\n",
    "# model = Custom_Chemprop(args)\n",
    "# checkpoint = torch.load(checkpoint_callback.best_model_path, map_location=lambda storage, loc: storage)\n",
    "# model.load_state_dict(checkpoint['state_dict'])\n",
    "# model.eval()\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "\n",
    "def enable_dropout(model):\n",
    "    \"\"\" Function to enable the dropout layers during test-time \"\"\"\n",
    "    for m in model.modules():\n",
    "        if m.__class__.__name__.startswith('Dropout'):\n",
    "            m.train()\n",
    "\n",
    "\n",
    "def get_chemprop_pred(dataloader, model, n_samples, n_classes, cal_uncert=False, num_forward_passes=1):\n",
    "\n",
    "    dropout_predictions = np.empty((0, n_samples, n_classes))\n",
    "    device = torch.device('cuda')\n",
    "    model = model.eval()\n",
    "    model = model.to(device)\n",
    "\n",
    "    if cal_uncert == True:\n",
    "        enable_dropout(model)\n",
    "\n",
    "    for i in range(num_forward_passes):\n",
    "        preds, targets = [], []\n",
    "        for batch in dataloader:\n",
    "            smiles, batch_targets = batch\n",
    "            smiles = [[SMILES] for SMILES in smiles]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                batch_preds = model(smiles)\n",
    "                batch_preds = batch_preds.tolist()\n",
    "                preds.extend(batch_preds)\n",
    "                targets.extend(batch_targets.cpu().detach().tolist())\n",
    "        preds = expit(np.array(preds))\n",
    "        targets = np.array(targets)\n",
    "\n",
    "        dropout_predictions = np.vstack(\n",
    "            (dropout_predictions, preds[np.newaxis, :, :]))\n",
    "        pred_mean = np.mean(dropout_predictions, axis=0)\n",
    "        pred_var = np.var(dropout_predictions, axis=0)\n",
    "\n",
    "    return targets, pred_mean, pred_var, dropout_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BALD_acquisition_function(pred):\n",
    "    '''\n",
    "    pred: probability (repeats, mol, tasks)\n",
    "    '''\n",
    "    pred_mean = pred.mean(axis=0)\n",
    "    epsilon = 1e-10\n",
    "    # Calculating entropy across multiple MCD forward passes\n",
    "    # input (mol, tasks) --> (mol, tasks)\n",
    "    H = - pred_mean * np.log(pred_mean + epsilon)  # shape (n_samples,task)\n",
    "    E_H = np.mean(-pred * np.log(pred + epsilon), axis=0)\n",
    "    # Calculating mutual information across multiple MCD forward passes\n",
    "    MI = H - E_H\n",
    "    return MI\n",
    "\n",
    "\n",
    "def get_top_indices(array_2d, topk):\n",
    "\n",
    "    # Flatten the array and get indices of N largest values\n",
    "    flat_indices = np.argpartition(array_2d.flatten(), -topk)[-topk:]\n",
    "\n",
    "    # Sort the top N values and their corresponding indices\n",
    "    sorted_indices = flat_indices[np.argsort(\n",
    "        array_2d.flatten()[flat_indices])][::-1]\n",
    "\n",
    "    # Convert flat indices to 2D indices\n",
    "    indices_2d = np.unravel_index(sorted_indices, array_2d.shape)\n",
    "\n",
    "    return indices_2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_indices(pool_set, arg):\n",
    "    query_mol = np.random.choice(range(pool_set.shape[0]), size= arg.n_query, replace=False)\n",
    "    query_task = np.random.choice(range(len(args.selected_tasks)), size= arg.n_query, replace=True)\n",
    "    return (query_mol, query_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30780/3917675102.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append(metrics.mean(), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# get model predictions on test set\n",
    "model = trained_model.eval()\n",
    "targets, pred_mean, pred_var, all_pred = get_chemprop_pred(test_dataloader, model,\n",
    "                                                           n_samples=test_set.shape[0],\n",
    "                                                           n_classes=len(args.selected_tasks),\n",
    "                                                           cal_uncert=False,\n",
    "                                                           num_forward_passes=1)\n",
    "\n",
    "# compute test metrics\n",
    "metrics = compute_binary_classification_metrics_MT(targets, pred_mean, missing='nan')\n",
    "metrics = metrics.append(metrics.mean(), ignore_index=True)\n",
    "metrics.insert(0, 'Tasks', args.selected_tasks + ['mean'])\n",
    "# metrics.to_csv(result_dir + f'{model_type[i]}_{label}_metrics.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions on pool_set\n",
    "args.n_query = 10\n",
    "args.num_forward_passes = 3\n",
    "if args.sampling_strategy == \"BALD\":\n",
    "    targets, pred_mean, pred_var, all_pred = get_chemprop_pred(pool_dataloader, model, \n",
    "                                n_samples= pool_set.shape[0], \n",
    "                                    n_classes= len(args.selected_tasks),\n",
    "                                    cal_uncert= True, \n",
    "                                    num_forward_passes = args.num_forward_passes)\n",
    "    \n",
    "    acquisition = BALD_acquisition_function(all_pred)\n",
    "    # We should not query with missing labels, so hide it\n",
    "    nan_mask = ~np.isnan(pool_set[args.selected_tasks].values)\n",
    "    acquisition = acquisition * nan_mask\n",
    "    print(np.max(acquisition))\n",
    "\n",
    "    # Get location of TopGuns\n",
    "    top_indices = get_top_indices(acquisition, args.n_query)\n",
    "    acquisition[top_indices]\n",
    "\n",
    "if args.sampling_strategy == \"uniform\":\n",
    "    top_indices = get_random_indices(pool_set, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4354, 1821, 2067, 4636, 1448, 3146, 1377, 1293, 4975, 2492]),\n",
       " array([11,  3,  8,  7, 10,  7, 11,  2,  4,  3]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_set(pool_set, top_indices):\n",
    "\n",
    "    # get top guns\n",
    "    selected_mol = pool_set.iloc[top_indices[0],0]\n",
    "\n",
    "    # diffuse all others ~y_ik\n",
    "    p_set = pool_set.iloc[:, 1:].copy(deep=True)\n",
    "    mask = np.ones_like(p_set, dtype=bool)\n",
    "    mask[top_indices] = False\n",
    "    p_set[mask] = np.nan\n",
    "\n",
    "    # pull our guys (y_ik)\n",
    "    selected_tasks = p_set.iloc[top_indices[0], :]\n",
    "    top_guns = pd.concat([selected_mol, selected_tasks], axis = 1).reset_index(drop = True)\n",
    "    return top_guns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_training_set(train_set, query_set):\n",
    "\n",
    "    # Divide and conquer\n",
    "    # convert query compounds into two sets\n",
    "\n",
    "    already_existing_compound = query_set[query_set.SMILES.isin(\n",
    "        train_set.SMILES)]\n",
    "    new_compound = query_set[~query_set.SMILES.isin(train_set.SMILES)]\n",
    "\n",
    "    # merge with new compound\n",
    "    train_set = pd.merge(train_set, new_compound,\n",
    "                         on=train_set.columns.to_list(),\n",
    "                         how=\"outer\")\n",
    "\n",
    "    # convert missing labels --> observed labels\n",
    "    train_set.combine_first(already_existing_compound)\n",
    "    return train_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_queried_index_from_pool_set(pool_set, top_indices):\n",
    "    # update pool set\n",
    "    SMILES = pool_set.iloc[:,0]\n",
    "    updated_poolset = pool_set.iloc[:, 1:].copy(deep=True)\n",
    "    mask = np.zeros_like(updated_poolset, dtype=bool)\n",
    "    mask[top_indices] = True\n",
    "    updated_poolset[mask] = np.nan\n",
    "    updated_poolset = pd.concat([SMILES, updated_poolset], axis = 1).reset_index(drop = True)\n",
    "    updated_poolset.dropna(axis = 0, how = 'all')\n",
    "    return updated_poolset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_set = get_query_set(pool_set, top_indices)\n",
    "updated_training = update_training_set(initial_set, query_set)\n",
    "updated_poolset = remove_queried_index_from_pool_set(pool_set, top_indices)\n",
    "\n",
    "initial_counts = initial_set.iloc[:, 1:].count()\n",
    "query_counts = query_set.iloc[:, 1:].count()\n",
    "updated_training_counts = updated_training.iloc[:, 1:].count()\n",
    "\n",
    "initial_poolset_counts = pool_set.iloc[:, 1:].count()\n",
    "updated_poolset_counts = updated_poolset.iloc[:, 1:].count()\n",
    "\n",
    "\n",
    "# Use an assertion to check if the counts are equal\n",
    "assert updated_training_counts.equals(initial_counts + query_counts), \"Training_count,Queryset counts are not equal\"\n",
    "assert initial_poolset_counts.equals(updated_poolset_counts + query_counts), \"Poolset, Queryset count are not equal\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5324, 13), (5324, 13))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_set.shape, updated_poolset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>NR-AR</th>\n",
       "      <th>NR-AR-LBD</th>\n",
       "      <th>NR-AhR</th>\n",
       "      <th>NR-Aromatase</th>\n",
       "      <th>NR-ER</th>\n",
       "      <th>NR-ER-LBD</th>\n",
       "      <th>NR-PPAR-gamma</th>\n",
       "      <th>SR-ARE</th>\n",
       "      <th>SR-ATAD5</th>\n",
       "      <th>SR-HSE</th>\n",
       "      <th>SR-MMP</th>\n",
       "      <th>SR-p53</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC(O)(P(=O)(O)O)P(=O)(O)O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC(C)(C)OOC(C)(C)CCC(C)(C)OOC(C)(C)C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCCCCCCC(=O)[O-].CCCCCCCC(=O)[O-].[Zn+2]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC(C)COC(=O)C(C)C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C=C(C)C(=O)OCCOC(=O)C(=C)C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5319</th>\n",
       "      <td>CC(C)(Oc1ccc(Cl)cc1)C(=O)OCCCOC(=O)C(C)(C)Oc1c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5320</th>\n",
       "      <td>O=S1(=O)c2cccc3cccc(c23)N1CCCN1CCN(c2ccc(F)cc2...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5321</th>\n",
       "      <td>Cc1oc(-c2ccccc2)nc1CCC(=O)c1ccc(CC2SC(=O)NC2=O...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5322</th>\n",
       "      <td>CC1CCCCN1CCCOC(=O)c1ccc(OC2CCCCC2)cc1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5323</th>\n",
       "      <td>O=C1OC(OC(=O)c2cccnc2Nc2cccc(C(F)(F)F)c2)c2ccc...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5324 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 SMILES  NR-AR  NR-AR-LBD  \\\n",
       "0                             CC(O)(P(=O)(O)O)P(=O)(O)O    0.0        0.0   \n",
       "1                  CC(C)(C)OOC(C)(C)CCC(C)(C)OOC(C)(C)C    0.0        0.0   \n",
       "2              CCCCCCCC(=O)[O-].CCCCCCCC(=O)[O-].[Zn+2]    NaN        NaN   \n",
       "3                                     CC(C)COC(=O)C(C)C    0.0        0.0   \n",
       "4                            C=C(C)C(=O)OCCOC(=O)C(=C)C    0.0        0.0   \n",
       "...                                                 ...    ...        ...   \n",
       "5319  CC(C)(Oc1ccc(Cl)cc1)C(=O)OCCCOC(=O)C(C)(C)Oc1c...    NaN        NaN   \n",
       "5320  O=S1(=O)c2cccc3cccc(c23)N1CCCN1CCN(c2ccc(F)cc2...    0.0        0.0   \n",
       "5321  Cc1oc(-c2ccccc2)nc1CCC(=O)c1ccc(CC2SC(=O)NC2=O...    NaN        NaN   \n",
       "5322              CC1CCCCN1CCCOC(=O)c1ccc(OC2CCCCC2)cc1    NaN        NaN   \n",
       "5323  O=C1OC(OC(=O)c2cccnc2Nc2cccc(C(F)(F)F)c2)c2ccc...    0.0        NaN   \n",
       "\n",
       "      NR-AhR  NR-Aromatase  NR-ER  NR-ER-LBD  NR-PPAR-gamma  SR-ARE  SR-ATAD5  \\\n",
       "0        0.0           0.0    0.0        0.0            0.0     0.0       0.0   \n",
       "1        0.0           0.0    0.0        0.0            0.0     NaN       0.0   \n",
       "2        NaN           NaN    NaN        NaN            NaN     0.0       NaN   \n",
       "3        0.0           0.0    0.0        0.0            0.0     0.0       0.0   \n",
       "4        0.0           0.0    0.0        0.0            0.0     0.0       0.0   \n",
       "...      ...           ...    ...        ...            ...     ...       ...   \n",
       "5319     NaN           NaN    NaN        NaN            NaN     0.0       NaN   \n",
       "5320     0.0           0.0    NaN        0.0            0.0     1.0       0.0   \n",
       "5321     NaN           NaN    NaN        NaN            NaN     1.0       NaN   \n",
       "5322     NaN           NaN    NaN        NaN            NaN     0.0       NaN   \n",
       "5323     0.0           0.0    0.0        0.0            0.0     NaN       0.0   \n",
       "\n",
       "      SR-HSE  SR-MMP  SR-p53  \n",
       "0        0.0     0.0     0.0  \n",
       "1        0.0     0.0     0.0  \n",
       "2        0.0     NaN     NaN  \n",
       "3        0.0     0.0     0.0  \n",
       "4        0.0     0.0     0.0  \n",
       "...      ...     ...     ...  \n",
       "5319     0.0     NaN     NaN  \n",
       "5320     0.0     NaN     NaN  \n",
       "5321     0.0     NaN     NaN  \n",
       "5322     0.0     NaN     NaN  \n",
       "5323     0.0     1.0     0.0  \n",
       "\n",
       "[5324 rows x 13 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.061 0.06 0.0\n",
      "0.043 0.087 0.00049\n",
      "0.006 0.03 0.00014\n",
      "0.042 0.071 0.00021\n",
      "0.037 0.019 8e-05\n",
      "0.069 0.059 3e-05\n",
      "0.022 0.057 0.00031\n",
      "0.014 0.012 0.0\n",
      "0.016 0.033 8e-05\n",
      "0.002 0.001 0.0\n",
      "0.003 0.001 0.0\n",
      "0.059 0.076 7e-05\n",
      "0.039 0.008 0.00024\n",
      "0.054 0.024 0.00021\n",
      "0.067 0.085 8e-05\n",
      "0.035 0.026 2e-05\n",
      "0.225 0.171 0.00071\n",
      "0.039 0.023 7e-05\n",
      "0.049 0.013 0.00032\n",
      "0.002 0.003 0.0\n",
      "0.012 0.017 1e-05\n",
      "0.043 0.048 1e-05\n",
      "0.12 0.035 0.00178\n",
      "0.945 0.93 6e-05\n",
      "0.025 0.014 3e-05\n",
      "0.053 0.12 0.00113\n",
      "0.051 0.038 4e-05\n",
      "0.071 0.075 0.0\n",
      "0.033 0.058 0.00015\n",
      "0.022 0.031 2e-05\n",
      "0.041 0.009 0.00025\n",
      "0.025 0.037 4e-05\n",
      "0.041 0.031 3e-05\n",
      "0.036 0.04 1e-05\n",
      "0.07 0.053 7e-05\n",
      "0.071 0.058 4e-05\n",
      "0.039 0.042 0.0\n",
      "0.043 0.035 2e-05\n",
      "0.026 0.042 7e-05\n",
      "0.013 0.011 0.0\n",
      "0.03 0.019 3e-05\n",
      "0.017 0.038 0.00011\n",
      "0.072 0.02 0.0007\n",
      "0.086 0.053 0.00027\n",
      "0.039 0.033 1e-05\n",
      "0.04 0.063 0.00013\n",
      "0.015 0.03 6e-05\n",
      "0.019 0.038 9e-05\n",
      "0.01 0.017 1e-05\n",
      "0.029 0.024 1e-05\n",
      "0.055 0.046 2e-05\n",
      "0.075 0.123 0.00057\n",
      "0.039 0.058 9e-05\n",
      "0.064 0.033 0.00024\n",
      "0.037 0.029 2e-05\n",
      "0.018 0.008 3e-05\n",
      "0.047 0.062 5e-05\n",
      "0.016 0.047 0.00024\n",
      "0.083 0.136 0.00069\n",
      "0.016 0.008 2e-05\n",
      "0.054 0.033 0.0001\n",
      "0.036 0.022 5e-05\n",
      "0.052 0.051 0.0\n",
      "0.086 0.061 0.00016\n",
      "0.079 0.057 0.00011\n",
      "0.048 0.063 6e-05\n",
      "0.064 0.064 0.0\n",
      "0.038 0.026 4e-05\n",
      "0.079 0.034 0.00051\n",
      "0.01 0.025 6e-05\n",
      "0.01 0.012 0.0\n",
      "0.075 0.053 0.00013\n",
      "0.136 0.175 0.00039\n",
      "0.062 0.049 4e-05\n",
      "0.032 0.018 5e-05\n",
      "0.05 0.033 7e-05\n",
      "0.077 0.054 0.00013\n",
      "0.042 0.025 7e-05\n",
      "0.043 0.032 3e-05\n",
      "0.039 0.064 0.00015\n",
      "0.032 0.124 0.00208\n",
      "0.055 0.038 7e-05\n",
      "0.026 0.014 4e-05\n",
      "0.02 0.015 1e-05\n",
      "0.017 0.056 0.00039\n",
      "0.026 0.025 0.0\n",
      "0.001 0.005 0.0\n",
      "0.001 0.0 0.0\n",
      "0.069 0.055 5e-05\n",
      "0.025 0.048 0.00014\n",
      "0.242 0.272 0.00023\n",
      "0.019 0.025 1e-05\n",
      "0.062 0.053 2e-05\n",
      "0.03 0.051 0.00011\n",
      "0.036 0.041 1e-05\n",
      "0.034 0.047 4e-05\n",
      "0.111 0.064 0.00056\n",
      "0.047 0.05 0.0\n",
      "0.072 0.088 6e-05\n",
      "0.035 0.02 6e-05\n",
      "0.046 0.139 0.00217\n",
      "0.021 0.02 0.0\n",
      "0.525 0.273 0.01588\n",
      "0.048 0.025 0.00013\n",
      "0.057 0.009 0.00057\n",
      "0.065 0.082 7e-05\n",
      "0.034 0.02 5e-05\n",
      "0.045 0.025 0.0001\n",
      "0.053 0.022 0.00024\n",
      "0.025 0.018 1e-05\n",
      "0.017 0.078 0.00094\n",
      "0.02 0.012 2e-05\n",
      "0.019 0.036 7e-05\n",
      "0.05 0.057 1e-05\n",
      "0.022 0.038 6e-05\n",
      "0.006 0.006 0.0\n",
      "0.013 0.025 4e-05\n",
      "0.889 0.891 0.0\n",
      "0.03 0.041 3e-05\n",
      "0.052 0.053 0.0\n",
      "0.039 0.038 0.0\n",
      "0.06 0.043 7e-05\n",
      "0.007 0.018 3e-05\n",
      "0.036 0.027 2e-05\n",
      "0.031 0.048 8e-05\n",
      "0.99 0.998 2e-05\n",
      "0.02 0.026 1e-05\n",
      "0.103 0.017 0.00184\n",
      "0.015 0.015 0.0\n",
      "0.041 0.021 0.0001\n",
      "0.043 0.039 0.0\n",
      "0.039 0.014 0.00016\n",
      "0.099 0.1 0.0\n",
      "0.045 0.024 0.00011\n",
      "0.039 0.023 6e-05\n",
      "0.022 0.02 0.0\n",
      "0.042 0.057 6e-05\n",
      "0.014 0.007 1e-05\n",
      "0.312 0.267 0.00049\n",
      "0.039 0.055 6e-05\n",
      "0.028 0.036 1e-05\n",
      "0.025 0.029 0.0\n",
      "0.034 0.026 2e-05\n",
      "0.025 0.059 0.00029\n",
      "0.034 0.034 0.0\n",
      "0.112 0.105 1e-05\n",
      "0.008 0.021 4e-05\n",
      "0.056 0.086 0.00023\n",
      "0.042 0.034 2e-05\n",
      "0.037 0.014 0.00013\n",
      "0.042 0.049 1e-05\n",
      "0.061 0.037 0.00014\n",
      "0.544 0.478 0.00109\n",
      "0.033 0.026 1e-05\n",
      "0.031 0.012 9e-05\n",
      "0.067 0.054 4e-05\n",
      "0.045 0.038 1e-05\n",
      "0.015 0.013 0.0\n",
      "0.004 0.005 0.0\n",
      "0.009 0.013 0.0\n",
      "0.013 0.046 0.00027\n",
      "0.012 0.012 0.0\n",
      "0.017 0.02 0.0\n",
      "0.037 0.035 0.0\n",
      "0.015 0.03 5e-05\n",
      "0.177 0.089 0.00194\n",
      "0.012 0.031 9e-05\n",
      "0.033 0.054 0.00011\n",
      "0.089 0.028 0.00094\n",
      "0.021 0.028 1e-05\n",
      "0.001 0.001 0.0\n",
      "0.025 0.061 0.00033\n",
      "0.012 0.024 4e-05\n",
      "0.046 0.068 0.00013\n",
      "0.073 0.037 0.00032\n",
      "0.038 0.027 3e-05\n",
      "0.03 0.056 0.00016\n",
      "0.016 0.028 3e-05\n",
      "0.035 0.027 2e-05\n",
      "0.035 0.012 0.00014\n",
      "0.047 0.05 0.0\n",
      "0.065 0.054 3e-05\n",
      "0.071 0.076 0.0\n",
      "0.062 0.08 8e-05\n",
      "0.017 0.006 3e-05\n",
      "0.041 0.054 4e-05\n",
      "0.054 0.026 0.0002\n",
      "0.077 0.107 0.00022\n",
      "0.047 0.048 0.0\n",
      "0.041 0.056 6e-05\n",
      "0.037 0.032 1e-05\n",
      "0.01 0.024 5e-05\n",
      "0.089 0.114 0.00016\n",
      "0.638 0.705 0.00112\n",
      "0.014 0.03 6e-05\n",
      "0.067 0.054 4e-05\n",
      "0.028 0.009 8e-05\n",
      "0.019 0.03 3e-05\n",
      "0.056 0.059 0.0\n",
      "0.007 0.014 1e-05\n",
      "0.045 0.061 6e-05\n",
      "0.057 0.021 0.00033\n",
      "0.102 0.086 6e-05\n",
      "0.084 0.089 1e-05\n",
      "0.083 0.072 3e-05\n",
      "0.006 0.007 0.0\n",
      "0.031 0.036 1e-05\n",
      "0.009 0.022 4e-05\n",
      "0.012 0.016 0.0\n",
      "0.094 0.097 0.0\n",
      "0.04 0.048 1e-05\n",
      "0.107 0.098 2e-05\n",
      "0.056 0.038 8e-05\n",
      "0.018 0.031 4e-05\n",
      "0.016 0.033 8e-05\n",
      "0.017 0.013 0.0\n",
      "0.061 0.034 0.00017\n",
      "0.026 0.061 0.00032\n",
      "0.005 0.009 0.0\n",
      "0.04 0.02 0.0001\n",
      "0.1 0.053 0.00055\n",
      "0.041 0.074 0.00027\n",
      "0.044 0.025 0.0001\n",
      "0.074 0.029 0.00052\n",
      "0.029 0.029 0.0\n",
      "0.049 0.031 8e-05\n",
      "0.802 0.864 0.00099\n",
      "0.014 0.02 1e-05\n",
      "0.357 0.267 0.00203\n",
      "0.018 0.039 0.00011\n",
      "0.091 0.09 0.0\n",
      "0.028 0.049 0.00011\n",
      "0.103 0.075 0.00019\n",
      "0.042 0.067 0.00016\n",
      "0.075 0.079 0.0\n",
      "0.032 0.019 4e-05\n",
      "0.059 0.077 8e-05\n",
      "0.036 0.044 2e-05\n",
      "0.049 0.037 3e-05\n",
      "0.042 0.02 0.00012\n",
      "0.043 0.04 0.0\n",
      "0.031 0.054 0.00014\n",
      "0.053 0.024 0.00022\n",
      "0.053 0.034 9e-05\n",
      "0.079 0.147 0.00117\n",
      "0.078 0.05 0.0002\n",
      "0.06 0.033 0.00018\n",
      "0.021 0.029 2e-05\n",
      "0.034 0.013 0.00011\n",
      "0.016 0.026 2e-05\n",
      "0.13 0.129 0.0\n",
      "0.09 0.083 1e-05\n",
      "0.111 0.116 1e-05\n",
      "0.05 0.053 0.0\n",
      "0.032 0.045 4e-05\n",
      "0.003 0.007 0.0\n",
      "0.187 0.101 0.00184\n",
      "0.17 0.08 0.00204\n",
      "0.034 0.049 5e-05\n",
      "0.044 0.035 2e-05\n",
      "0.012 0.035 0.00014\n",
      "0.046 0.065 9e-05\n",
      "0.044 0.018 0.00016\n",
      "0.044 0.097 0.0007\n",
      "0.019 0.015 0.0\n",
      "0.047 0.027 9e-05\n",
      "0.096 0.118 0.00013\n",
      "0.09 0.049 0.00041\n",
      "0.018 0.039 0.00011\n",
      "0.039 0.053 5e-05\n",
      "0.352 0.309 0.00046\n",
      "0.052 0.063 3e-05\n",
      "0.01 0.015 1e-05\n",
      "0.014 0.009 1e-05\n",
      "0.038 0.026 4e-05\n",
      "0.073 0.043 0.00023\n",
      "0.069 0.086 7e-05\n",
      "0.05 0.062 3e-05\n",
      "0.688 0.71 0.00012\n",
      "0.028 0.034 1e-05\n",
      "0.033 0.025 1e-05\n",
      "0.009 0.011 0.0\n",
      "0.071 0.068 0.0\n",
      "0.05 0.035 5e-05\n",
      "0.022 0.045 0.00013\n",
      "0.083 0.05 0.00027\n",
      "0.044 0.037 1e-05\n",
      "0.02 0.047 0.00018\n",
      "0.005 0.008 0.0\n",
      "0.025 0.012 4e-05\n",
      "0.173 0.073 0.00252\n",
      "0.556 0.733 0.00786\n",
      "0.067 0.125 0.00084\n",
      "0.058 0.049 2e-05\n",
      "0.023 0.014 2e-05\n",
      "0.07 0.121 0.00065\n",
      "0.03 0.038 2e-05\n",
      "0.046 0.045 0.0\n",
      "0.004 0.005 0.0\n",
      "0.084 0.035 0.0006\n",
      "0.047 0.059 4e-05\n",
      "0.028 0.021 1e-05\n",
      "0.029 0.026 0.0\n",
      "0.038 0.07 0.00026\n",
      "0.052 0.06 2e-05\n",
      "0.027 0.056 0.00021\n",
      "0.065 0.046 9e-05\n",
      "0.039 0.025 5e-05\n",
      "0.044 0.047 0.0\n",
      "0.022 0.037 6e-05\n",
      "0.027 0.062 0.00031\n",
      "0.104 0.062 0.00044\n",
      "0.026 0.031 1e-05\n",
      "0.017 0.04 0.00013\n",
      "0.046 0.043 0.0\n",
      "0.02 0.046 0.00017\n",
      "0.548 0.673 0.0039\n",
      "0.051 0.028 0.00014\n",
      "0.043 0.042 0.0\n",
      "0.05 0.069 9e-05\n",
      "0.097 0.107 3e-05\n",
      "0.058 0.079 0.0001\n",
      "0.041 0.029 3e-05\n",
      "0.055 0.043 3e-05\n",
      "0.025 0.016 2e-05\n",
      "0.02 0.025 1e-05\n",
      "0.026 0.019 1e-05\n",
      "0.08 0.064 7e-05\n",
      "0.056 0.09 0.00029\n",
      "0.027 0.012 6e-05\n",
      "0.001 0.004 0.0\n",
      "0.049 0.026 0.00013\n",
      "0.103 0.091 4e-05\n",
      "0.002 0.003 0.0\n",
      "0.028 0.043 5e-05\n",
      "0.012 0.004 2e-05\n",
      "0.015 0.018 0.0\n",
      "0.042 0.018 0.00014\n",
      "0.031 0.033 0.0\n",
      "0.033 0.063 0.00023\n",
      "0.04 0.066 0.00017\n",
      "0.104 0.096 2e-05\n",
      "0.074 0.109 0.00031\n",
      "0.024 0.046 0.00012\n",
      "0.062 0.106 0.00047\n",
      "0.009 0.006 0.0\n",
      "0.029 0.036 1e-05\n",
      "0.009 0.019 2e-05\n",
      "0.026 0.018 2e-05\n",
      "0.078 0.014 0.00104\n",
      "0.073 0.031 0.00043\n",
      "0.033 0.039 1e-05\n",
      "0.058 0.085 0.00018\n",
      "0.025 0.017 2e-05\n",
      "0.035 0.035 0.0\n",
      "0.049 0.042 1e-05\n",
      "0.012 0.01 0.0\n",
      "0.021 0.024 0.0\n",
      "0.109 0.072 0.00034\n",
      "0.076 0.066 2e-05\n",
      "0.026 0.022 1e-05\n",
      "0.046 0.018 0.00019\n",
      "0.024 0.047 0.00012\n",
      "0.059 0.042 7e-05\n",
      "0.04 0.032 1e-05\n",
      "0.097 0.093 0.0\n",
      "0.055 0.07 6e-05\n",
      "0.029 0.012 7e-05\n",
      "0.07 0.068 0.0\n",
      "0.912 0.863 0.00059\n",
      "0.064 0.05 5e-05\n",
      "0.101 0.049 0.00068\n",
      "0.023 0.054 0.00025\n",
      "0.043 0.073 0.00023\n",
      "0.034 0.025 2e-05\n",
      "0.037 0.022 6e-05\n",
      "0.043 0.1 0.00081\n",
      "0.045 0.059 5e-05\n",
      "0.059 0.052 1e-05\n",
      "0.015 0.027 4e-05\n",
      "0.046 0.028 8e-05\n",
      "0.069 0.053 7e-05\n",
      "0.015 0.026 3e-05\n",
      "0.132 0.09 0.00044\n",
      "0.042 0.037 1e-05\n",
      "0.015 0.027 4e-05\n",
      "0.07 0.033 0.00034\n",
      "0.029 0.007 0.00012\n",
      "0.046 0.049 0.0\n",
      "0.078 0.031 0.00055\n",
      "0.068 0.073 0.0\n",
      "0.057 0.027 0.00023\n",
      "0.061 0.052 2e-05\n",
      "0.044 0.024 0.0001\n",
      "0.037 0.033 0.0\n",
      "0.04 0.056 7e-05\n",
      "0.045 0.055 2e-05\n",
      "0.011 0.019 2e-05\n",
      "0.572 0.8 0.01292\n",
      "0.025 0.027 0.0\n",
      "0.05 0.035 6e-05\n",
      "0.018 0.012 1e-05\n",
      "0.025 0.029 0.0\n",
      "0.018 0.027 2e-05\n",
      "0.086 0.073 4e-05\n",
      "0.042 0.024 8e-05\n",
      "0.036 0.08 0.0005\n",
      "0.002 0.002 0.0\n",
      "0.021 0.014 1e-05\n",
      "0.059 0.044 5e-05\n",
      "0.021 0.067 0.00052\n",
      "0.049 0.013 0.00032\n",
      "0.026 0.042 7e-05\n",
      "0.057 0.033 0.00014\n",
      "0.002 0.007 0.0\n",
      "0.041 0.082 0.00042\n",
      "0.049 0.058 2e-05\n",
      "0.027 0.012 6e-05\n",
      "0.063 0.07 1e-05\n",
      "0.024 0.012 4e-05\n",
      "0.054 0.027 0.00018\n",
      "0.046 0.029 7e-05\n",
      "0.489 0.567 0.00154\n",
      "0.03 0.036 1e-05\n",
      "0.082 0.053 0.0002\n",
      "0.136 0.099 0.00033\n",
      "0.042 0.031 3e-05\n",
      "0.037 0.039 0.0\n",
      "0.065 0.059 1e-05\n",
      "0.031 0.065 0.00029\n",
      "0.105 0.037 0.00114\n",
      "0.007 0.014 1e-05\n",
      "0.127 0.085 0.00046\n",
      "0.067 0.057 3e-05\n",
      "0.03 0.035 1e-05\n",
      "0.018 0.033 6e-05\n",
      "0.026 0.018 1e-05\n",
      "0.041 0.016 0.00016\n",
      "0.009 0.022 4e-05\n",
      "0.029 0.016 4e-05\n",
      "0.019 0.01 2e-05\n",
      "0.016 0.016 0.0\n",
      "0.042 0.029 4e-05\n",
      "0.09 0.074 7e-05\n",
      "0.073 0.052 0.00011\n",
      "0.021 0.019 0.0\n",
      "0.033 0.026 1e-05\n",
      "0.016 0.018 0.0\n",
      "0.025 0.043 8e-05\n",
      "0.072 0.09 8e-05\n",
      "0.329 0.291 0.00038\n",
      "0.025 0.055 0.00022\n",
      "0.069 0.076 1e-05\n",
      "0.056 0.051 1e-05\n",
      "0.042 0.044 0.0\n",
      "0.024 0.049 0.00015\n",
      "0.046 0.011 0.00031\n",
      "0.04 0.038 0.0\n",
      "0.003 0.008 1e-05\n",
      "0.09 0.061 0.0002\n",
      "0.013 0.019 1e-05\n",
      "0.078 0.096 8e-05\n",
      "0.082 0.057 0.00015\n",
      "0.06 0.057 0.0\n",
      "0.087 0.076 3e-05\n",
      "0.021 0.041 0.0001\n",
      "0.038 0.066 0.00019\n",
      "0.009 0.005 0.0\n",
      "0.033 0.061 0.00021\n",
      "0.089 0.092 0.0\n",
      "0.028 0.038 2e-05\n",
      "0.044 0.042 0.0\n",
      "0.014 0.008 1e-05\n",
      "0.045 0.013 0.00025\n",
      "0.067 0.045 0.00012\n",
      "0.107 0.052 0.00077\n",
      "0.01 0.013 0.0\n",
      "0.006 0.008 0.0\n",
      "0.076 0.032 0.00047\n",
      "0.011 0.013 0.0\n",
      "0.01 0.037 0.00018\n",
      "0.083 0.063 0.0001\n",
      "0.007 0.013 1e-05\n",
      "0.048 0.02 0.00019\n",
      "0.043 0.043 0.0\n",
      "0.11 0.092 8e-05\n",
      "0.779 0.654 0.0039\n",
      "0.052 0.033 9e-05\n",
      "0.032 0.05 8e-05\n",
      "0.096 0.103 1e-05\n",
      "0.714 0.809 0.00227\n",
      "0.036 0.042 1e-05\n",
      "0.085 0.042 0.00046\n",
      "0.017 0.036 9e-05\n",
      "0.107 0.079 0.00021\n",
      "0.054 0.037 7e-05\n",
      "0.0 0.0 0.0\n",
      "0.018 0.011 1e-05\n",
      "0.139 0.083 0.00078\n",
      "0.05 0.075 0.00015\n",
      "0.045 0.032 4e-05\n",
      "0.01 0.012 0.0\n",
      "0.058 0.052 1e-05\n",
      "0.079 0.053 0.00016\n",
      "0.02 0.039 9e-05\n",
      "0.031 0.024 1e-05\n",
      "0.091 0.121 0.00021\n",
      "0.008 0.002 1e-05\n",
      "0.059 0.018 0.00042\n",
      "0.026 0.051 0.00014\n",
      "0.058 0.034 0.00014\n",
      "0.073 0.051 0.00012\n",
      "0.024 0.035 3e-05\n",
      "0.016 0.02 0.0\n",
      "0.042 0.02 0.00012\n",
      "0.011 0.006 1e-05\n",
      "0.015 0.011 1e-05\n",
      "0.015 0.012 0.0\n",
      "0.158 0.223 0.00108\n",
      "0.008 0.046 0.00037\n",
      "0.002 0.001 0.0\n",
      "0.01 0.003 1e-05\n",
      "0.036 0.072 0.00032\n",
      "0.005 0.011 1e-05\n",
      "0.025 0.054 0.0002\n",
      "0.052 0.045 1e-05\n",
      "0.036 0.017 0.0001\n",
      "0.038 0.04 0.0\n",
      "0.023 0.029 1e-05\n",
      "0.014 0.005 2e-05\n",
      "0.036 0.021 6e-05\n",
      "0.015 0.022 1e-05\n",
      "0.018 0.012 1e-05\n",
      "0.026 0.015 4e-05\n",
      "0.036 0.05 5e-05\n",
      "0.08 0.044 0.00032\n",
      "0.031 0.04 2e-05\n",
      "0.043 0.03 4e-05\n",
      "0.064 0.059 1e-05\n",
      "0.012 0.017 1e-05\n",
      "0.023 0.041 8e-05\n",
      "0.052 0.039 4e-05\n",
      "0.151 0.1 0.00065\n",
      "0.045 0.043 0.0\n",
      "0.046 0.072 0.00017\n",
      "0.011 0.016 1e-05\n",
      "0.069 0.08 3e-05\n",
      "0.09 0.129 0.00039\n",
      "0.024 0.057 0.00027\n",
      "0.08 0.056 0.00014\n",
      "0.007 0.008 0.0\n",
      "0.048 0.046 0.0\n",
      "0.025 0.017 1e-05\n",
      "0.033 0.063 0.00022\n",
      "0.018 0.012 1e-05\n",
      "0.145 0.135 2e-05\n",
      "0.04 0.041 0.0\n",
      "0.014 0.024 2e-05\n",
      "0.049 0.058 2e-05\n",
      "0.045 0.022 0.00013\n",
      "0.014 0.024 3e-05\n",
      "0.012 0.082 0.00123\n",
      "0.758 0.785 0.00019\n",
      "0.089 0.114 0.00016\n",
      "0.03 0.033 0.0\n",
      "0.163 0.181 8e-05\n",
      "0.062 0.045 8e-05\n",
      "0.07 0.069 0.0\n",
      "0.01 0.018 2e-05\n",
      "0.069 0.127 0.00084\n",
      "0.121 0.073 0.00058\n",
      "0.026 0.034 2e-05\n",
      "0.023 0.027 0.0\n",
      "0.019 0.067 0.00057\n",
      "0.05 0.061 3e-05\n",
      "0.014 0.009 1e-05\n",
      "0.001 0.002 0.0\n",
      "0.02 0.031 3e-05\n",
      "0.002 0.008 1e-05\n",
      "0.032 0.031 0.0\n",
      "0.012 0.012 0.0\n",
      "0.061 0.078 7e-05\n",
      "0.085 0.027 0.00083\n",
      "0.044 0.065 0.00012\n",
      "0.038 0.055 7e-05\n",
      "0.03 0.115 0.00181\n",
      "0.04 0.063 0.00013\n",
      "0.045 0.047 0.0\n",
      "0.128 0.121 1e-05\n",
      "0.003 0.005 0.0\n",
      "0.014 0.018 0.0\n",
      "0.036 0.021 5e-05\n",
      "0.111 0.059 0.00067\n",
      "0.145 0.171 0.00017\n",
      "0.038 0.041 0.0\n",
      "0.032 0.037 1e-05\n",
      "0.02 0.067 0.00054\n",
      "0.016 0.008 2e-05\n",
      "0.039 0.022 8e-05\n",
      "0.061 0.025 0.00032\n",
      "0.001 0.002 0.0\n",
      "0.064 0.057 1e-05\n",
      "0.045 0.015 0.00024\n",
      "0.015 0.004 3e-05\n",
      "0.061 0.024 0.00034\n",
      "0.023 0.04 7e-05\n",
      "0.021 0.036 6e-05\n",
      "0.027 0.019 2e-05\n",
      "0.083 0.051 0.00026\n",
      "0.006 0.004 0.0\n",
      "0.033 0.041 2e-05\n",
      "0.049 0.101 0.00067\n",
      "0.031 0.027 0.0\n",
      "0.032 0.033 0.0\n",
      "0.047 0.047 0.0\n",
      "0.034 0.04 1e-05\n",
      "0.032 0.017 5e-05\n",
      "0.046 0.03 6e-05\n",
      "0.03 0.047 7e-05\n",
      "0.022 0.03 2e-05\n",
      "0.1 0.085 5e-05\n",
      "0.083 0.076 1e-05\n",
      "0.056 0.047 2e-05\n",
      "0.095 0.12 0.00015\n",
      "0.023 0.037 4e-05\n",
      "0.041 0.044 0.0\n",
      "0.07 0.108 0.00036\n",
      "0.062 0.041 0.0001\n",
      "0.024 0.056 0.00026\n",
      "0.044 0.052 2e-05\n",
      "0.01 0.016 1e-05\n",
      "0.044 0.075 0.00024\n",
      "0.066 0.039 0.00018\n",
      "0.04 0.038 0.0\n",
      "0.007 0.008 0.0\n",
      "0.02 0.017 0.0\n",
      "0.114 0.075 0.00039\n",
      "0.06 0.044 6e-05\n",
      "0.012 0.028 6e-05\n",
      "0.062 0.083 0.00012\n",
      "0.001 0.001 0.0\n",
      "0.022 0.014 2e-05\n",
      "0.039 0.04 0.0\n",
      "0.071 0.053 8e-05\n",
      "0.01 0.048 0.00035\n",
      "0.043 0.026 7e-05\n",
      "0.033 0.017 6e-05\n",
      "0.039 0.076 0.00035\n",
      "0.034 0.047 4e-05\n",
      "0.029 0.025 1e-05\n",
      "0.926 0.973 0.00055\n",
      "0.019 0.07 0.00065\n",
      "0.054 0.062 1e-05\n",
      "0.009 0.017 1e-05\n",
      "0.247 0.32 0.00131\n",
      "0.08 0.061 9e-05\n",
      "0.02 0.017 0.0\n",
      "0.039 0.03 2e-05\n",
      "0.017 0.04 0.00013\n",
      "0.046 0.042 0.0\n",
      "0.049 0.042 1e-05\n",
      "0.078 0.072 1e-05\n",
      "0.013 0.027 5e-05\n",
      "0.009 0.017 2e-05\n",
      "0.017 0.018 0.0\n",
      "0.037 0.039 0.0\n",
      "0.039 0.039 0.0\n",
      "0.053 0.046 2e-05\n",
      "0.062 0.193 0.00429\n",
      "0.097 0.08 7e-05\n",
      "0.017 0.033 6e-05\n",
      "0.025 0.036 3e-05\n",
      "0.037 0.018 9e-05\n",
      "0.479 0.63 0.00571\n",
      "0.053 0.029 0.00014\n",
      "0.06 0.054 1e-05\n",
      "0.056 0.054 0.0\n",
      "0.044 0.029 5e-05\n",
      "0.091 0.101 2e-05\n",
      "0.029 0.087 0.00083\n",
      "0.004 0.003 0.0\n",
      "0.038 0.053 5e-05\n",
      "0.012 0.018 1e-05\n",
      "0.087 0.122 0.00031\n",
      "0.517 0.57 0.00069\n",
      "0.024 0.025 0.0\n",
      "0.04 0.046 1e-05\n",
      "0.097 0.051 0.00054\n",
      "0.013 0.043 0.00022\n",
      "0.094 0.074 0.0001\n",
      "0.034 0.011 0.00014\n",
      "0.665 0.613 0.00067\n",
      "0.006 0.01 0.0\n",
      "0.103 0.079 0.00015\n",
      "0.028 0.026 0.0\n",
      "0.046 0.053 1e-05\n",
      "0.024 0.023 0.0\n",
      "0.027 0.06 0.00027\n",
      "0.097 0.042 0.00076\n",
      "0.03 0.067 0.00035\n",
      "0.838 0.61 0.01296\n",
      "0.017 0.027 3e-05\n",
      "0.051 0.018 0.00027\n",
      "0.064 0.086 0.00012\n",
      "0.067 0.085 8e-05\n",
      "0.023 0.064 0.00043\n",
      "0.101 0.097 1e-05\n",
      "0.019 0.008 3e-05\n",
      "0.108 0.123 6e-05\n",
      "0.104 0.099 0.0\n",
      "0.022 0.015 1e-05\n",
      "0.088 0.065 0.00014\n",
      "0.162 0.091 0.00127\n",
      "0.042 0.024 8e-05\n",
      "0.036 0.046 3e-05\n",
      "0.013 0.028 6e-05\n",
      "0.046 0.03 6e-05\n",
      "0.029 0.042 4e-05\n",
      "0.026 0.012 5e-05\n",
      "0.02 0.036 6e-05\n",
      "0.013 0.004 2e-05\n",
      "0.044 0.043 0.0\n",
      "0.016 0.014 0.0\n",
      "0.037 0.034 0.0\n",
      "0.05 0.041 2e-05\n",
      "0.021 0.04 9e-05\n",
      "0.076 0.078 0.0\n",
      "0.086 0.154 0.00115\n",
      "0.022 0.059 0.00035\n",
      "0.029 0.04 3e-05\n",
      "0.02 0.038 8e-05\n",
      "0.032 0.022 3e-05\n",
      "0.029 0.025 1e-05\n",
      "0.027 0.034 1e-05\n",
      "0.059 0.015 0.00048\n",
      "0.028 0.047 9e-05\n",
      "0.027 0.028 0.0\n",
      "0.059 0.06 0.0\n",
      "0.09 0.141 0.00063\n",
      "0.057 0.09 0.00027\n",
      "0.061 0.091 0.00022\n",
      "0.034 0.025 2e-05\n",
      "0.171 0.065 0.0028\n",
      "0.421 0.219 0.01024\n",
      "0.02 0.011 2e-05\n",
      "0.018 0.016 0.0\n",
      "0.053 0.052 0.0\n",
      "0.037 0.031 1e-05\n",
      "0.228 0.149 0.00154\n",
      "0.033 0.027 1e-05\n",
      "0.028 0.049 0.00011\n",
      "0.053 0.028 0.00015\n",
      "0.356 0.671 0.02482\n",
      "0.079 0.244 0.00682\n",
      "0.046 0.015 0.00024\n",
      "0.006 0.018 3e-05\n",
      "0.037 0.07 0.00026\n",
      "0.01 0.024 5e-05\n",
      "0.046 0.039 1e-05\n",
      "0.083 0.071 4e-05\n",
      "0.055 0.063 2e-05\n",
      "0.136 0.186 0.00062\n",
      "0.063 0.061 0.0\n",
      "0.545 0.594 0.0006\n",
      "0.028 0.018 3e-05\n",
      "0.021 0.014 1e-05\n",
      "0.066 0.081 6e-05\n",
      "0.031 0.023 1e-05\n",
      "0.057 0.052 1e-05\n",
      "0.028 0.014 5e-05\n",
      "0.025 0.023 0.0\n",
      "0.28 0.232 0.00057\n",
      "0.032 0.077 0.00051\n",
      "0.019 0.02 0.0\n",
      "0.05 0.048 0.0\n",
      "0.053 0.032 0.0001\n",
      "0.159 0.281 0.00371\n",
      "0.021 0.055 0.00029\n",
      "0.045 0.036 2e-05\n",
      "0.095 0.089 1e-05\n",
      "0.07 0.132 0.00094\n",
      "0.97 0.84 0.00421\n",
      "0.02 0.031 3e-05\n",
      "0.03 0.021 2e-05\n",
      "0.049 0.025 0.00014\n",
      "0.005 0.014 2e-05\n",
      "0.024 0.022 0.0\n",
      "0.02 0.01 3e-05\n",
      "0.024 0.037 4e-05\n",
      "0.012 0.024 3e-05\n",
      "0.039 0.02 9e-05\n",
      "0.021 0.032 3e-05\n",
      "0.03 0.06 0.00023\n",
      "0.056 0.048 2e-05\n",
      "0.021 0.031 3e-05\n",
      "0.029 0.022 1e-05\n",
      "0.021 0.014 1e-05\n",
      "0.031 0.028 0.0\n",
      "0.014 0.041 0.00018\n",
      "0.001 0.005 0.0\n",
      "0.029 0.02 2e-05\n",
      "0.097 0.027 0.00122\n",
      "0.045 0.026 9e-05\n",
      "0.03 0.012 8e-05\n",
      "0.093 0.072 0.00011\n",
      "0.017 0.011 1e-05\n",
      "0.028 0.027 0.0\n",
      "0.018 0.007 3e-05\n",
      "0.057 0.048 2e-05\n",
      "0.079 0.074 1e-05\n",
      "0.067 0.082 6e-05\n",
      "0.068 0.086 8e-05\n",
      "0.051 0.038 4e-05\n",
      "0.035 0.021 5e-05\n",
      "0.043 0.034 2e-05\n",
      "0.022 0.026 0.0\n",
      "0.07 0.063 1e-05\n",
      "0.054 0.104 0.00061\n",
      "0.033 0.017 7e-05\n",
      "0.006 0.012 1e-05\n",
      "0.099 0.09 2e-05\n",
      "0.043 0.015 0.0002\n",
      "0.256 0.195 0.00094\n",
      "0.246 0.188 0.00085\n",
      "0.023 0.028 1e-05\n",
      "0.06 0.078 8e-05\n",
      "0.04 0.096 0.00078\n",
      "0.071 0.053 8e-05\n",
      "0.019 0.027 2e-05\n",
      "0.032 0.064 0.00026\n",
      "0.047 0.072 0.00015\n",
      "0.074 0.114 0.00041\n",
      "0.119 0.035 0.00173\n",
      "0.032 0.042 2e-05\n",
      "0.052 0.036 7e-05\n",
      "0.032 0.042 3e-05\n",
      "0.065 0.083 8e-05\n",
      "0.037 0.022 6e-05\n",
      "0.047 0.038 2e-05\n",
      "0.055 0.048 1e-05\n",
      "0.016 0.023 1e-05\n",
      "0.005 0.001 0.0\n",
      "0.072 0.131 0.00087\n",
      "0.023 0.008 6e-05\n",
      "0.036 0.023 4e-05\n",
      "0.018 0.013 1e-05\n",
      "0.028 0.032 0.0\n",
      "0.023 0.077 0.00073\n",
      "0.02 0.05 0.00023\n",
      "0.017 0.011 1e-05\n",
      "0.033 0.012 0.0001\n",
      "0.035 0.045 3e-05\n",
      "0.021 0.056 0.00031\n",
      "0.011 0.006 1e-05\n",
      "0.051 0.076 0.00015\n",
      "0.024 0.018 1e-05\n",
      "0.031 0.049 8e-05\n",
      "0.042 0.031 3e-05\n",
      "0.088 0.041 0.00057\n",
      "0.029 0.017 4e-05\n",
      "0.014 0.017 0.0\n",
      "0.016 0.009 1e-05\n",
      "0.035 0.031 0.0\n",
      "0.033 0.021 3e-05\n",
      "0.073 0.039 0.0003\n",
      "0.036 0.031 0.0\n",
      "0.006 0.009 0.0\n",
      "0.078 0.043 0.0003\n",
      "0.006 0.008 0.0\n",
      "0.085 0.187 0.00259\n",
      "0.174 0.292 0.00345\n",
      "0.055 0.027 0.0002\n",
      "0.027 0.061 0.0003\n",
      "0.032 0.038 1e-05\n",
      "0.033 0.05 7e-05\n",
      "0.033 0.026 1e-05\n",
      "0.04 0.055 6e-05\n",
      "0.044 0.031 4e-05\n",
      "0.039 0.025 5e-05\n",
      "0.011 0.003 1e-05\n",
      "0.04 0.049 2e-05\n",
      "0.035 0.029 1e-05\n",
      "0.285 0.06 0.01261\n",
      "0.039 0.027 4e-05\n",
      "0.047 0.036 3e-05\n",
      "0.043 0.037 1e-05\n",
      "0.888 0.955 0.00114\n",
      "0.062 0.074 4e-05\n",
      "0.062 0.064 0.0\n",
      "0.096 0.157 0.00093\n",
      "0.006 0.01 0.0\n",
      "0.062 0.016 0.00053\n",
      "0.109 0.058 0.00065\n",
      "0.277 0.342 0.00105\n",
      "0.07 0.03 0.00038\n",
      "0.072 0.094 0.00012\n",
      "0.038 0.041 0.0\n",
      "0.017 0.005 4e-05\n",
      "0.018 0.03 4e-05\n",
      "0.056 0.079 0.00013\n",
      "0.052 0.048 0.0\n",
      "0.119 0.091 0.0002\n",
      "0.027 0.04 4e-05\n",
      "0.024 0.009 5e-05\n",
      "0.088 0.093 1e-05\n",
      "0.016 0.074 0.00084\n",
      "0.085 0.085 0.0\n",
      "0.046 0.036 3e-05\n",
      "0.107 0.124 8e-05\n",
      "0.051 0.065 5e-05\n",
      "0.029 0.118 0.00198\n",
      "0.029 0.059 0.00023\n",
      "0.012 0.013 0.0\n",
      "0.037 0.059 0.00012\n",
      "0.028 0.026 0.0\n",
      "0.191 0.165 0.00017\n",
      "0.043 0.029 5e-05\n",
      "0.032 0.044 4e-05\n",
      "0.76 0.782 0.00011\n",
      "0.05 0.042 1e-05\n",
      "0.027 0.034 1e-05\n",
      "0.054 0.058 0.0\n",
      "0.042 0.035 2e-05\n",
      "0.122 0.029 0.00218\n",
      "0.036 0.035 0.0\n",
      "0.071 0.168 0.00234\n",
      "0.026 0.04 5e-05\n",
      "0.116 0.083 0.00027\n",
      "0.0 0.001 0.0\n",
      "0.026 0.039 4e-05\n",
      "0.772 0.712 0.00092\n",
      "0.073 0.039 0.00029\n",
      "0.053 0.054 0.0\n",
      "0.074 0.04 0.00028\n",
      "0.878 0.818 0.0009\n",
      "0.015 0.011 0.0\n",
      "0.065 0.032 0.00027\n",
      "0.026 0.027 0.0\n",
      "0.12 0.079 0.00042\n",
      "0.027 0.029 0.0\n",
      "0.054 0.023 0.00024\n",
      "0.07 0.061 2e-05\n",
      "0.093 0.094 0.0\n",
      "0.06 0.056 0.0\n",
      "0.022 0.031 2e-05\n",
      "0.042 0.014 0.0002\n",
      "0.005 0.002 0.0\n",
      "0.022 0.043 0.00011\n",
      "0.08 0.05 0.00022\n",
      "0.017 0.053 0.00032\n",
      "0.042 0.032 2e-05\n",
      "0.066 0.059 1e-05\n",
      "0.049 0.067 9e-05\n",
      "0.003 0.004 0.0\n",
      "0.029 0.007 0.00013\n",
      "0.084 0.094 2e-05\n",
      "0.038 0.026 4e-05\n",
      "0.026 0.035 2e-05\n",
      "0.033 0.018 6e-05\n",
      "0.053 0.047 1e-05\n",
      "0.029 0.025 0.0\n",
      "0.036 0.051 5e-05\n",
      "0.017 0.023 1e-05\n",
      "0.033 0.048 5e-05\n",
      "0.047 0.026 0.00011\n",
      "0.023 0.032 2e-05\n",
      "0.082 0.12 0.00036\n",
      "0.017 0.039 0.00012\n",
      "0.31 0.35 0.00039\n",
      "0.027 0.039 4e-05\n",
      "0.045 0.103 0.00083\n",
      "0.038 0.058 0.0001\n",
      "0.055 0.084 0.00021\n",
      "0.069 0.095 0.00016\n",
      "0.003 0.001 0.0\n",
      "0.047 0.067 0.0001\n",
      "0.034 0.009 0.00015\n",
      "0.045 0.07 0.00015\n",
      "0.171 0.094 0.00146\n",
      "0.025 0.018 1e-05\n",
      "0.055 0.037 8e-05\n",
      "0.055 0.051 1e-05\n",
      "0.145 0.103 0.00044\n",
      "0.032 0.059 0.00017\n",
      "0.038 0.05 3e-05\n",
      "0.123 0.146 0.00013\n",
      "0.065 0.06 0.0\n",
      "0.032 0.026 1e-05\n",
      "0.035 0.017 8e-05\n",
      "0.075 0.096 0.00011\n",
      "0.055 0.048 1e-05\n",
      "0.004 0.018 5e-05\n",
      "0.027 0.041 5e-05\n",
      "0.034 0.017 8e-05\n",
      "0.089 0.055 0.00029\n",
      "0.026 0.037 3e-05\n",
      "0.485 0.369 0.00336\n",
      "0.048 0.041 1e-05\n",
      "0.003 0.015 4e-05\n",
      "0.06 0.017 0.00047\n",
      "0.038 0.021 7e-05\n",
      "0.098 0.202 0.00268\n",
      "0.081 0.04 0.00042\n",
      "0.027 0.046 8e-05\n",
      "0.046 0.039 1e-05\n",
      "0.023 0.017 1e-05\n",
      "0.039 0.03 2e-05\n",
      "0.026 0.03 0.0\n",
      "0.003 0.012 2e-05\n",
      "0.058 0.048 3e-05\n",
      "0.036 0.044 2e-05\n",
      "0.035 0.027 2e-05\n",
      "0.084 0.137 0.00071\n",
      "0.009 0.001 1e-05\n",
      "0.001 0.002 0.0\n",
      "0.092 0.03 0.00096\n",
      "0.037 0.073 0.00032\n",
      "0.032 0.025 1e-05\n",
      "0.055 0.063 2e-05\n",
      "0.003 0.016 5e-05\n",
      "0.058 0.071 5e-05\n",
      "0.037 0.026 3e-05\n",
      "0.044 0.017 0.00019\n",
      "0.032 0.044 4e-05\n",
      "0.018 0.004 4e-05\n",
      "0.104 0.081 0.00014\n",
      "0.012 0.012 0.0\n",
      "0.044 0.035 2e-05\n",
      "0.046 0.024 0.00012\n",
      "0.009 0.016 1e-05\n",
      "0.021 0.022 0.0\n",
      "0.871 0.947 0.00144\n",
      "0.021 0.023 0.0\n",
      "0.024 0.028 1e-05\n",
      "0.069 0.176 0.00283\n",
      "0.01 0.01 0.0\n",
      "0.04 0.026 5e-05\n",
      "0.024 0.031 1e-05\n",
      "0.049 0.053 1e-05\n",
      "0.014 0.021 1e-05\n",
      "0.057 0.027 0.00022\n",
      "0.053 0.058 1e-05\n",
      "0.057 0.03 0.00018\n",
      "0.199 0.064 0.00455\n",
      "0.005 0.009 0.0\n",
      "0.025 0.021 0.0\n",
      "0.044 0.034 2e-05\n",
      "0.013 0.028 6e-05\n",
      "0.023 0.009 5e-05\n",
      "0.033 0.028 1e-05\n",
      "0.01 0.029 9e-05\n",
      "0.034 0.026 2e-05\n",
      "0.013 0.034 0.00011\n",
      "0.024 0.047 0.00014\n",
      "0.021 0.035 5e-05\n",
      "0.027 0.042 6e-05\n",
      "0.001 0.004 0.0\n",
      "0.025 0.012 4e-05\n",
      "0.011 0.012 0.0\n",
      "0.895 0.852 0.00046\n",
      "0.05 0.139 0.00202\n",
      "0.114 0.086 0.0002\n",
      "0.013 0.017 0.0\n",
      "0.027 0.032 1e-05\n",
      "0.041 0.039 0.0\n",
      "0.1 0.079 0.00011\n",
      "0.032 0.017 6e-05\n",
      "0.022 0.025 0.0\n",
      "0.031 0.043 3e-05\n",
      "0.02 0.034 4e-05\n",
      "0.012 0.007 1e-05\n",
      "0.072 0.066 1e-05\n",
      "0.633 0.601 0.00025\n",
      "0.04 0.036 0.0\n",
      "0.039 0.028 3e-05\n",
      "0.095 0.1 0.0\n",
      "0.013 0.025 4e-05\n",
      "0.014 0.019 1e-05\n",
      "0.043 0.05 1e-05\n",
      "0.046 0.058 3e-05\n",
      "0.021 0.034 4e-05\n",
      "0.021 0.013 1e-05\n",
      "0.001 0.002 0.0\n",
      "0.026 0.112 0.00184\n",
      "0.054 0.056 0.0\n",
      "0.017 0.013 0.0\n",
      "0.04 0.052 4e-05\n",
      "0.049 0.054 1e-05\n",
      "0.028 0.024 0.0\n",
      "0.047 0.069 0.00012\n",
      "0.043 0.054 3e-05\n",
      "0.06 0.064 0.0\n",
      "0.017 0.037 0.00011\n",
      "0.065 0.063 0.0\n",
      "0.219 0.375 0.00609\n",
      "0.021 0.036 5e-05\n",
      "0.025 0.025 0.0\n",
      "0.029 0.028 0.0\n",
      "0.076 0.063 4e-05\n",
      "0.055 0.081 0.00017\n",
      "0.031 0.071 0.0004\n",
      "0.058 0.051 1e-05\n",
      "0.028 0.026 0.0\n",
      "0.017 0.035 8e-05\n",
      "0.05 0.031 9e-05\n",
      "0.054 0.027 0.00017\n",
      "0.031 0.038 1e-05\n",
      "0.067 0.064 0.0\n",
      "0.057 0.029 0.00019\n",
      "0.031 0.028 0.0\n",
      "0.013 0.048 0.0003\n",
      "0.029 0.053 0.00015\n",
      "0.042 0.044 0.0\n",
      "0.02 0.035 6e-05\n",
      "0.016 0.025 2e-05\n",
      "0.003 0.002 0.0\n",
      "0.003 0.004 0.0\n",
      "0.005 0.005 0.0\n",
      "0.033 0.027 1e-05\n",
      "0.969 0.964 1e-05\n",
      "0.026 0.027 0.0\n",
      "0.016 0.014 0.0\n",
      "0.03 0.047 7e-05\n",
      "0.02 0.041 0.00011\n",
      "0.025 0.029 1e-05\n",
      "0.019 0.039 0.0001\n",
      "0.027 0.056 0.00022\n",
      "0.051 0.036 5e-05\n",
      "0.073 0.049 0.00014\n",
      "0.031 0.02 3e-05\n",
      "0.029 0.075 0.00052\n",
      "0.055 0.09 0.00031\n",
      "0.036 0.018 8e-05\n",
      "0.033 0.017 6e-05\n",
      "0.023 0.071 0.00056\n",
      "0.014 0.021 1e-05\n",
      "0.084 0.079 1e-05\n",
      "0.159 0.185 0.00017\n",
      "0.027 0.057 0.00022\n",
      "0.041 0.041 0.0\n",
      "0.087 0.087 0.0\n",
      "0.111 0.074 0.00034\n",
      "0.033 0.039 1e-05\n",
      "0.001 0.006 1e-05\n",
      "0.05 0.058 2e-05\n",
      "0.046 0.027 9e-05\n",
      "0.032 0.026 1e-05\n",
      "0.084 0.065 9e-05\n",
      "0.109 0.062 0.00055\n",
      "0.004 0.005 0.0\n",
      "0.08 0.086 1e-05\n",
      "0.025 0.019 1e-05\n",
      "0.049 0.054 1e-05\n",
      "0.014 0.027 5e-05\n",
      "0.027 0.022 1e-05\n",
      "0.074 0.025 0.0006\n",
      "0.018 0.056 0.00035\n",
      "0.073 0.056 7e-05\n",
      "0.045 0.02 0.00016\n",
      "0.113 0.106 1e-05\n",
      "0.06 0.034 0.00018\n",
      "0.02 0.044 0.00014\n",
      "0.031 0.051 0.0001\n",
      "0.019 0.013 1e-05\n",
      "0.058 0.066 2e-05\n",
      "0.027 0.02 1e-05\n",
      "0.023 0.026 0.0\n",
      "0.008 0.008 0.0\n",
      "0.1 0.064 0.00032\n",
      "0.001 0.004 0.0\n",
      "0.031 0.053 0.00013\n",
      "0.032 0.054 0.00011\n",
      "0.019 0.089 0.00122\n",
      "0.015 0.006 2e-05\n",
      "0.032 0.059 0.00019\n",
      "0.063 0.076 5e-05\n",
      "0.04 0.033 1e-05\n",
      "0.028 0.032 1e-05\n",
      "0.044 0.055 3e-05\n",
      "0.075 0.072 0.0\n",
      "0.071 0.035 0.00032\n",
      "0.084 0.049 0.0003\n",
      "0.074 0.046 0.00019\n",
      "0.07 0.058 4e-05\n",
      "0.063 0.074 3e-05\n",
      "0.043 0.079 0.00032\n",
      "0.067 0.044 0.00014\n",
      "0.01 0.007 0.0\n",
      "0.021 0.033 3e-05\n",
      "0.107 0.078 0.00021\n",
      "0.041 0.014 0.00017\n",
      "0.015 0.016 0.0\n",
      "0.077 0.023 0.00073\n",
      "0.008 0.017 2e-05\n",
      "0.05 0.054 0.0\n",
      "0.042 0.035 1e-05\n",
      "0.064 0.057 1e-05\n",
      "0.056 0.083 0.00019\n",
      "0.048 0.035 5e-05\n",
      "0.047 0.056 2e-05\n",
      "0.031 0.021 2e-05\n",
      "0.08 0.031 0.0006\n",
      "0.017 0.012 1e-05\n",
      "0.022 0.02 0.0\n",
      "0.041 0.023 8e-05\n",
      "0.063 0.035 0.00019\n",
      "0.038 0.022 6e-05\n",
      "0.043 0.036 1e-05\n",
      "0.051 0.022 0.00021\n",
      "0.024 0.041 7e-05\n",
      "0.027 0.018 2e-05\n",
      "0.067 0.053 5e-05\n",
      "0.036 0.059 0.00013\n",
      "0.046 0.043 0.0\n",
      "0.01 0.033 0.00012\n",
      "0.044 0.025 0.0001\n",
      "0.072 0.072 0.0\n",
      "0.001 0.002 0.0\n",
      "0.024 0.033 2e-05\n",
      "0.041 0.018 0.00013\n",
      "0.018 0.003 6e-05\n",
      "0.161 0.166 0.0\n",
      "0.052 0.053 0.0\n",
      "0.023 0.043 0.0001\n",
      "0.033 0.058 0.00015\n",
      "0.004 0.008 0.0\n",
      "0.039 0.016 0.00013\n",
      "0.039 0.039 0.0\n",
      "0.027 0.021 1e-05\n",
      "0.037 0.046 2e-05\n",
      "0.042 0.029 4e-05\n",
      "0.037 0.021 6e-05\n",
      "0.049 0.06 3e-05\n",
      "0.076 0.029 0.00055\n",
      "0.014 0.015 0.0\n",
      "0.012 0.042 0.00022\n",
      "0.119 0.111 2e-05\n",
      "0.042 0.04 0.0\n",
      "0.005 0.012 1e-05\n",
      "0.058 0.031 0.00018\n",
      "0.015 0.034 9e-05\n",
      "0.09 0.064 0.00017\n",
      "0.031 0.045 5e-05\n",
      "0.035 0.017 8e-05\n",
      "0.09 0.094 0.0\n",
      "0.038 0.067 0.00021\n",
      "0.012 0.018 1e-05\n",
      "0.053 0.056 0.0\n",
      "0.021 0.029 2e-05\n",
      "0.051 0.047 0.0\n",
      "0.036 0.022 5e-05\n",
      "0.935 0.842 0.00215\n",
      "0.658 0.43 0.013\n",
      "0.11 0.075 0.00032\n",
      "0.251 0.219 0.00025\n",
      "0.079 0.062 7e-05\n",
      "0.069 0.053 6e-05\n",
      "0.028 0.018 3e-05\n",
      "0.049 0.031 8e-05\n",
      "0.022 0.016 1e-05\n",
      "0.034 0.026 1e-05\n",
      "0.046 0.026 0.00011\n",
      "0.836 0.906 0.00121\n",
      "0.0 0.0 0.0\n",
      "0.071 0.049 0.00013\n",
      "0.085 0.075 3e-05\n",
      "0.332 0.214 0.00346\n",
      "0.075 0.046 0.0002\n",
      "0.057 0.062 1e-05\n",
      "0.03 0.05 9e-05\n",
      "0.052 0.044 2e-05\n",
      "0.062 0.101 0.00038\n",
      "0.07 0.032 0.00035\n",
      "0.032 0.043 3e-05\n",
      "0.032 0.032 0.0\n",
      "0.011 0.01 0.0\n",
      "0.015 0.023 1e-05\n",
      "0.032 0.032 0.0\n",
      "0.049 0.035 5e-05\n",
      "0.053 0.039 5e-05\n",
      "0.014 0.006 1e-05\n",
      "0.032 0.029 0.0\n",
      "0.013 0.026 5e-05\n",
      "0.036 0.018 8e-05\n",
      "0.043 0.049 1e-05\n",
      "0.012 0.013 0.0\n",
      "0.013 0.021 1e-05\n",
      "0.074 0.064 3e-05\n",
      "0.038 0.03 2e-05\n",
      "0.038 0.023 6e-05\n",
      "0.06 0.054 1e-05\n",
      "0.052 0.046 1e-05\n",
      "0.044 0.065 0.00011\n",
      "0.319 0.58 0.01697\n",
      "0.255 0.312 0.00079\n",
      "0.049 0.029 0.0001\n",
      "0.017 0.076 0.00087\n",
      "0.088 0.11 0.00012\n",
      "0.016 0.01 1e-05\n",
      "0.019 0.006 5e-05\n",
      "0.101 0.146 0.0005\n",
      "0.505 0.603 0.00244\n",
      "0.061 0.039 0.00012\n",
      "0.087 0.096 2e-05\n",
      "0.04 0.05 3e-05\n",
      "0.018 0.018 0.0\n",
      "0.141 0.109 0.00026\n",
      "0.014 0.01 0.0\n",
      "0.016 0.006 3e-05\n",
      "0.014 0.009 1e-05\n",
      "0.038 0.045 1e-05\n",
      "0.079 0.113 0.0003\n",
      "0.026 0.014 3e-05\n",
      "0.033 0.037 1e-05\n",
      "0.036 0.06 0.00014\n",
      "0.155 0.09 0.00105\n",
      "0.04 0.021 9e-05\n",
      "0.057 0.092 0.00031\n",
      "0.069 0.067 0.0\n",
      "0.057 0.039 8e-05\n",
      "0.042 0.05 2e-05\n",
      "0.062 0.012 0.00062\n",
      "0.072 0.041 0.00025\n",
      "0.031 0.053 0.00013\n",
      "0.133 0.147 5e-05\n",
      "0.032 0.042 3e-05\n",
      "0.028 0.027 0.0\n",
      "0.083 0.072 3e-05\n",
      "0.093 0.115 0.00012\n",
      "0.059 0.057 0.0\n",
      "0.023 0.033 3e-05\n",
      "0.037 0.02 7e-05\n",
      "0.018 0.014 1e-05\n",
      "0.02 0.044 0.00015\n",
      "0.054 0.064 2e-05\n",
      "0.047 0.081 0.00029\n",
      "0.15 0.105 0.00051\n",
      "0.085 0.053 0.00026\n",
      "0.004 0.006 0.0\n",
      "0.015 0.007 2e-05\n",
      "0.034 0.017 8e-05\n",
      "0.034 0.015 9e-05\n",
      "0.135 0.073 0.00098\n",
      "0.06 0.101 0.00042\n",
      "0.009 0.026 7e-05\n",
      "0.053 0.053 0.0\n",
      "0.342 0.246 0.00232\n",
      "0.015 0.01 1e-05\n",
      "0.618 0.436 0.00831\n",
      "0.027 0.028 0.0\n",
      "0.035 0.023 4e-05\n",
      "0.073 0.095 0.00012\n",
      "0.041 0.032 2e-05\n",
      "0.038 0.035 0.0\n",
      "0.077 0.039 0.00036\n",
      "0.034 0.031 0.0\n",
      "0.066 0.079 4e-05\n",
      "0.002 0.013 3e-05\n",
      "0.04 0.064 0.00014\n",
      "0.052 0.01 0.00044\n",
      "0.046 0.043 0.0\n",
      "0.087 0.081 1e-05\n",
      "0.033 0.036 0.0\n",
      "0.029 0.022 1e-05\n",
      "0.023 0.014 2e-05\n",
      "0.025 0.046 0.00012\n",
      "0.036 0.031 1e-05\n",
      "0.029 0.019 2e-05\n",
      "0.06 0.084 0.00015\n",
      "0.037 0.021 6e-05\n",
      "0.098 0.066 0.00026\n",
      "0.085 0.043 0.00045\n",
      "0.027 0.028 0.0\n",
      "0.539 0.517 0.00011\n",
      "0.027 0.013 5e-05\n",
      "0.016 0.018 0.0\n",
      "0.129 0.057 0.00127\n",
      "0.1 0.07 0.00023\n",
      "0.017 0.018 0.0\n",
      "0.041 0.02 0.00011\n",
      "0.018 0.017 0.0\n",
      "0.029 0.019 3e-05\n",
      "0.006 0.004 0.0\n",
      "0.043 0.058 6e-05\n",
      "0.082 0.133 0.00065\n",
      "0.062 0.019 0.00047\n",
      "0.037 0.025 3e-05\n",
      "0.029 0.033 0.0\n",
      "0.065 0.025 0.00041\n",
      "0.023 0.012 3e-05\n",
      "0.035 0.02 6e-05\n",
      "0.035 0.04 1e-05\n",
      "0.033 0.08 0.00054\n",
      "0.067 0.085 8e-05\n",
      "0.049 0.089 0.0004\n",
      "0.033 0.049 6e-05\n",
      "0.02 0.01 2e-05\n",
      "0.06 0.059 0.0\n",
      "0.025 0.018 1e-05\n",
      "0.042 0.041 0.0\n",
      "0.007 0.019 3e-05\n",
      "0.028 0.038 2e-05\n",
      "0.058 0.019 0.00037\n",
      "0.035 0.031 0.0\n",
      "0.057 0.084 0.00017\n",
      "0.034 0.05 7e-05\n",
      "0.018 0.004 5e-05\n",
      "0.088 0.083 1e-05\n",
      "0.096 0.065 0.00024\n",
      "0.028 0.021 1e-05\n",
      "0.047 0.06 4e-05\n",
      "0.053 0.022 0.00025\n",
      "0.065 0.081 6e-05\n",
      "0.018 0.02 0.0\n",
      "0.067 0.091 0.00014\n",
      "0.071 0.056 5e-05\n",
      "0.16 0.08 0.00161\n",
      "0.006 0.013 1e-05\n",
      "0.035 0.028 1e-05\n",
      "0.019 0.03 3e-05\n",
      "0.021 0.027 1e-05\n",
      "0.032 0.03 0.0\n",
      "0.014 0.02 1e-05\n",
      "0.044 0.065 0.00011\n",
      "0.028 0.045 7e-05\n",
      "0.04 0.056 6e-05\n",
      "0.102 0.017 0.00179\n",
      "0.054 0.041 4e-05\n",
      "0.081 0.04 0.00043\n",
      "0.021 0.021 0.0\n",
      "0.031 0.052 0.00011\n",
      "0.003 0.013 2e-05\n",
      "0.023 0.008 5e-05\n",
      "0.053 0.064 3e-05\n",
      "0.045 0.116 0.00124\n",
      "0.058 0.051 1e-05\n",
      "0.064 0.038 0.00016\n",
      "0.037 0.068 0.00023\n",
      "0.033 0.045 4e-05\n",
      "0.062 0.164 0.00259\n",
      "0.022 0.01 3e-05\n",
      "0.004 0.01 1e-05\n",
      "0.057 0.028 0.0002\n",
      "0.036 0.073 0.00035\n",
      "0.041 0.017 0.00014\n",
      "0.055 0.091 0.00032\n",
      "0.025 0.045 0.00011\n",
      "0.078 0.081 0.0\n",
      "0.03 0.049 9e-05\n",
      "0.021 0.051 0.00023\n",
      "0.043 0.011 0.00025\n",
      "0.05 0.07 0.0001\n",
      "0.053 0.064 3e-05\n",
      "0.04 0.033 1e-05\n",
      "0.055 0.053 0.0\n",
      "0.04 0.049 2e-05\n",
      "0.033 0.018 6e-05\n",
      "0.01 0.01 0.0\n",
      "0.105 0.051 0.00073\n",
      "0.02 0.025 1e-05\n",
      "0.058 0.048 2e-05\n",
      "0.063 0.034 0.0002\n",
      "0.09 0.05 0.00041\n",
      "0.049 0.062 4e-05\n",
      "0.071 0.115 0.00049\n",
      "0.023 0.035 4e-05\n",
      "0.035 0.022 4e-05\n",
      "0.002 0.0 0.0\n",
      "0.021 0.027 1e-05\n",
      "0.046 0.023 0.00013\n",
      "0.076 0.033 0.00045\n",
      "0.008 0.001 1e-05\n",
      "0.012 0.013 0.0\n",
      "0.044 0.063 8e-05\n",
      "0.032 0.068 0.00033\n",
      "0.044 0.026 8e-05\n",
      "0.019 0.017 0.0\n",
      "0.034 0.022 3e-05\n",
      "0.056 0.079 0.00013\n",
      "0.052 0.07 9e-05\n",
      "0.057 0.07 4e-05\n",
      "0.037 0.031 1e-05\n",
      "0.034 0.028 1e-05\n",
      "0.068 0.064 0.0\n",
      "0.102 0.029 0.00135\n",
      "0.018 0.039 0.00011\n",
      "0.061 0.037 0.00015\n",
      "0.133 0.058 0.00141\n",
      "0.034 0.055 0.00011\n",
      "0.129 0.085 0.0005\n",
      "0.03 0.032 0.0\n",
      "0.04 0.033 1e-05\n",
      "0.096 0.162 0.00106\n",
      "0.02 0.019 0.0\n",
      "0.001 0.001 0.0\n",
      "0.02 0.022 0.0\n",
      "0.023 0.016 1e-05\n",
      "0.069 0.042 0.00018\n",
      "0.046 0.053 1e-05\n",
      "0.034 0.014 0.0001\n",
      "0.016 0.008 2e-05\n",
      "0.032 0.02 4e-05\n",
      "0.008 0.01 0.0\n",
      "0.014 0.021 1e-05\n",
      "0.033 0.042 2e-05\n",
      "0.029 0.014 5e-05\n",
      "0.051 0.038 4e-05\n",
      "0.022 0.047 0.00015\n",
      "0.142 0.067 0.0014\n",
      "0.049 0.045 0.0\n",
      "0.038 0.028 3e-05\n",
      "0.011 0.021 2e-05\n",
      "0.05 0.033 7e-05\n",
      "0.022 0.012 2e-05\n",
      "0.05 0.026 0.00015\n",
      "0.091 0.051 0.0004\n",
      "0.017 0.011 1e-05\n",
      "0.06 0.036 0.00015\n",
      "0.005 0.006 0.0\n",
      "0.015 0.027 4e-05\n",
      "0.122 0.112 3e-05\n",
      "0.062 0.033 0.00022\n",
      "0.055 0.095 0.00039\n",
      "0.502 0.375 0.00408\n",
      "0.01 0.008 0.0\n",
      "0.059 0.031 0.00019\n",
      "0.035 0.043 1e-05\n",
      "0.029 0.041 4e-05\n",
      "0.013 0.017 0.0\n",
      "0.043 0.112 0.00121\n",
      "0.07 0.115 0.00051\n",
      "0.081 0.042 0.00039\n",
      "0.007 0.021 5e-05\n",
      "0.027 0.037 3e-05\n",
      "0.05 0.033 8e-05\n",
      "0.022 0.047 0.00016\n",
      "0.06 0.087 0.00018\n",
      "0.032 0.02 3e-05\n",
      "0.044 0.058 5e-05\n",
      "0.029 0.023 1e-05\n",
      "0.014 0.019 1e-05\n",
      "0.053 0.023 0.00023\n",
      "0.882 0.83 0.00067\n",
      "0.04 0.039 0.0\n",
      "0.08 0.043 0.00034\n",
      "0.068 0.069 0.0\n",
      "0.048 0.055 1e-05\n",
      "0.484 0.395 0.00201\n",
      "0.041 0.026 5e-05\n",
      "0.026 0.041 5e-05\n",
      "0.037 0.027 3e-05\n",
      "0.031 0.043 4e-05\n",
      "0.023 0.016 1e-05\n",
      "0.111 0.243 0.0044\n",
      "0.03 0.05 0.0001\n",
      "0.059 0.078 9e-05\n",
      "0.095 0.039 0.00079\n",
      "0.018 0.019 0.0\n",
      "0.029 0.025 0.0\n",
      "0.013 0.023 3e-05\n",
      "0.047 0.039 2e-05\n",
      "0.026 0.013 4e-05\n",
      "0.041 0.035 1e-05\n",
      "0.06 0.021 0.00037\n",
      "0.049 0.024 0.00015\n",
      "0.011 0.001 3e-05\n",
      "0.064 0.069 0.0\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(all_pred[0, :, 0], all_pred[1, :, 0]):\n",
    "    print(np.round(i, 3), np.around(j, 3), np.round(np.var([i, j]), 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/projects/home/mmasood1/Model_weights/preclinical_clinical/chemprop/model-epoch=11-val_BCE_loss=0.19.ckpt'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_callback.best_model_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
      "Loading pretrained parameter \"readout.1.weight\".\n",
      "Loading pretrained parameter \"readout.1.bias\".\n",
      "Moving model to cuda\n",
      "best_model balanced_acc         0.544626\n",
      "f1_score             0.202154\n",
      "specificity          0.305844\n",
      "sensitivity          0.783408\n",
      "roc_auc              0.473830\n",
      "AUPR                 0.097593\n",
      "average_precision    0.100683\n",
      "dtype: float64\n",
      "1\n",
      "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
      "Loading pretrained parameter \"readout.1.weight\".\n",
      "Loading pretrained parameter \"readout.1.bias\".\n",
      "Moving model to cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24192/3954520195.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append(metrics.mean(), ignore_index= True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_model balanced_acc         0.528686\n",
      "f1_score             0.189478\n",
      "specificity          0.446164\n",
      "sensitivity          0.611208\n",
      "roc_auc              0.432481\n",
      "AUPR                 0.094822\n",
      "average_precision    0.096823\n",
      "dtype: float64\n",
      "script completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24192/3954520195.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append(metrics.mean(), ignore_index= True)\n"
     ]
    }
   ],
   "source": [
    "models_chkpoints = [checkpoint_callback.best_model_path,\n",
    "                    checkpoint_callback.last_model_path]\n",
    "model_type = [\"best_model\", \"last_model\"]\n",
    "\n",
    "data_dir = args.metadata_dir + \"predicitons/\"\n",
    "result_dir = args.metadata_dir + \"Results/\"\n",
    "\n",
    "for i, chk_path in enumerate(models_chkpoints):\n",
    "    print(i)\n",
    "    args.pretrained_dir = chk_path\n",
    "    model = pretrained_model(Custom_Chemprop, args)\n",
    "    model = model.eval()\n",
    "\n",
    "    targets, preds, pred_var = get_chemprop_pred(val_dataloader, model,\n",
    "                                                 n_samples=val_y.shape[0],\n",
    "                                                 n_classes=val_y.shape[1],\n",
    "                                                 cal_uncert=True,\n",
    "                                                 num_forward_passes=args.num_forward_passes)\n",
    "    metrics = compute_binary_classification_metrics_MT(\n",
    "        targets, preds, missing='nan')\n",
    "    print(model_type[i], metrics.mean())\n",
    "    metrics = metrics.append(metrics.mean(), ignore_index=True)\n",
    "    metrics.insert(0, 'Tasks', args.selected_tasks + ['mean'])\n",
    "\n",
    "    obs = pd.DataFrame(targets)\n",
    "    obs.columns = args.selected_tasks\n",
    "    obs.insert(0, 'SMILES', test_set.ids)\n",
    "\n",
    "    pred = pd.DataFrame(preds)\n",
    "    pred.columns = args.selected_tasks\n",
    "    pred.insert(0, 'SMILES', test_set.ids)\n",
    "\n",
    "    pred_var = pd.DataFrame(pred_var)\n",
    "    pred_var.columns = args.selected_tasks\n",
    "    pred_var.insert(0, 'SMILES', test_set.ids)\n",
    "\n",
    "    label = 'test'\n",
    "    # obs.to_csv(data_dir + f'{model_type[i]}_{label}_obs.csv', index=False)\n",
    "    # pred.to_csv(data_dir + f'{model_type[i]}_{label}_pred.csv', index=False)\n",
    "    # pred_var.to_csv(data_dir + f'{model_type[i]}_{label}_pred.csv', index=False)\n",
    "    # metrics.to_csv(result_dir + f'{model_type[i]}_{label}_metrics.csv', index=False)\n",
    "\n",
    "print(\"script completed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.read_csv(\"/projects/home/mmasood1/trained_model_predictions/Tox21/Chemprop/Results/best_model_test_metrics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.read_csv(\"/projects/home/mmasood1/trained_model_predictions/Tox21/Chemprop/Results/last_model_test_metrics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "args.num_forward_passes = 2\n",
    "models_chkpoints = [\"/projects/home/mmasood1/Model_weights/preclinical_clinical/chemprop/model-epoch=18-val_BCE_loss=0.19.ckpt\"]\n",
    "model_type = [\"best_model\"]\n",
    "\n",
    "data_dir = args.metadata_dir + \"predicitons/\"\n",
    "result_dir = args.metadata_dir + \"Results/\"\n",
    "\n",
    "for i, chk_path in enumerate(models_chkpoints):\n",
    "    print(i)\n",
    "    args.pretrained_dir = chk_path\n",
    "    trained_model = pretrained_model(Custom_Chemprop,args)\n",
    "    trained_model = trained_model.eval()\n",
    "\n",
    "    targets, preds, pred_var = get_chemprop_pred(val_dataloader, trained_model, \n",
    "                                   n_samples= val_y.shape[0], \n",
    "                                   n_classes= val_y.shape[1],\n",
    "                                   cal_uncert= True, \n",
    "                                   num_forward_passes = args.num_forward_passes)\n",
    "    metrics = compute_binary_classification_metrics_MT(targets, preds, missing = 'nan')\n",
    "    metrics = metrics.append(metrics.mean(), ignore_index= True)\n",
    "    metrics.insert(0, 'Tasks', args.selected_tasks + ['mean'])\n",
    "\n",
    "print(\"script completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tasks</th>\n",
       "      <th>balanced_acc</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>specificity</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>AUPR</th>\n",
       "      <th>average_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NR-AR</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NR-AR-LBD</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NR-AhR</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NR-Aromatase</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NR-ER</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NR-ER-LBD</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NR-PPAR-gamma</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SR-ARE</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SR-ATAD5</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SR-HSE</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SR-MMP</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SR-p53</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Tasks  balanced_acc  f1_score  specificity  sensitivity  roc_auc  \\\n",
       "0           NR-AR         0.727     0.568        0.989        0.466    0.752   \n",
       "1       NR-AR-LBD         0.789     0.565        0.920        0.659    0.771   \n",
       "2          NR-AhR         0.766     0.519        0.717        0.816    0.828   \n",
       "3    NR-Aromatase         0.687     0.365        0.852        0.522    0.743   \n",
       "4           NR-ER         0.642     0.378        0.906        0.379    0.684   \n",
       "5       NR-ER-LBD         0.699     0.362        0.917        0.480    0.744   \n",
       "6   NR-PPAR-gamma         0.704     0.275        0.685        0.722    0.750   \n",
       "7          SR-ARE         0.675     0.500        0.810        0.540    0.722   \n",
       "8        SR-ATAD5         0.679     0.277        0.697        0.662    0.729   \n",
       "9          SR-HSE         0.704     0.393        0.902        0.505    0.760   \n",
       "10         SR-MMP         0.755     0.578        0.828        0.681    0.824   \n",
       "11         SR-p53         0.696     0.386        0.732        0.660    0.756   \n",
       "12           mean         0.710     0.431        0.830        0.591    0.755   \n",
       "\n",
       "     AUPR  average_precision  \n",
       "0   0.485              0.486  \n",
       "1   0.430              0.443  \n",
       "2   0.527              0.529  \n",
       "3   0.324              0.331  \n",
       "4   0.373              0.374  \n",
       "5   0.274              0.286  \n",
       "6   0.175              0.181  \n",
       "7   0.467              0.469  \n",
       "8   0.194              0.200  \n",
       "9   0.305              0.313  \n",
       "10  0.519              0.523  \n",
       "11  0.323              0.326  \n",
       "12  0.366              0.372  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv(\n",
    "    \"/projects/home/mmasood1/trained_model_predictions/Tox21/Chemprop/Results/test_metrics.csv\")\n",
    "results.round(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\n",
    "    \"/projects/home/mmasood1/trained_model_predictions/Tox21/Chemprop/Results/test_metrics.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24431/379112739.py:2: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  pred_var.mean().mean().round(6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.001732"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_var = pd.read_csv(\n",
    "    \"/projects/home/mmasood1/trained_model_predictions/Tox21/Chemprop/predicitons/test_pred.csv\")\n",
    "pred_var.mean().mean().round(6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NR-AR</th>\n",
       "      <th>NR-AR-LBD</th>\n",
       "      <th>NR-AhR</th>\n",
       "      <th>NR-Aromatase</th>\n",
       "      <th>NR-ER</th>\n",
       "      <th>NR-ER-LBD</th>\n",
       "      <th>NR-PPAR-gamma</th>\n",
       "      <th>SR-ARE</th>\n",
       "      <th>SR-ATAD5</th>\n",
       "      <th>SR-HSE</th>\n",
       "      <th>SR-MMP</th>\n",
       "      <th>SR-p53</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7826</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7827</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7828</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7829</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7830</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7831 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      NR-AR  NR-AR-LBD  NR-AhR  NR-Aromatase  NR-ER  NR-ER-LBD  NR-PPAR-gamma  \\\n",
       "0       0.0        0.0     1.0           NaN    NaN        0.0            0.0   \n",
       "1       0.0        0.0     0.0           0.0    0.0        0.0            0.0   \n",
       "2       NaN        NaN     NaN           NaN    NaN        NaN            NaN   \n",
       "3       0.0        0.0     0.0           0.0    0.0        0.0            0.0   \n",
       "4       0.0        0.0     0.0           0.0    0.0        0.0            0.0   \n",
       "...     ...        ...     ...           ...    ...        ...            ...   \n",
       "7826    NaN        NaN     NaN           NaN    NaN        NaN            NaN   \n",
       "7827    1.0        1.0     0.0           0.0    1.0        0.0            NaN   \n",
       "7828    1.0        1.0     0.0           0.0    1.0        1.0            0.0   \n",
       "7829    1.0        1.0     0.0           NaN    1.0        1.0            0.0   \n",
       "7830    0.0        0.0     NaN           0.0    0.0        0.0            0.0   \n",
       "\n",
       "      SR-ARE  SR-ATAD5  SR-HSE  SR-MMP  SR-p53  \n",
       "0        1.0       0.0     0.0     0.0     0.0  \n",
       "1        NaN       0.0     NaN     0.0     0.0  \n",
       "2        0.0       NaN     0.0     NaN     NaN  \n",
       "3        NaN       0.0     NaN     0.0     0.0  \n",
       "4        0.0       0.0     0.0     0.0     0.0  \n",
       "...      ...       ...     ...     ...     ...  \n",
       "7826     0.0       NaN     0.0     NaN     NaN  \n",
       "7827     NaN       0.0     0.0     NaN     0.0  \n",
       "7828     1.0       0.0     0.0     0.0     0.0  \n",
       "7829     0.0       0.0     0.0     1.0     1.0  \n",
       "7830     0.0       0.0     0.0     1.0     0.0  \n",
       "\n",
       "[7831 rows x 12 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(args.target_file)\n",
    "data = data.loc[:, args.selected_tasks]\n",
    "\n",
    "target_weights = (data == 0).sum() / (data == 1).sum()\n",
    "args.target_weights = target_weights.values\n",
    "# normalize target weights (Coming from Chemprop)\n",
    "avg_weight = sum(args.target_weights)/len(args.target_weights)\n",
    "self.target_weights = [w/avg_weight for w in args.target_weights]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_arslan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
